#!/usr/bin/env bash

# This file is part of CO𝘕CEPT, the cosmological 𝘕-body code in Python.
# Copyright © 2015–2021 Jeppe Mosgaard Dakin.
#
# CO𝘕CEPT is free software: You can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# CO𝘕CEPT is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with CO𝘕CEPT. If not, see https://www.gnu.org/licenses/
#
# The author of CO𝘕CEPT can be contacted at dakin(at)phys.au.dk
# The latest version of CO𝘕CEPT is available at
# https://github.com/jmd-dk/concept/



# Help text which gets printed if invoked with -h or --help.
help_text='This script downloads and installs the CO𝘕CEPT code with all its
dependencies.

Below you will find a short description of how to run this script.
This is more thoroughly documented in the CO𝘕CEPT documentation:
https://jmd-dk.github.io/concept/installation.html

If run without an argument, this script will prompt for an
installation directory. Alternatively, this directory can be passed as
an argument. Everything will be installed within this directory.

Options taken by this script:
-h, --help             Show this help message and exit.
-t, --tests            Test the various dependency programs after their
                       individual installations. CO𝘕CEPT itself will similarly
                       be tested. On failure (fatal or non-fatal) of any test,
                       a log file of the test output will be placed in the
                       installation subdirectory of the given program. Any
                       test failures will be reported at the end of the entire
                       installation process.
-y, --yes_to_defaults  Accept default options on future queries. These include
                       system-wide installations of system dependencies,
                       should they be missing, as well as termination of
                       already running CO𝘕CEPT installation process, should
                       one exist.
--slim                 Slim down the installation in order to save disk space.
                       This removes uncritical content from all installed
                       dependency programs and CO𝘕CEPT itself.
--fix-ssh              Set up the ~/.ssh directory so that it allows for
                       password-less SSH login between nodes. This may be
                       needed in order to run multi-node MPI computations on
                       clusters. The original state of the ~/.ssh directory
                       will be backed up. Note that this option will perform
                       the changes to ~/.ssh only; no actual installation will
                       take place.

The full invocation signature of this script thus looks like
  /path/to/install [/path/to/concept] [-t] [-y] [--slim]
or
  /path/to/install --fix-ssh
where brackets indicate optional arguments.

The system dependencies mentioned above consist of the following
(GNU implementations, specifically):
  - awk
  - gcc
  - g++
  - gfortran
  - grep
  - gzip
  - make
  - sed
  - tar
  - wget
  - glibc
  - as and ld
  - Linux headers
If any of these are missing, an attempt will be made to locate the
package manager on the system. If successful, you will be prompted to install
the missing system dependency, which will require root access.

The only system dependencies needed but not installed are the GNU core
utilities and Bash. This script (and others used in CO𝘕CEPT) should be
compatible with Bash version 3.0 or later.

The programs which will be installed into the specified installation
directory consist of the following and will be installed in order:
  - zlib (needed by HDF5, Python, pillow (needed by Matplotlib))
  - GSL
  - Perl (needed by OpenSSL, OpenBLAS, MPICH/OpenMPI)
  - MPICH/OpenMPI
  - HDF5
  - FFTW
  - FreeType (needed by Matplotlib)
  - ncurses  (needed by _curses (needed by Blessings))
  - OpenSSL  (needed by pip)
  - libffi   (needed by _ctypes (needed by pip))
  - OpenBLAS (needed by SciPy, used by NumPy)
  - Python, with the following packages
    (along with their own Python package dependencies):
      - pip, setuptools, wheel (if any of the below)
      - Blessings
      - Cython
      - CythonGSL
      - NumPy
      - SciPy
      - Matplotlib
      - MPI4Py
      - H5Py
      - Sphinx
      - Sphinx-copybutton
      - Sphinx-rtd-theme
      - Sphinx-tabs
  - CO𝘕CEPT
  - CLASS
  - FFTW 2 (needed by GADGET)
  - GADGET

Due to the numerosity of the above list, the installation process will take
a couple of hours on modern hardware. Should the installation process end
prematurely, simply rerun this script with the same arguments and environment
as originally, and it will pick up the installation from where it left off.

See https://jmd-dk.github.io/concept/installation.html for further information.
'
# Print help text and exit, if help is requested
for var in "$@"; do
    if     [ "${var}" ==  "-h"    ] \
        || [ "${var}" == "--h"    ] \
        || [ "${var}" == "--he"   ] \
        || [ "${var}" == "--hel"  ] \
        || [ "${var}" == "--help" ]; then
        printf "${help_text}"
        exit 0
    fi
done

# Absolute paths to this file
this_file="$(readlink -f "${BASH_SOURCE[0]}")"

# If invoked directly from the web (e.g. via wget), a small pause
# ensures that the print outs will not corrupt the loading bar.
sleep 2
# Newer versions of wget saves a copy of the printout when using the
# -O- option to a file called wget-log[.x], x ∈ ℕ. Remove any such log
# produced from invoking this script via wget.
wget_log_maxage=300
for filename in *; do
    if [ ! -f "${filename}" ] || [[ "${filename}" != "wget-log"* ]]; then
        continue
    fi
    fileage=$(($(date +%s) - $(stat -c '%Y' "${filename}")))
    if [ ${fileage} -lt ${wget_log_maxage} ]; then
        rm -f "${filename}" || :
    fi
done



##################
# Specifications #
##################
# The MPI implementation to use
mpi_lower="$(echo "${mpi}" | tr '[:upper:]' '[:lower:]')"
if [ -z "${mpi}" ]; then
    # If mpi_dir is specified,
    # try to determine whether MPICH or OpenMPI is used.
    if [ -n "${mpi_dir}" ]; then
        if     [ -f "${mpi_dir}/bin/mpichversion" ]                           \
            || [ -f "$(dirname "${mpi_dir}")/bin/mpichversion" ]              \
            || [ -f "$(dirname "$(dirname "${mpi_dir}")")/bin/mpichversion" ] \
        ; then
            mpi="mpich"
        elif   [ -f "${mpi_dir}/bin/ompi_info" ]                           \
            || [ -f "$(dirname "${mpi_dir}")/bin/ompi_info" ]              \
            || [ -f "$(dirname "$(dirname "${mpi_dir}")")/bin/ompi_info" ] \
        ; then
            mpi="openmpi"
        else
            mpi="unknown"
        fi
    else
        # Use MPICH by default
        mpi="mpich"
    fi
elif [ "${mpi_lower}" != "mpich" ] && [ "${mpi_lower}" != "openmpi" ]; then
    echo "Specified MPI implementation mpi=\"${mpi}\" not recognised.
Will use MPICH" >&2
    mpi="mpich"
fi
mpi="$(echo "${mpi}" | tr '[:upper:]' '[:lower:]')"
mpi_formatted="${mpi}"
if [ "${mpi_formatted}" == "mpich" ]; then
    mpi_formatted="MPICH"
elif [ "${mpi_formatted}" == "openmpi" ]; then
    mpi_formatted="OpenMPI"
fi
# This function sets the variables "name_dir" (if not set already)
# and "name_preinstalled".
set_dir() {
    # Arguments: Program name, install directory.
    # Set "name_preinstalled" if "name_dir" is already set
    eval "${1}_preinstalled=True"
    eval "[ -n \"\${${1}_dir}\" ] || ${1}_preinstalled=\"False\""
    # Set "name_dir" if "name_dir" is not already set
    # or "name" should be installed.
    eval "[ -n \"\${${1}_dir}\" ] || ${1}_dir=\"${2}\""
    eval "(! (   [ \"\${${1}_install}\"      == \"False\" ] \
              && [ \"\${${1}_preinstalled}\" == \"False\" ])) || ${1}_dir=\"\""
}
# The install_explicit_only environment variable, when set to "True",
# disables all implicit installations.
if [ "${install_explicit_only}" == "True" ]; then
    for progname in         \
        "concept"           \
        "blas"              \
        "class"             \
        "fftw"              \
        "fftw_for_gadget"   \
        "freetype"          \
        "gadget"            \
        "gsl"               \
        "hdf5"              \
        "libffi"            \
        "mpi"               \
        "ncurses"           \
        "openssl"           \
        "perl"              \
        "python"            \
        "zlib"              \
        "blessings"         \
        "cython"            \
        "cythongsl"         \
        "h5py"              \
        "matplotlib"        \
        "mpi4py"            \
        "numpy"             \
        "scipy"             \
        "sphinx"            \
        "sphinx_copybutton" \
        "sphinx_rtd_theme"  \
        "sphinx_tabs"       \
    ; do
        eval "[ -n \"\${${progname}_install}\" ] || ${progname}_install=\"False\""
    done
fi
# Specification of paths. The substring "__concept_dir__"
# will later be replaced with the top-level directory.
set_dir "concept"         "__concept_dir__"
set_dir "class"           "__concept_dir__/dep/class"
set_dir "fftw"            "__concept_dir__/dep/fftw"
set_dir "freetype"        "__concept_dir__/dep/freetype"
set_dir "gadget"          "__concept_dir__/dep/gadget"
set_dir "fftw_for_gadget" "${gadget_dir}/fftw"
set_dir "gsl"             "__concept_dir__/dep/gsl"
set_dir "hdf5"            "__concept_dir__/dep/hdf5"
set_dir "mpi"             "__concept_dir__/dep/${mpi}"
set_dir "blas"            "__concept_dir__/dep/openblas"
set_dir "perl"            "__concept_dir__/dep/perl"
set_dir "python"          "__concept_dir__/dep/python"
set_dir "ncurses"         "${python_dir}"
set_dir "openssl"         "${python_dir}"
set_dir "libffi"          "${python_dir}"
set_dir "zlib"            "__concept_dir__/dep/zlib"
tmp_dir="__concept_dir__/.tmp"
log="${tmp_dir}/install_log"
env="__concept_dir__/.env"
path="__concept_dir__/.path"

# This function sets the variable "name_version" if not set already.
# For pre-installed software, set "name_version" to "pre-installed".
# If a third argument is given, this is the version to fall back to,
# in case of unsuccessful retrieval of the link to the first version.
set_version() {
    # Arguments: Program name, version, [fallback version]
    progname="$1"
    version="$2"
    version_fallback="$3"
    eval "[ -z \"\${${progname}_version}\" ] || ${progname}_version_specifiedbyuser=\"True\""
    eval "[ -n \"\${${progname}_version}\" ] || ${progname}_version=\"${version}\""
    eval "[ \"\${${progname}_preinstalled}\" != \"True\" ] || ${progname}_version=\"pre-installed\""
    if [ -n "${version_fallback}" ]; then
        eval "${progname}_version_fallback=\"${version_fallback}\""
    fi
    eval "${progname}_version=\"\${${progname}_version/v/}\""
    eval "${progname}_version_fallback=\"\${${progname}_version_fallback/v/}\""
}
# Specification of software versions.
# The rightmost column are fallbacks, which will be used if the
# link to the version given by the middle column is broken.
# In case of CO𝘕CEPT and CLASS, possible versions are the corresponding
# GitHub branches and releases.
concept_version_specified="False"
if [ -n "${concept_version}" ]; then
    concept_version_specified="True"
fi
set_version "concept"           "1.0.1"
set_version "blas"              "0.3.18"  "0.3.18"
set_version "class"             "2.7.2"
set_version "fftw"              "3.3.10"  "3.3.10"
set_version "fftw_for_gadget"   "2.1.5"   "2.1.5"   # Do not change
set_version "freetype"          "2.11.1"  "2.11.1"
set_version "gadget"            "2.0.7"             # Do not change
set_version "gsl"               "2.7"     "2.7"
set_version "hdf5"              "1.12.1"
set_version "libffi"            "3.4.2"   "3.3"
if [ "${mpi}" == "mpich" ]; then
    set_version "mpi"           "3.4.2"   "3.4.2"
elif [ "${mpi}" == "openmpi" ]; then
    set_version "mpi"           "4.1.2"
fi
set_version "ncurses"           "6.3"     "6.3"
set_version "openssl"           "3.0.0"   "1.1.1k"
set_version "perl"              "5.34.0"
set_version "python"            "3.9.9"
set_version "zlib"              "1.2.11"  "1.2.11"
# Python packages
set_version "blessings"         "1.7"
set_version "cython"            "0.29.24"
set_version "cythongsl"         "0.2.2"
set_version "h5py"              "3.6.0"
set_version "matplotlib"        "3.5.0"
set_version "mpi4py"            "3.1.3"
set_version "numpy"             "1.21.4"
set_version "pip"               "21.3.1"
set_version "scipy"             "1.7.3"
set_version "setuptools"        "59.5.0"
set_version "sphinx"            "4.3.1"
set_version "sphinx_copybutton" "0.4.0"
set_version "sphinx_rtd_theme"  "1.0.0"
set_version "sphinx_tabs"       "3.2.0"
set_version "wheel"             "0.37.0"
# Note that the versions may be changed further down due to known
# compatibility issues between specific versions of the above programs
# and specific versions of system dependencies.



#################
# Initial setup #
#################
# Set up error trapping
ctrl_c() {
    current_step="aborting"
    sleep 0.5
    kill -9 -- -$$ > /dev/null 2>&1 || :
    exit 2
}
abort() {
    sleep 0.5
    kill -9 -- -$$ > /dev/null 2>&1 || :
    exit 1
}
trap 'ctrl_c' SIGINT
trap 'abort' EXIT
set -e

# Set sleep_time, the amount of seconds spend sleeping at various stages
if [ -z "${sleep_time}" ]; then
    sleep_time=10
fi

# For the terminal to be able to print Unicode characters correctly,
# we need to use a UTF-8 locale.
set_locale() {
    # This function will set the locale through the LC_ALL and LANG
    # environment variables. We want to use a supported UTF-8 locale.
    # The preference order is as follows:
    #   en_US.UTF-8
    #   en_*.UTF-8
    #   C.UTF-8
    #   POSIX.UTF-8
    #   *.UTF-8
    # We consider the suffix (UTF-8) valid regardless of the case and
    # presence of the dash.
    # Get all available locals.
    locales="$(locale -a 2>/dev/null || :)"
    if [ -z "${locales}" ]; then
        return
    fi
    # Look for available UTF-8 locale
    for prefix in "en_US" "en_*" "C" "POSIX" "*"; do
        for suffix in "UTF-8" "UTF8" "utf-8" "utf8"; do
            pattern="${prefix}.${suffix}"
            for loc in ${locales}; do
                if [[ "${loc}" == ${pattern} ]]; then
                    export LC_ALL="${loc}"
                    export LANG="${loc}"
                    return
                fi
            done
        done
    done
}
set_locale
# Set the terminal if unset or broken
if [ -z "${TERM}" ] || [ "${TERM}" == "dumb" ]; then
    export TERM="linux"
fi

# ANSI/VT100 escape sequences
esc="\x1b"
# Text formatting
esc_normal="${esc}[0m"
esc_bold="${esc}[1m"
esc_italic="${esc}[3m"
esc_reverted="${esc}[7m"
esc_no_italic="${esc}[23m"
# The name of the program, nicely typeset
if [ -z "${esc_concept}" ]; then
    esc_concept="CO${esc_italic}N${esc_no_italic}CEPT"
else
    esc_concept="${esc_concept//\$\{esc_italic\}/${esc_italic}}"
    esc_concept="${esc_concept//\$\{esc_no_italic\}/${esc_no_italic}}"
fi
# Text colours
esc_red="${esc}[91m"
esc_green="${esc}[92m"
esc_yellow="${esc}[93m"
esc_blue="${esc}[94m"
# Cursor movement
esc_up="${esc}[1A"
esc_erase="${esc}[K"
# Special characters
en_quad="\xE2\x80\x80"
# Functions for pretty printing text
heading() {
    printf "\n${esc_bold}${esc_yellow}${1}${esc_normal}\n"
}
error() {
    printf "\n${esc_bold}${esc_red}${1}${esc_normal}\n\n" >&2
}

# Print out welcome message
if [ "${say_welcome}" != "False" ]; then
    printf "\n${esc_bold}This is the installation script for ${esc_concept},
the cosmological ${esc_italic}N${esc_no_italic}-body code in Python${esc_normal}\n"
fi

# Status control sequences
status="initialization"
status_prefix="__new_status__="
status_prefix_length=${#status_prefix}
status_disable="disable"
status_enable="enable"
status_on="on"
status_off="off"
status_visible="${status_on}"
status_finish_successfully="finish_successfully"
status_installpid="installpid="
status_setvar="setvar:"

# Set test_success variables
blas_test_success="True"
class_test_success="True"
concept_test_success="True"
fftw_test_success="True"
fftw_for_gadget_test_success="True"
freetype_test_success="True"
gadget_test_success="True"
gsl_test_success="True"
hdf5_test_success="True"
libffi_test_success="True"
mpi_test_success="True"
ncurses_test_success="True"
openssl_test_success="True"
perl_test_success="True"
python_test_success="True"
zlib_test_success="True"
numpy_test_success="True"
scipy_test_success="True"

# Read in command-line arguments
if [ -z "${do_tests}" ]; then
    do_tests="False"
fi
if [ -z "${yes_to_defaults}" ]; then
    yes_to_defaults="False"
fi
if [ -z "${fix_ssh}" ]; then
    fix_ssh="False"
fi
if [ -z "${slim}" ]; then
    slim="False"
fi
if [ -z "${concept_dir_specified}" ]; then
    concept_dir_specified="False"
fi
for var in "$@"; do
    # Strip command-line argument for brackets, which may have
    # been added by users not familiar with this syntax for
    # specifying optional arguments.
    var="${var//\[/}"
    var="${var//\]/}"
    # Parse command-line argument
    if     [ "${var}" ==  "-t"     ] \
        || [ "${var}" == "--t"     ] \
        || [ "${var}" == "--te"    ] \
        || [ "${var}" == "--tes"   ] \
        || [ "${var}" == "--test"  ] \
        || [ "${var}" == "--tests" ] \
    ; then
        do_tests="True"
    elif   [ "${var}" ==  "-y"               ] \
        || [ "${var}" == "--y"               ] \
        || [ "${var}" == "--ye"              ] \
        || [ "${var}" == "--yes"             ] \
        || [ "${var}" == "--yes-"            ] \
        || [ "${var}" == "--yes-t"           ] \
        || [ "${var}" == "--yes-to"          ] \
        || [ "${var}" == "--yes-to-"         ] \
        || [ "${var}" == "--yes-to-d"        ] \
        || [ "${var}" == "--yes-to-de"       ] \
        || [ "${var}" == "--yes-to-def"      ] \
        || [ "${var}" == "--yes-to-defa"     ] \
        || [ "${var}" == "--yes-to-defau"    ] \
        || [ "${var}" == "--yes-to-defaul"   ] \
        || [ "${var}" == "--yes-to-default"  ] \
        || [ "${var}" == "--yes-to-defaults" ] \
    ; then
        yes_to_defaults="True"
    elif   [ "${var}" == "--f"       ] \
        || [ "${var}" == "--fi"      ] \
        || [ "${var}" == "--fix"     ] \
        || [ "${var}" == "--fix-"    ] \
        || [ "${var}" == "--fix-s"   ] \
        || [ "${var}" == "--fix-ss"  ] \
        || [ "${var}" == "--fix-ssh" ] \
    ; then
        fix_ssh="True"
    elif   [ "${var}" == "--s"                    ] \
        || [ "${var}" == "--sl"                   ] \
        || [ "${var}" == "--sli"                  ] \
        || [ "${var}" == "--slim"                 ] \
    ; then
        slim="True"
    elif [ "${var}" == "--fast" ]; then
        # This is a deprecated option for skipping tests,
        # which is now the default. Allow it but do nothing.
        :
    elif [ "${concept_dir_specified}" == "False" ]; then
        concept_dir="${var}"
        concept_dir_specified="True"
    else
        if [ "${var}" != "${concept_dir}" ]; then
            error "Got command-line argument \"${var}\", "\
"but the installation path is already set to \"${concept_dir}\""
            exit 1
        fi
    fi
done

# Changes to initial environment variables due to command-line arguments
if [ "${slim}" == "True" ]; then
    export CFLAGS="${CFLAGS} -g0"
    export CXXFLAGS="${CXXFLAGS} -g0"
    export LDFLAGS="${LDFLAGS} -Wl,-s"
fi

# Backup of initial environment variables
env_var_names=(     \
    BLAS            \
    CC              \
    CFLAGS          \
    CPPFLAGS        \
    CXX             \
    CXXFLAGS        \
    F77             \
    F90             \
    F9X             \
    FC              \
    FCFLAGS         \
    FFLAGS          \
    HDF5_DIR        \
    HDF5_MPI        \
    LAPACK          \
    LD_LIBRARY_PATH \
    LD_PRELOAD      \
    LDFLAGS         \
    LIBS            \
    MPICC           \
    MPILIBS         \
    MPLSETUPCFG     \
    PATH            \
    PERL            \
    PKG_CONFIG_PATH \
    TEMP            \
    TMP             \
    TMPDIR          \
)
for env_var_name in "${env_var_names[@]}"; do
    # Save initial state (set/unset) of the environment variable
    if [ -n "$(eval "echo "\${${env_var_name}+x}"")" ]; then
        eval "${env_var_name}_set=\"True\""
    else
        eval "${env_var_name}_set=\"False\""
    fi
    # Save initial value of the environment variable
    eval "${env_var_name}_backup=\"\${${env_var_name}}\""
done
# Function that resets all above environment
# variables to their initial state.
reset_environment() {
    for env_var_name in "${env_var_names[@]}"; do
        eval "env_var_set=\"\${${env_var_name}_set}\""
        if [ "${env_var_set}" == "True" ]; then
            # env_var_name initially set
            eval "export ${env_var_name}=\"\${${env_var_name}_backup}\""
        else
            # env_var_name initially unset
            unset "${env_var_name}"
        fi
    done
}

# Function for converting a path to its absolute form
initial_dir="$(pwd)"  # It is crucial that this line is before any cd
convert_to_abs_path() {
    # Arguments: path
    current_dir="$(pwd)"
    cd "${initial_dir}"
    # Places backslashes before spaces.
    # These are needed when expanding tilde, but they will not persist.
    abs_path="${1// /\\ }"
    # Expand tilde
    eval abs_path="${abs_path}"
    # Convert to absolute path
    abs_path=$(readlink -m "${abs_path}")
    cd "${current_dir}"
    echo "${abs_path}"
}

# Setup password-less SSH login between nodes (and exit), if requested
if [ "${fix_ssh}" == "True" ]; then
    # Move the pre-existing ~/.ssh directory into a directory
    # ~/.ssh_backup/<date>,
    # with <date> the current time.
    if [ -d ~/".ssh" ]; then
        passwordless_ssh_timestamp="$(date)"
        passwordless_ssh_timestamp="${passwordless_ssh_timestamp// /-}"
        passwordless_ssh_backup_dir="$(convert_to_abs_path \
            "~/.ssh_backup/${passwordless_ssh_timestamp}")"
        mkdir -p ~/".ssh_backup/${passwordless_ssh_timestamp}"
        mv ~/".ssh" ~/".ssh_backup/${passwordless_ssh_timestamp}/"
        echo "The existing ~/.ssh directory has been moved to ${passwordless_ssh_backup_dir}/.ssh"
    fi
    mkdir -p ~/".ssh"
    # The type of encryption to use for the ssh keys.
    # Should be "dsa" or "rsa".
    key_type="rsa"
    # Generate a public/private key pair
    ssh-keygen -t "${key_type}" -N "" -f ~/".ssh/id_${key_type}" >/dev/null
    # Add public key to the list of keys allowed to log in
    cat ~/".ssh/id_${key_type}.pub" >> ~/".ssh/authorized_keys"
    cat ~/".ssh/id_${key_type}.pub" >> ~/".ssh/authorized_keys2"
    # Suppress future confirmation dialogues
    echo "Host *
  StrictHostKeyChecking no
  UserKnownHostsFile /dev/null
  LogLevel ERROR
" >> ~/".ssh/config"
    # Remove any previously known hosts (there should be none
    # as the ~/.ssh directory has just been created).
    rm -f "known_hosts"* 2>/dev/null || :
    # Set proper permissions in order for ssh
    # to allow password-less login.
    chmod go-w ~
    chmod 700 ~/".ssh"
    chmod 644 ~/".ssh/authorized_keys"
    chmod 644 ~/".ssh/authorized_keys2"
    chmod go-rwx ~/".ssh/config" || :
    chmod go-rwx ~/".ssh/id_${key_type}"
    chmod go+r ~/".ssh/id_${key_type}.pub"
    # Inform the user on this change
    printf "\nPassword-less ssh login between nodes has been configured\n"
    # Do not install CO𝘕CEPT
    trap : 0
    exit 0
fi

# Function which prints the absolute path of a given command.
# If the command is not an executable file on the PATH but instead a
# known function, the input command is printed as is. If the command
# cannot be found at all, nothing is printed and an exit code of 1
# is returned.
get_command() {
    command_name="${1}"
    # Use the type built-in to locate the command
    command_path="$(type "${command_name}" 2>/dev/null || :)"
    command_path="${command_path##* }"
    if [[ "${command_path}" == "/"* ]]; then
        # The command is a path
        command_path="$(readlink -f "${command_path}")"
        echo "${command_path}"
        return 0
    elif [ -n "${command_path}" ]; then
        # The command exists as a function
        echo "${command_name}"
        return 0
    fi
    # The command does not exist
    return 1
}

# Creating top-level directory (concept_dir)
current_step="setup of top-level directory"
set_concept_files() {
    files=(             \
        ".env"          \
        ".dockerignore" \
        ".github"       \
        ".gitignore"    \
        ".path"         \
        "Dockerfile"    \
        "Makefile"      \
        "concept"       \
        "doc"           \
        "install"       \
        "param"         \
        "src"           \
        "test"          \
        "util"          \
    )
    if [ "${slim}" != "True" ]; then
         files=("${files[@]}" "CHANGELOG.md" "LICENSE" "README.md")
    fi
}
if [ "${concept_dir_specified}" == "False" ]; then
    printf "\nYou must now specify an installation directory for ${esc_concept}"
    if [ -n "${HOME}" ] && [ -d "${HOME}" ] && [ ! -d "${HOME}/concept" ]; then
        concept_dir_suggestion="${HOME}/concept"
        printf ", e.g.\n${concept_dir_suggestion}"
    else
        printf "."
    fi
    concept_dir=""
    while [ -z "${concept_dir}" ]; do
        printf "\nWhere should ${esc_concept} be installed?\n"
        read -p "> " concept_dir
        if [ -n "${concept_dir}" ]; then
            break
        fi
    done
fi
concept_dir="$(convert_to_abs_path "${concept_dir}")"
if [ "${concept_dir_specified}" == "False" ]; then
    concept_dir_reasonable="False"
    if [ "${concept_dir}" == "${HOME}" ]; then
        printf "\nYou have specified your home directory \"${HOME}\" for the installation path.\n"
    elif [ "${concept_dir}" == "${HOME}/Desktop" ]; then
        printf "\nYou have specified your desktop \"${HOME}/Desktop\" for the installation path.\n"
    elif [ "${concept_dir}" == "/home" ]; then
        printf "\nYou have specified the \"/home\" directory for the installation path.\n"
    elif [ "${concept_dir}" == "/" ]; then
        printf "\nYou have specified the root directory \"/\" for the installation path.\n"
    elif [ "${concept_dir}" == "/root" ]; then
        printf "\nYou have specified the \"/root\" directory for the installation path.\n"
    else
        if [ -d "${concept_dir}" ]; then
            if [ -z "$(ls -A "${concept_dir}")" ]; then
                concept_dir_reasonable="True"
            else
                set_concept_files
                for f in "${files[@]}"; do
                    f="${concept_dir}/${f}"
                    if [ -f "${f}" ] || [ -d "${f}" ]; then
                        concept_dir_reasonable="True"
                        break
                    fi
                done
            fi
        else
            concept_dir_reasonable="True"
        fi
        if [ "${concept_dir_reasonable}" == "False" ]; then
            printf "\nYou have specified the non-empty \"${concept_dir}\" directory \
for the installation path.\n"
        fi
    fi
    if [ "${concept_dir_reasonable}" == "False" ]; then
        concept_dir_suggestion="$(convert_to_abs_path "${concept_dir}/concept")"
        printf "You should probably change the installation path to a subdirectory within \
this directory — e.g. \"${concept_dir_suggestion}\" — so that ${esc_concept} is fully contained \
within a dedicated directory (to abort the installation, press Ctrl+C).\n"
        while :; do
            read -p "Change installation path to \"${concept_dir_suggestion}\"? [Y/n] " yn
            case "${yn}" in
                [Yy]*)
                    concept_dir="${concept_dir_suggestion}"
                    break
                    ;;
                [Nn]*)
                    break
                    ;;
                "")
                    concept_dir="${concept_dir_suggestion}"
                    break
                    ;;
                *)
                    ;;
            esac
        done
    fi
fi
concept_dir="$(convert_to_abs_path "${concept_dir}")"
concept_dir_is_sane="True"
mkdir -p "${concept_dir}" 2>/dev/null || concept_dir_is_sane="False"
if [ "${concept_dir_is_sane}" == "False" ]; then
    error "\nThe installation path \"${concept_dir}\" cannot be created."
    exit 1
fi
cd "${concept_dir}"

# Print out values of common installation options
heading "Installation options"
echo "Path               \"${concept_dir}\""
if [[ "${mpi_dir}" == "__concept_dir__"* ]]; then
    echo "MPI                Dedicated ${mpi_formatted}"
else
    if [ "${mpi_formatted}" == "unknown" ]; then
        echo "MPI                \"${mpi_dir}\""
    else
        echo "MPI                \"${mpi_dir}\" (${mpi_formatted})"
    fi
fi
echo "Slim installation  ${slim}"
echo "Yes to defaults    ${yes_to_defaults}"
echo "Tests              ${do_tests}"
if [ "${concept_dir_reasonable}" == "False" ]; then
    sleep 2
fi

# Replace "__concept_dir__" with the user specified concept_dir
# within the path to the tmp directory and the log file.
tmp_dir="${tmp_dir/__concept_dir__/${concept_dir}}"
log="${log/__concept_dir__/${concept_dir}}"
# Create the tmp directory.
# This will not be removed until the end,
# and here only if it is empty.
mkdir -p "${tmp_dir}"

# Check for another installation that is already running
if [ "${check_other_running_installation}" != "False" ] && [ -f "${log}" ]; then
    installpid_line=""
    while read logline; do  # we really want to 'grep', but this might not (yet) be installed
        if [[ "${logline}" == "${status_prefix}${status_installpid}"* ]]; then
            installpid_line="${logline}"
        fi
    done <<< "$(cat "${log}")"
    installpid_old=""
    if [ -n "${installpid_line}" ]; then
        installpid_old="${installpid_line#*=}"
        installpid_old="${installpid_old#*=}"
    fi
    if     [   -n "${installpid_old}"            ] \
        && [ 0 -le ${installpid_old} 2>/dev/null ] \
        && kill -0 ${installpid_old} 2>/dev/null   \
    ; then
        # Other installation detected
        printf "\nAnother installation is still running.\n"
        printf "We should kill this other installation if we wish to start anew."
        if [ "${yes_to_defaults}" == "True" ]; then
            printf "\nKilling other installation\n"
            kill ${installpid_old} || :
            wait ${installpid_old} >/dev/null 2>&1 || :
            echo "Other installation killed"
        else
            while :; do
                printf "
How to proceed?
  0) Kill other installation and continue with this one
  1) Abort this installation
  2) Abort both installations
  3) Continue both installations (not recommended)
: "
                read answer
                answer="${answer//(/}"
                answer="${answer//)/}"
                case "${answer}" in
                    0)
                        echo "Killing other installation"
                        kill ${installpid_old} || :
                        wait ${installpid_old} >/dev/null 2>&1 || :
                        echo "Other installation killed"
                        break
                        ;;
                    1)
                        echo "Aborting"
                        trap : 0
                        exit 0
                        ;;
                    2)
                        echo "Killing other installation"
                        kill ${installpid_old} || :
                        wait ${installpid_old} >/dev/null 2>&1 || :
                        echo "Other installation killed"
                        echo "Aborting"
                        trap : 0
                        exit 0
                        ;;
                    3)
                        echo "Continuing regardless"
                        break
                        ;;
                    *)
                        ;;
                esac
            done
        fi
    fi
fi

# This function should be called before any use of sudo and will cache
# the root password to the sudo_command variable. After this, instead of
# involving sudo, invoke ${sudo_command} (using eval). This way, the root
# password has to be entered at most once.
sudo_func_built="False"
build_sudo_func() {
    if [ "${sudo_func_built}" == "True" ]; then
        return
    fi
    sudo_command_only="False"
    if [ "$1" == "sudo_command_only" ]; then
        sudo_command_only="True"
    fi
    if [ "${sudo_command_only}" == "False" ]; then
        sudo_func_built="True"
    fi
    # If root, no sudo/su is needed
    if [ "${EUID}" == "0" ]; then
        sudo_func() {
            eval "$@"
        }
        sudo_command() {
            echo "$@"
        }
        return
    fi
    # Check for sudo and su command
    sudo_exist="False"
    if get_command "sudo" >/dev/null; then
        sudo_exist="True"
    fi
    su_exist="False"
    if get_command "su" >/dev/null; then
        su_exist="True"
    fi
    if [ "${sudo_exist}" == "False" ] && [ "${su_exist}" == "False" ]; then
        # Neither the sudo nor the su command exist.
        # Assume root privileges by default.
        sudo_func() {
            eval "$@"
        }
        sudo_command() {
            echo "$@"
        }
        return
    fi
    # Invalidate sudo timestamp
    if [ "${sudo_exist}" == "True" ]; then
        sudo -k
    fi
    # Check if sudo/su run without a password
    if [ "${sudo_exist}" == "True" ]; then
        output="$(echo '' | sudo -S echo 'hello' 2>/dev/null || :)"
        if [ "${output##* }" == "hello" ]; then
            sudo_func() {
                args="$@"
                sudo ${args}
            }
            sudo_command() {
                echo "sudo $@"
            }
            return
        fi
    fi
    if [ "${su_exist}" == "True" ]; then
        output="$(echo '' | su -c 'echo hello' 2>/dev/null || :)"
        if [ "${output##* }" == "hello" ]; then
            sudo_func() {
                args="$@"
                su -c "${args}"
            }
            sudo_command() {
                echo "su -c '$@'"
            }
            return
        fi
    fi
    # If we only need to build the sudo command, do so now and return
    if [ "${sudo_command_only}" == "True" ]; then
        if [ "${sudo_exist}" == "True" ]; then
            sudo_command() {
                echo "sudo $@"
            }
        elif [ "${su_exist}" == "True" ]; then
            sudo_command() {
                echo "su -c '$@'"
            }
        else
            sudo_command() {
                echo "$@"
            }
        fi
        return
    fi
    # Prompt for password and try out sudo and/or su
    first_prompt="True"
    while :; do
        if [ "${first_prompt}" == "False" ] || [ -z "${root_password}" ]; then
            read -s -p "[sudo] password for $(whoami): " root_password
            echo
        fi
        first_prompt="False"
        # Try out sudo
        if [ "${sudo_exist}" == "True" ]; then
            output="$(echo "${root_password}" | sudo -S echo hello 2>/dev/null || :)"
            if [ "${output##* }" == "hello" ]; then
                sudo_func() {
                    args="$@"
                    echo "${root_password}" | sudo -S ${args}
                }
                sudo_command() {
                    echo "sudo $@"
                }
                return
            fi
        fi
        # Try out su
        if [ "${su_exist}" == "True" ]; then
            output="$(echo "${root_password}" | su -c 'echo hello' 2>/dev/null || :)"
            if [ "${output##* }" == "hello" ]; then
                sudo_func() {
                    args="$@"
                    echo "${root_password}" | su -c "${args}"
                }
                sudo_command() {
                    echo "su -c '$@'"
                }
                return
            fi
        fi
        echo "Sorry, try again."
    done
}

# This directory may be created by the fix_path(), use_mpi_compilers() or
# use_specified_mpi_compilers() functions, which use it to store symlinks
# to MPI library files.
mpi_symlinkdir="${concept_dir}/dep/.mpi_symlinks"

# Check whether system dependencies are installed and located on PATH
current_step="check for pre-installed system dependencies"
# Check for package manager and set package names
set_package_names() {
    # Arguments: Package name for awk, gcc, g++, gfortran, grep, gzip,
    # make, sed, tar, wget, glibc, as and ld, Linux headers.
    i=0
    for package in      \
        "awk"           \
        "gcc"           \
        "gxx"           \
        "gfortran"      \
        "grep"          \
        "gzip"          \
        "make"          \
        "sed"           \
        "tar"           \
        "wget"          \
        "glibc"         \
        "as_ld"         \
        "linux_headers" \
    ; do
        ((i += 1))
        eval "${package}_package=\${${i}}"
    done
}
set_package_manager_and_names() {
    # This function takes no arguments
    update_command=""
    package_manager=""
    for pmanager in \
        "apt-get"   \
        "apt"       \
        "aptitude"  \
        "dnf"       \
        "yum"       \
        "zypper"    \
        "urpmi"     \
        "pacman"    \
        "eopkg"     \
        "emerge"    \
        "slackpkg"  \
        "apk"       \
    ; do
        if get_command "${pmanager}" >/dev/null; then
            # Package manager found
            package_manager="${pmanager}"
            # Package names
            case "${package_manager}" in
                "apt-get")
                    install_command="${package_manager} -y install --no-install-recommends"
                    update_command="${package_manager} update"
                    set_package_names               \
                        "gawk"                      \
                        "gcc"                       \
                        "g++"                       \
                        "gfortran"                  \
                        "grep"                      \
                        "gzip"                      \
                        "make"                      \
                        "sed"                       \
                        "tar"                       \
                        "wget"                      \
                        "libc6 libc6-dev"           \
                        "binutils"                  \
                        "linux-headers-$(uname -r)"
                    break
                    ;;
                "apt")
                    install_command="${package_manager} install -y --no-install-recommends"
                    update_command="${package_manager} update"
                    set_package_names               \
                        "gawk"                      \
                        "gcc"                       \
                        "g++"                       \
                        "gfortran"                  \
                        "grep"                      \
                        "gzip"                      \
                        "make"                      \
                        "sed"                       \
                        "tar"                       \
                        "wget"                      \
                        "libc6 libc6-dev"           \
                        "binutils"                  \
                        "linux-headers-$(uname -r)"
                    break
                    ;;
                "aptitude")
                    install_command="${package_manager} -y install"
                    update_command="${package_manager} update"
                    set_package_names               \
                        "gawk"                      \
                        "gcc"                       \
                        "g++"                       \
                        "gfortran"                  \
                        "grep"                      \
                        "gzip"                      \
                        "make"                      \
                        "sed"                       \
                        "tar"                       \
                        "wget"                      \
                        "libc6 libc6-dev"           \
                        "binutils"                  \
                        "linux-headers-$(uname -r)"
                    break
                    ;;
                "dnf")
                    install_command="${package_manager} -y install"
                    set_package_names       \
                        "gawk"              \
                        "gcc"               \
                        "gcc-c++"           \
                        "gcc-gfortran"      \
                        "grep"              \
                        "gzip"              \
                        "make"              \
                        "sed"               \
                        "tar"               \
                        "wget"              \
                        "glibc glibc-devel" \
                        "binutils"          \
                        "kernel-headers"
                    break
                    ;;
                "yum")
                    install_command="${package_manager} -y install"
                    set_package_names       \
                        "gawk"              \
                        "gcc"               \
                        "gcc-c++"           \
                        "gcc-gfortran"      \
                        "grep"              \
                        "gzip"              \
                        "make"              \
                        "sed"               \
                        "tar"               \
                        "wget"              \
                        "glibc glibc-devel" \
                        "binutils"          \
                        "kernel-headers"
                    break
                    ;;
                "zypper")
                    install_command="${package_manager} -n install"
                    set_package_names          \
                        "gawk"                 \
                        "gcc"                  \
                        "gcc-c++"              \
                        "gcc-fortran"          \
                        "grep"                 \
                        "gzip"                 \
                        "make"                 \
                        "sed"                  \
                        "tar"                  \
                        "wget"                 \
                        "glibc glibc-devel"    \
                        "binutils"             \
                        "linux-kernel-headers"
                    break
                    ;;
                "urpmi")
                    install_command="${package_manager} --auto"
                    set_package_names              \
                        "gawk"                     \
                        "gcc"                      \
                        "gcc-c++"                  \
                        "gcc-gfortran"             \
                        "grep"                     \
                        "gzip"                     \
                        "make"                     \
                        "sed"                      \
                        "tar"                      \
                        "wget"                     \
                        "glibc glibc-devel"        \
                        "binutils"                 \
                        "kernel-userspace-headers"
                    break
                    ;;
                "pacman")
                    install_command="${package_manager} -S --noconfirm"
                    update_command="${package_manager} -Sy"
                    set_package_names   \
                        "gawk"          \
                        "gcc"           \
                        "gcc"           \
                        "gcc-fortran"   \
                        "grep"          \
                        "gzip"          \
                        "make"          \
                        "sed"           \
                        "tar"           \
                        "wget"          \
                        "glibc"         \
                        "binutils"      \
                        "linux-headers"
                    break
                    ;;
                "eopkg")
                    install_command="${package_manager} install -y"
                    set_package_names       \
                        "gawk"              \
                        "gcc"               \
                        "g++"               \
                        "gfortran"          \
                        "grep"              \
                        "gzip"              \
                        "make"              \
                        "sed"               \
                        "tar"               \
                        "wget"              \
                        "glibc glibc-devel" \
                        "binutils"          \
                        "linux-headers"
                    break
                    ;;
                "emerge")
                    install_command="${package_manager}"
                    set_package_names       \
                        "gawk"              \
                        "gcc"               \
                        "gcc"               \
                        "fortran"           \
                        "grep"              \
                        "gzip"              \
                        "make"              \
                        "sed"               \
                        "tar"               \
                        "wget"              \
                        "glibc"             \
                        "binutils"          \
                        "linux-headers"
                    break
                    ;;
                "slackpkg")
                    install_command="${package_manager} install"
                    set_package_names       \
                        "gawk"              \
                        "gcc"               \
                        "gcc-g++"           \
                        "gcc-gfortran"      \
                        "grep"              \
                        "gzip"              \
                        "make"              \
                        "sed"               \
                        "tar"               \
                        "wget"              \
                        "glibc"             \
                        "binutils"          \
                        "kernel-headers"
                    break
                    ;;
                "apk")
                    install_command="${package_manager} add"
                    set_package_names         \
                        "gawk"                \
                        "gcc"                 \
                        "g++"                 \
                        "gfortran"            \
                        "grep"                \
                        "gzip"                \
                        "make"                \
                        "sed"                 \
                        "tar"                 \
                        "wget"                \
                        "libc-utils libc-dev" \
                        "binutils"            \
                        "linux-headers"
                    break
                    ;;
            esac
            break
        fi
    done
}
set_package_manager_and_names
# Function for testing whether system dependencies are installed and
# located on PATH. For missing system dependencies, it will attempt to
# figure out the command to install it.
check_system_dependency() {
    # Arguments: Command, package name
    if ! get_command "${1}" >/dev/null; then
        # Package not installed
        if [ -n "${package_manager}" ]; then
            # Package manager found
            if [ "${yes_to_defaults}" == "True" ]; then
                printf "\nAuto installing '$1'\n"
                build_sudo_func
                if [ -n "${update_command}" ]; then
                    sudo_func ${update_command} || :
                    update_command=""
                fi
                sudo_func ${install_command} $2
                echo "$1 successfully installed"
            else
                build_sudo_func "sudo_command_only"
                printf "\nCould not find '$1'\n"
                echo "You can install it by typing:"
                if [ -n "${update_command}" ]; then
                    printf "$(sudo_command ${update_command}); "
                fi
                sudo_command ${install_command} $2
                while :; do
                    read -p "Run above command now? [Y/n] " yn
                    case "${yn}" in
                        [Yy]*)
                            build_sudo_func
                            if [ -n "${update_command}" ]; then
                                sudo_func ${update_command} || :
                                update_command=""
                            fi
                            sudo_func ${install_command} $2
                            echo "$1 successfully installed"
                            return
                            ;;
                        [Nn]*)
                            error "Terminated install due to missing component '${1}'"
                            exit 1
                            ;;
                        "")
                            build_sudo_func
                            if [ -n "${update_command}" ]; then
                                sudo_func ${update_command} || :
                                update_command=""
                            fi
                            sudo_func ${install_command} $2
                            echo "$1 successfully installed"
                            return
                            ;;
                        *)
                            error "Terminated install due to missing component '${1}'"
                            exit 1
                            ;;
                    esac
                done
                exit 1
            fi
        else
            # No package manager found
            error "Error: Could not find '${1}'"
            exit 1
        fi
    fi
}
check_system_dependency "awk"      "${awk_package}"
check_system_dependency "gcc"      "${gcc_package}"
check_system_dependency "g++"      "${gxx_package}"
check_system_dependency "gfortran" "${gfortran_package}"
check_system_dependency "grep"     "${grep_package}"
check_system_dependency "gzip"     "${gzip_package}"
check_system_dependency "make"     "${make_package}"
check_system_dependency "sed"      "${sed_package}"
check_system_dependency "tar"      "${tar_package}"
check_system_dependency "wget"     "${wget_package}"

# Though gcc is now guaranteed to be installed,
# it may miss important components, which we check for here.
current_step="check of gcc components"
gcc_test() {
    # Arguments:
    #   - Name of gcc component
    #   - C source code to test
    #   - Expected output
    #   - Text to write if fail
    #   - Name of package to install if fail
    name="$1"
    C_source="$2"
    expected_output="$3"
    message="$4"
    package_name="$5"
    # Prepare for gcc test
    current_dir="$(pwd)"
    gcc_test_dir="${tmp_dir}/gcc_test"
    # Test compile and run
    for i in 0 1; do
        # Cleanup
        cd "${current_dir}"
        rm -rf "${gcc_test_dir}" || :
        mkdir -p "${gcc_test_dir}"
        # Write C source to file
        cd "${gcc_test_dir}"
        echo "${C_source}" > main.c
        # Compile
        gcc_test_success="True"
        gcc main.c -o main >/dev/null 2>&1 || gcc_test_success="False"
        if [ "${gcc_test_success}" == "True" ]; then
            # Run
            gcc_test_output="$(./main 2>&1)"
            if [ "${gcc_test_output}" != "${expected_output}" ]; then
                gcc_test_success="False"
            fi
        fi
        if [ "${gcc_test_success}" == "False" ]; then
            if [ $i -eq 0 ]; then
                # Test failed.
                # Prompt for installation of needed package.
                echo
                echo "${message}"
                if [ -z "${package_manager}" ]; then
                    # No package manager found
                    error "Error: Could not find any installed package manager"
                    exit 1
                fi
                if [ "${yes_to_defaults}" == "True" ]; then
                    echo "Auto installing ${name}"
                    build_sudo_func
                    if [ -n "${update_command}" ]; then
                        sudo_func ${update_command} || :
                        update_command=""
                    fi
                    sudo_func ${install_command} ${package_name}
                else
                    build_sudo_func "sudo_command_only"
                    echo "To ensure that ${name} are installed, type:"
                    if [ -n "${update_command}" ]; then
                        printf "$(sudo_command ${update_command}); "
                    fi
                    sudo_command ${install_command} ${package_name}
                    gcc_test_prompt() {
                        while :; do
                            read -p "Run above command now? [Y/n] " yn
                            case "${yn}" in
                                [Yy]*)
                                    build_sudo_func
                                    if [ -n "${update_command}" ]; then
                                        sudo_func ${update_command} || :
                                        update_command=""
                                    fi
                                    sudo_func ${install_command} ${package_name}
                                    return
                                    ;;
                                [Nn]*)
                                    error "Terminated install due to missing component: ${name}"
                                    exit 1
                                    ;;
                                "")
                                    build_sudo_func
                                    if [ -n "${update_command}" ]; then
                                        sudo_func ${update_command} || :
                                        update_command=""
                                    fi
                                    sudo_func ${install_command} ${package_name}
                                    return
                                    ;;
                                *)
                                    error "Terminated install due to missing component: ${name}"
                                    exit 1
                                    ;;
                            esac
                        done
                        exit 1
                    }
                    gcc_test_prompt
                fi
                echo "${name} successfully installed"
            else
                # Test failed even after installing the needed package
                error "Terminated install due to gcc failing to \
properly compile \"${gcc_test_dir}/main.c\""
                exit 1
            fi
        fi
    done
    # Cleanup after test
    cd "${current_dir}"
    rm -rf "${gcc_test_dir}" || :
}
# Basic gcc test, checking for the standard library,
# the assembler and linker.
gcc_test                                                \
    "the gcc C standard library, assembler and linker"  \
    '
#include <stdio.h>
int main(void){
    printf("hello\n");
    return 0;
}
'                                                       \
    "hello"                                             \
    "gcc could not compile even a simple C program. \
We need to make sure that the gcc C standard library, \
as well as the assembler and linker are all installed." \
    "${glibc_package} ${as_ld_package}"
# Check for the Linux headers
gcc_test                                                \
    "the Linux headers"  \
    '
#include <linux/limits.h>
#include <stdio.h>
int main(void){
    printf("hello\n");
    return 0;
}
'                                                       \
    "hello"                                             \
    "gcc could not find the Linux headers. \
We need to make sure that these are installed."         \
    "${linux_headers_package}"

# Change default versions if they are known not to work
# with the present versions of the system dependencies.
:

# Function which finds files deep inside a directory tree
# (like the GNU find command).
find_recursive() {
    # Arguments: Absolute path to directory,
    # file/directory to find,
    # [type of file to find: "-f" for file (default),
    #  "-d" for directory].
    local dirname="$1"
    local filename="$2"
    local fd="$3"
    if [ -z "${fd}" ]; then
        fd="-f"
    fi
    # Change directory
    local current_dir="$4"
    local primary_call="False"
    if [ -z "${current_dir}" ]; then
        # This is the primary call to this function
        primary_call="True"
        current_dir="$(pwd)"
        found_results=()
    fi
    dirname="$(convert_to_abs_path "${dirname}")"
    if [ ! -d "${dirname}" ]; then
        return
    fi
    cd "${dirname}"
    # Is file at this location?
    if [ ${fd} "${filename}" ]; then
        # Found
        found_results=("${found_results[@]}" "${dirname}/${filename}")
    else
        # Not found. Search in all subdirectories.
        local f
        for f in *; do
            if [ -d "${f}" ]; then
                find_recursive "${dirname}/${f}" "${filename}" "${fd}" "${current_dir}"
                cd "${dirname}"
            fi
        done
    fi
    cd "${current_dir}"
    if [ "${primary_call}" == "True" ]; then
        # Print out the shortest of the found results, where the length
        # is measured by counting the number of / in the paths.
        N=${#found_results[@]}
        if [ ${N} -gt 0 ]; then
            shortest_result="${found_results[0]}"
            n_slashes_shortest=$(echo "${shortest_result}" | awk -F/ '{print NF-1}')
            for ((i = 1; i < ${N}; i += 1)); do
                n_slashes=$(echo "${found_results[$i]}" | awk -F/ '{print NF-1}')
                if [ ${n_slashes} -lt ${n_slashes_shortest} ]; then
                    shortest_result="${found_results[$i]}"
                    n_slashes_shortest=${n_slashes}
                fi
            done
            echo "${shortest_result}"
        fi
    fi
}

# Replace "__concept_dir__" in paths with the user specified concept_dir.
# Also convert to absolute path and check that this path exist for
# pre-installed libraries.
fix_path() {
    # Arguments: Program name
    progname="${1// /_}"
    progname="$(echo "${progname}" | tr '[:upper:]' '[:lower:]')"
    # Replace "__concept_dir__"
    eval "[ \"\${${progname=}_preinstalled}\" == \"True\" ] \
          || ${progname=}_dir=\"\${${progname=}_dir/__concept_dir__/${concept_dir}}\""
    # Convert to absolute path
    eval "${progname=}_dir=\"\$(convert_to_abs_path \"\${${progname=}_dir}\")\""
    # Check that the path to pre-installed dependencies exist
    if [ "${check_preinstalled}" != "False" ]; then
        if eval "[ \"\${${progname}_preinstalled}\" == \"True\" ] \
            && [ ! -d \"\${${progname}_dir}\" ] \
            && [ ! -f \"\${${progname}_dir}\" ]" \
        ; then
            error "The specified directory\n\"$(eval "echo \${${progname}_dir}")\"\n\
for ${1/CONCEPT/$esc_concept} does not exist!"
            exit 1
        fi
    fi
    # Check and correct user specified dependency directories
    eval "progname_dir=\"\${${progname=}_dir}\""
    if [ -f "${progname_dir}" ]; then
        progname_dir="$(dirname ${progname_dir})"
    fi
    if [ "${progname}" == 'class' ] && [ "${class_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/class" ]; then
            if [ -f "${progname_dir}/../class" ]; then
                class_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate CLASS at \"${class_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'concept' ] && [ "${concept_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/concept" ]; then
            if [ -f "${progname_dir}/../concept" ]; then
                concept_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate ${esc_concept} at \"${concept_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'fftw' ] && [ "${fftw_preinstalled}" == "True" ]; then
        if     [ ! -f "${progname_dir}/lib/libfftw3.so" ] \
            && [ ! -f "${progname_dir}/lib/libfftw3f.so" ]; then
            if     [ -f "${progname_dir}/../lib/libfftw3.so" ] \
                || [ -f "${progname_dir}/../lib/libfftw3f.so" ]; then
                fftw_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate FFTW at \"${fftw_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'freetype' ] && [ "${freetype_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/lib/libfreetype.so" ]; then
            if [ -f "${progname_dir}/../lib/libfreetype.so" ]; then
                freetype_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate FreeType at \"${freetype_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'gadget' ] && [ "${gadget_preinstalled}" == "True" ]; then
        if [ ! -d "${progname_dir}/Gadget2" ]; then
            if [ -d "${progname_dir}/../Gadget2" ]; then
                gadget_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate GADGET at \"${gadget_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'gsl' ] && [ "${gsl_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/lib/libgsl.so" ]; then
            if [ -f "${progname_dir}/../lib/libgsl.so" ]; then
                gsl_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate GSL at \"${gsl_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'hdf5' ] && [ "${hdf5_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/lib/libhdf5.so" ]; then
            if [ -f "${progname_dir}/../lib/libhdf5.so" ]; then
                hdf5_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate HDF5 at \"${hdf5_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'libffi' ] && [ "${libffi_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/lib/libffi.so" ]; then
            if [ -f "${progname_dir}/../lib/libffi.so" ]; then
                libffi_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate libffi at \"${libffi_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'mpi' ] && [ "${mpi_preinstalled}" == "True" ]; then
        # As a pre-installed MPI is often used, allow for a rather
        # general directory layout. Find mpi_bindir, mpi_libdir and
        # mpi_includedir and set mpi_dir to the deepest common directory
        # in the path of these three directories.
        # First find the mpicc executable.
        progname_dir_shallow="${progname_dir}"
        for ((i = 0; i < 3; i += 1)); do
            mpicc="$(find_recursive "${progname_dir_shallow}" "mpicc")"
            if [ -n "${mpicc}" ] || [ "${progname_dir_shallow}" == "/" ]; then
                break
            fi
            progname_dir_shallow="$(dirname "${progname_dir_shallow}")"
        done
        if [ -z "${mpicc}" ] && [ "${check_preinstalled}" != "False" ]; then
            error "Could not locate mpicc at \"${mpi_dir}\""
            exit 1
        fi
        # The directory containing mpicc will be stored
        # in mpi_compilerdir.
        mpi_compilerdir="$(dirname "${mpicc}")"
        # Now use mpicc to locate the lib and include directories
        mpicc_show="$("${mpicc}" -show || :)"
        mpi_libdirs="$(echo "${mpicc_show}" | grep -o '\-L[^ ]*' || :)"
        n_mpi_libdirs=$(echo "${mpi_libdirs}" | wc -l)
        if [ ${n_mpi_libdirs} -eq 1 ]; then
            mpi_libdir="${mpi_libdirs:2}"
        else
            # Several lib directories exist. Merge them via symlinking.
            mpi_libdir_merged="${mpi_symlinkdir}/merged_lib_specified"
            mkdir -p "${mpi_libdir_merged}"
            while read mpi_libdir; do
                mpi_libdir="${mpi_libdir:2}"
                if [ -d "${mpi_libdir}" ]; then
                    for f in "${mpi_libdir}/"*; do
                        f_base="$(basename "${f}")"
                        mpi_symlink_name="${mpi_libdir_merged}/${f_base}"
                        if     [ ! -f "${mpi_symlink_name}" ] \
                            && [ ! -d "${mpi_symlink_name}" ]; then
                            ln -s "${f}" "${mpi_symlink_name}" >/dev/null 2>&1 || :
                        fi
                    done
                fi
            done <<< "${mpi_libdirs}"
            mpi_libdir="${mpi_libdir_merged}"
        fi
        if [ ! -d "${mpi_libdir}" ]; then
            error "Warning: Could not get MPI library information out of \"${mpicc}\""
            mpi_libdir="$(dirname "${mpi_compilerdir}")/lib"
        fi
        mpi_includedirs="$(echo "${mpicc_show}" | grep -o '\-I[^ ]*' || :)"
        n_mpi_includedirs=$(echo "${mpi_includedirs}" | wc -l)
        if [ ${n_mpi_includedirs} -eq 1 ]; then
            mpi_includedir="${mpi_includedirs:2}"
        else
            # Several include directories exist.
            # Merge them via symlinking.
            mpi_includedir_merged="${mpi_symlinkdir}/merged_include_specified"
            mkdir -p "${mpi_includedir_merged}"
            while read mpi_includedir; do
                mpi_includedir="${mpi_includedir:2}"
                if [ -d "${mpi_includedir}" ]; then
                    for f in "${mpi_includedir}/"*; do
                        f_base="$(basename "${f}")"
                        mpi_symlink_name="${mpi_includedir_merged}/${f_base}"
                        if     [ ! -f "${mpi_symlink_name}" ] \
                            && [ ! -d "${mpi_symlink_name}" ]; then
                            ln -s "${f}" "${mpi_symlink_name}" >/dev/null 2>&1 || :
                        fi
                    done
                fi
            done <<< "${mpi_includedirs}"
            mpi_includedir="${mpi_includedir_merged}"
        fi
        if [ ! -d "${mpi_includedir}" ]; then
            error "Warning: Could not get MPI include information out of \"${mpicc}\""
            mpi_includedir="$(dirname "${mpi_compilerdir}")/include"
        fi
        # Find the mpiexec executable, which might not be in the same
        # directory as mpicc. The mpi_bindir directory is set from the
        # mpiexec executable.
        progname_dir_shallow="${progname_dir}"
        for ((i = 0; i < 3; i += 1)); do
            mpi_bindir="$(find_recursive "${progname_dir_shallow}" "mpiexec")"
            if [ -n "${mpi_bindir}" ] || [ "${progname_dir_shallow}" == "/" ]; then
                break
            fi
            progname_dir_shallow="$(dirname "${progname_dir_shallow}")"
        done
        if [ -n "${mpi_bindir}" ]; then
            mpi_bindir="$(dirname "${mpi_bindir}")"
        else
            # Check for mpiexec in PATH
            mpiexec="$(which mpiexec 2>/dev/null || :)"
            if [ -n "${mpiexec}" ]; then
                mpi_bindir="$(dirname "${mpiexec}")"
                printf "\nMPI binary directory set to \"${mpi_bindir}\" (from PATH)\n\n"
            else
                if [ -f "${mpi_bindir}" ]; then
                    mpi_bindir="$(basename "${mpi_bindir}")"
                fi
                error "Warning: Could not locate MPI binaries at \"${mpi_dir}\", \
nor anywhere in the PATH"
                mpi_bindir="${mpi_compilerdir}"
            fi
        fi
        # Set mpi_dir
        mpi_dir_cancidates=(                     \
            "$(readlink -f "${mpi_bindir}"    )" \
            "$(readlink -f "${mpi_libdir}"    )" \
            "$(readlink -f "${mpi_includedir}")" \
        )
        N=${#mpi_dir_cancidates[@]}
        length="${#mpi_dir_cancidates[0]}"
        different="False"
        for ((j = 1; j < ${length}; j += 1)); do
            part0="${mpi_dir_cancidates[0]}"
            part0="${part0::$j}"
            for ((i = 1; i < ${N}; i += 1)); do
                part0_i="${mpi_dir_cancidates[$i]}"
                part0_i="${part0_i::$j}"
                if [ "${part0_i}" != "${part0}" ]; then
                    different="True"
                    break
                fi
            done
            if [ "${different}" == "True" ]; then
                break
            fi
        done
        ((j -= 1)) || :
        if [ ${j} -gt 1 ]; then
            mpi_dir="${mpi_dir_cancidates[0]}"
            mpi_dir="${mpi_dir::$j}"
            if [[ "${mpi_dir}" != *"/" ]]; then
                mpi_dir="$(dirname "${mpi_dir}")"
            fi
        fi
        if [ -f "${mpi_dir}" ]; then
            mpi_dir="$(dirname "${mpi_dir}")"
        fi
        if [ "$(basename "${mpi_dir}")" == "bin" ]; then
            mpi_dir="$(dirname "${mpi_dir}")"
        fi
        mpi_dir="${mpi_dir%/}"
        # If MPI_ROOT is set and it agrees with the mpi_*dir variables,
        # use this path name explicitly (it may differ
        # due to symbolic links).
        if [ -n "${MPI_ROOT}" ] && [ -d "${MPI_ROOT}" ]; then
            if [                                                                \
                "$(readlink -m "${MPI_ROOT}")" == "$(readlink -m "${mpi_dir}")" \
            ]; then
                mpi_dir="${MPI_ROOT}"
            fi
            if [                                                                            \
                "$(readlink -m "${MPI_ROOT}/bin")" == "$(readlink -m "${mpi_compilerdir}")" \
            ]; then
                mpi_compilerdir="${MPI_ROOT}/bin"
                if [                                                                           \
                    "$(readlink -m "${mpi_compilerdir}/mpicc")" == "$(readlink -m "${mpicc}")" \
                ]; then
                    mpicc="${mpi_compilerdir}/mpicc"
                fi
            fi
            if [                                                                       \
                "$(readlink -m "${MPI_ROOT}/bin")" == "$(readlink -m "${mpi_bindir}")" \
            ]; then
                mpi_bindir="${MPI_ROOT}/bin"
                if [                                                                          \
                    "$(readlink -m "${mpi_bindir}/mpiexec")" == "$(readlink -m "${mpiexec}")" \
                ]; then
                    mpiexec="${mpi_bindir}/mpiexec"
                fi
            fi
            if [                                                                       \
                "$(readlink -m "${MPI_ROOT}/lib")" == "$(readlink -m "${mpi_libdir}")" \
            ]; then
                mpi_libdir="${MPI_ROOT}/lib"
            fi
            if [                                                                               \
                "$(readlink -m "${MPI_ROOT}/include")" == "$(readlink -m "${mpi_includedir}")" \
            ]; then
                mpi_includedir="${MPI_ROOT}/include"
            fi
        fi
    fi
    if [ "${progname}" == 'ncurses' ] && [ "${ncurses_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/lib/libncurses.so" ]; then
            if [ -f "${progname_dir}/../lib/libncurses.so" ]; then
                ncurses_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate ncurses at \"${ncurses_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'blas' ] && [ "${blas_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/include/cblas.h" ]; then
            if [ -f "${progname_dir}/../include/cblas.h" ]; then
                blas_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate OpenBLAS at \"${blas_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'openssl' ] && [ "${openssl_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/lib/libssl.so" ]; then
            if [ -f "${progname_dir}/../lib/libssl.so" ]; then
                openssl_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate OpenSSL at \"${openssl_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'perl' ] && [ "${perl_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/bin/perl" ]; then
            if [ -f "${progname_dir}/../bin/perl" ]; then
                perl_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate Perl at \"${perl_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'python' ] && [ "${python_preinstalled}" == "True" ]; then
        if     [ ! -f "${progname_dir}/bin/python" ] \
            && [ ! -f "${progname_dir}/bin/python3" ]; then
            if     [ -f "${progname_dir}/../bin/python" ] \
                || [ -f "${progname_dir}/../bin/python3" ]; then
                python_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate Python at \"${python_dir}\""
                exit 1
            fi
        fi
    fi
    if [ "${progname}" == 'zlib' ] && [ "${zlib_preinstalled}" == "True" ]; then
        if [ ! -f "${progname_dir}/lib/libz.so" ]; then
            if [ -f "${progname_dir}/../lib/libz.so" ]; then
                zlib_dir="$(dirname ${progname_dir})"
            elif [ "${check_preinstalled}" != "False" ]; then
                error "Could not locate zlib at \"${zlib_dir}\""
                exit 1
            fi
        fi
    fi
}
fix_path "CLASS"
fix_path "CONCEPT"
fix_path "FreeType"
fix_path "zlib"
fix_path "ncurses"
fix_path "BLAS"
fix_path "OpenSSL"
fix_path "libffi"
fix_path "Perl"
fix_path "Python"
fix_path "FFTW"
fix_path "GADGET"
fix_path "FFTW for GADGET"
fix_path "GSL"
fix_path "HDF5"
fix_path "MPI"
env="${env/__concept_dir__/${concept_dir}}"
path="${path/__concept_dir__/${concept_dir}}"

# Set mpicc, mpi_compilerdir, mpi_bindir, mpi_libdir and mpi_includedir
# if not already set.
if [ -z "${mpicc}" ]; then
    mpicc="${mpi_dir}/bin/mpicc"
fi
if [ -z "${mpi_compilerdir}" ]; then
    mpi_compilerdir="${mpi_dir}/bin"
fi
if [ -z "${mpi_bindir}" ]; then
    mpi_bindir="${mpi_dir}/bin"
fi
if [ -z "${mpi_libdir}" ]; then
    mpi_libdir="${mpi_dir}/lib"
fi
if [ -z "${mpi_includedir}" ]; then
    mpi_includedir="${mpi_dir}/include"
fi

# Set test_log path variables
blas_test_log="${blas_dir}/test_log"
class_test_log="${class_dir}/test_log"
concept_test_log="${concept_dir}/test_log"
fftw_test_log="${fftw_dir}/test_log"
fftw_for_gadget_test_log="${fftw_for_gadget_dir}/test_log"
freetype_test_log="${freetype_dir}/test_log"
gadget_test_log="${gadget_dir}/test_log"
gsl_test_log="${gsl_dir}/test_log"
hdf5_test_log="${hdf5_dir}/test_log"
libffi_test_log="${libffi_dir}/lib/libffi-${libffi_version}/test_log"
mpi_test_log="${mpi_dir}/test_log"
ncurses_test_log="${ncurses_dir}/include/ncurses/test_log"
openssl_test_log="${openssl_dir}/include/openssl/test_log"
perl_test_log="${perl_dir}/test_log"
python_test_log="${python_dir}/test_log"
zlib_test_log="${zlib_dir}/test_log"
numpy_test_log="${python_dir}/numpy_test_log"
scipy_test_log="${python_dir}/scipy_test_log"

# Check whether this script is run locally or remotely via ssh
ssh="True"
if [ -z "${SSH_CLIENT}" ] && [ -z "${SSH_TTY}" ]; then
    ssh="False"
fi

# When running locally, set the "make_jobs" variable, holding the -j
# option for future make commands, enabling parallel building.
# Some implementations of make does not support the bare -j option
# without explicitly specifying a number afterwards. If so, we do not
# make use of the -j option.
make_jobs_set_by_user="False"
if [ -n "${make_jobs}" ]; then
    make_jobs_set_by_user="True"
fi
if ([ "${ssh}" == "False" ] && [ -z "${make_jobs}" ]) || [ -n "${make_jobs}" ]; then
    make_jobs_test_dir="${tmp_dir}/make_jobs_test"
    rm -rf "${make_jobs_test_dir}" || :
    mkdir -p "${make_jobs_test_dir}"
    printf "
test:
\t@echo success
" > "${make_jobs_test_dir}/Makefile"
    if [ -z "${make_jobs}" ]; then
        make_jobs="-j"
    fi
    make_jobs_output="$(cd "${make_jobs_test_dir}" && make ${make_jobs} 2>/dev/null)" || :
    if [ "${make_jobs_output}" != "success" ]; then
        if [ "${make_jobs_set_by_user}" == "True" ]; then
            echo "Changing make_jobs from '${make_jobs}' to ''" 2>&1
        fi
        make_jobs=""
    fi
    rm -rf "${make_jobs_test_dir}" || :
fi
# Set OMP_NUM_THREADS to 1 when running remotely,
# so that OpenMP runs serially.
if [ "${ssh}" == "True" ] && [ -z "${OMP_NUM_THREADS}" ]; then
    export OMP_NUM_THREADS=1
fi
# In OpenMPI 3 and 4, oversubscription (having more MPI processes
# than physical cores) is disallowed by default.
# We want oversubscription to be allowed during installation.
if [ -z "${OMPI_MCA_rmaps_base_oversubscribe}" ]; then
    export OMPI_MCA_rmaps_base_oversubscribe=1
fi
# By default, OpenMPI disallows any usage by the root user.
# We do not want this limitation during installation.
export OMPI_ALLOW_RUN_AS_ROOT=1
export OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1



##########################
# Dependency discovering #
##########################
current_step="discovery of dependencies"
# Flags specifying whether or not any Python packages,
# software (meaning anything but Python packages) or any of those
# should be installed.
install_any_pypackages="False"
install_any_software="False"
install_anything="False"
assume_preinstalled() {
    # Arguments: Program name (lower-case)
    eval "name_preinstalled=\"\${${1}_preinstalled}\""
    if [ "${name_preinstalled}" == "False" ]; then
        eval "${1}_preinstalled=\"True\""
        eval "${1}_dir=\"\""
        eval "${1}_version=\"pre-installed\""
    fi
}
# If Python is pre-installed, assume that OpenSSL,
# libffi and ncurses are also pre-installed.
if [ "${python_preinstalled}" == "True" ]; then
    assume_preinstalled "openssl"
    assume_preinstalled "libffi"
    assume_preinstalled "ncurses"
fi
# If OpenSSL, BLAS and MPI is pre-installed,
# assume that Perl is also pre-installed.
if     [ "${openssl_preinstalled}" == "True" ] \
    && [ "${blas_preinstalled}"    == "True" ] \
    && [ "${mpi_preinstalled}"     == "True" ] \
; then
    assume_preinstalled "perl"
fi

# Function that checks whether a given Python package
# is installed or not.
check_pypackage_installed() {
    # Arguments: Python package name
    local pypackage="${1}"
    pypackage="${pypackage//-/}"
    current_dir="$(pwd)"
    cd "${concept_dir}"
    # Some Python packages may need access to libraries at runtime
    current_LD_LIBRARY_PATH="${LD_LIBRARY_PATH}"
    for lib in "blas" "gsl" "hdf5" "ncurses" "python" "zlib"; do
        eval "lib_dir=\"\${${lib}_dir}\""
        if [ -z "${lib_dir}" ]; then
            continue
        fi
        lib_dir="${lib_dir}/lib"
        if [ ! -d "${lib_dir}" ]; then
            continue
        fi
        export LD_LIBRARY_PATH="${lib_dir}:${LD_LIBRARY_PATH}"
    done
    # On some systems the MPI4Py package only works when Python
    # is run through MPI.
    python_executors=("")
    if [ "${pypackage}" == "mpi4py" ]; then
        python_executors=("${python_executors[@]}" "mpiexec -n 1")
        if [ -n "${mpiexec_extra_args_local}" ]; then
            python_executors=("${python_executors[@]}" "mpiexec ${mpiexec_extra_args_local} -n 1")
        fi
    fi
    local pypackage_installed
    for python_executor in "${python_executors[@]}"; do
        pypackage_installed="$(${python_executor} "${python}" -B -c "
from time import sleep
try:
    if '${pypackage}' == 'cythongsl':
        # CythonGSL has an extra underscore when importing
        import cython_gsl
    elif '${pypackage}' == 'pythondateutil':
        # Python-dateutil is imported as dateutil
        import dateutil
    elif '${pypackage}' == 'fonttools':
        # fontTools is written in camel case
        import fontTools
    elif '${pypackage}' == 'matplotlib':
        # For Matplotlib we do a more thorough test
        import matplotlib
        matplotlib.use('agg')
        import matplotlib.pyplot as plt
    elif '${pypackage}' == 'mpi4py':
        # For MPI4Py we do a more thorough test
        import mpi4py.rc; mpi4py.rc.threads = False  # Do not use threads
        from mpi4py import MPI
    elif '${pypackage}' == 'pillow':
        # Pillow is imported as PIL
        import PIL
    elif '${pypackage}' == 'scipy':
        # For SciPy we do a more thorough test
        import scipy.integrate
        import scipy.interpolate
        import scipy.optimize
        import scipy.signal
        import scipy.special
    else:
        import ${pypackage}
    sleep(1)
    print('\nTrue')
except:
    print('\nFalse')
" 2>/dev/null | tail -n 1)"
        if [ "${pypackage_installed}" == "True" ]; then
            break
        else
            pypackage_installed="False"
        fi
    done
    echo "${pypackage_installed}"
    cd "${current_dir}"
    export LD_LIBRARY_PATH="${current_LD_LIBRARY_PATH}"
}

# Set "pypackage"_preinstalled variables
blessings_preinstalled="False"
cython_preinstalled="False"
cythongsl_preinstalled="False"
h5py_preinstalled="False"
matplotlib_preinstalled="False"
mpi4py_preinstalled="False"
numpy_preinstalled="False"
scipy_preinstalled="False"
sphinx_preinstalled="False"
sphinx_copybutton_preinstalled="False"
sphinx_rtd_theme_preinstalled="False"
sphinx_tabs_preinstalled="False"
pip_preinstalled="False"
if [ "${python_preinstalled}" == "True" ]; then
    python=$(ls -1 "${python_dir}/bin/python"* | head -n 1)
    for pypackage in      \
        blessings         \
        cython            \
        cythongsl         \
        h5py              \
        matplotlib        \
        mpi4py            \
        numpy             \
        pip               \
        scipy             \
        sphinx            \
        sphinx_copybutton \
        sphinx_rtd_theme  \
        sphinx_tabs       \
    ; do
        pypackage_preinstalled=$(check_pypackage_installed ${pypackage})
        eval "${pypackage}_preinstalled=\"${pypackage_preinstalled}\""
    done
fi

# Variables telling whether or not a program needs to be installed.
# CO𝘕CEPT (install by default)
if [ -z "${concept_install}" ]; then
    concept_install="False"
    if [ "${concept_preinstalled}" == "False" ]; then
        concept_install="True"
    fi
fi
# CLASS (needed by CO𝘕CEPT)
if [ -z "${class_install}" ]; then
    class_install="False"
    if [ "${class_preinstalled}" == "False" ] && [ "${concept_install}" == "True" ]; then
        class_install="True"
    fi
fi
# GADGET (needed by CO𝘕CEPT)
if [ -z "${gadget_install}" ]; then
    gadget_install="False"
    if [ "${gadget_preinstalled}" == "False" ] && [ "${concept_install}" == "True" ]; then
        gadget_install="True"
    fi
fi
# FFTW for GADGET (needed by GADGET)
if [ -z "${fftw_for_gadget_install}" ]; then
    fftw_for_gadget_install="False"
    if [ "${fftw_for_gadget_preinstalled}" == "False" ] && [ "${gadget_install}" == "True" ]; then
        fftw_for_gadget_install="True"
    fi
fi
# Python (needed by CLASS, CO𝘕CEPT)
if [ -z "${python_install}" ]; then
    python_install="False"
    if [ "${python_preinstalled}" == "False" ] \
        && ([ "${concept_install}" == "True" ] || [ "${class_install}" == "True" ]); then
        python_install="True"
    fi
fi
# Python packages (needed by CLASS, CO𝘕CEPT)
if [ -z "${pip_install}" ]; then
    # Always install pip if Python is to be installed
    pip_install="False"
    if [ "${python_install}" == "True" ]; then
        pip_install="True"
    fi
fi
for pypackage in \
    blessings         \
    cython            \
    cythongsl         \
    h5py              \
    matplotlib        \
    mpi4py            \
    numpy             \
    scipy             \
    sphinx            \
    sphinx_copybutton \
    sphinx_rtd_theme  \
    sphinx_tabs       \
; do
    eval "pypackage_install=\"\${${pypackage}_install}\""
    if [ -z "${pypackage_install}" ]; then
        eval "${pypackage}_install=\"False\""
        eval "pypackage_preinstalled=\"\${${pypackage}_preinstalled}\""
        if [ "${pypackage_preinstalled}" == "False" ] && [ "${concept_install}" == "True" ]; then
            eval "${pypackage}_install=\"True\""
        fi
    fi
done
# FFTW (needed by CO𝘕CEPT)
if [ -z "${fftw_install}" ]; then
    fftw_install="False"
    if [ "${fftw_preinstalled}" == "False" ] && [ "${concept_install}" == "True" ]; then
        fftw_install="True"
    fi
fi
# HDF5 (needed by CO𝘕CEPT)
if [ -z "${hdf5_install}" ]; then
    hdf5_install="False"
    if [ "${hdf5_preinstalled}" == "False" ] && [ "${concept_install}" == "True" ]; then
        hdf5_install="True"
    fi
fi
# MPI (needed by CO𝘕CEPT, GADGET)
if [ -z "${mpi_install}" ]; then
    mpi_install="False"
    if [ "${mpi_preinstalled}" == "False" ] && \
        (   [ "${concept_install}" == "True" ] \
         || [ "${gadget_install}"  == "True" ]); then
        mpi_install="True"
    fi
fi
# GSL (needed by CO𝘕CEPT, GADGET)
if [ -z "${gsl_install}" ]; then
    gsl_install="False"
    if [ "${gsl_preinstalled}" == "False" ] && \
        (   [ "${concept_install}" == "True" ] \
         || [ "${gadget_install}"  == "True" ]); then
        gsl_install="True"
    fi
fi
# zlib (needed by HDF5, Python, Matplotlib (via pillow))
if [ -z "${zlib_install}" ]; then
    zlib_install="False"
    if [ "${zlib_preinstalled}" == "False" ] &&   \
        (   [ "${hdf5_install}"       == "True" ] \
         || [ "${python_install}"     == "True" ] \
         || [ "${matplotlib_install}" == "True" ]); then
        zlib_install="True"
    fi
fi
# FreeType (needed by Matplotlib)
if [ -z "${freetype_install}" ]; then
    freetype_install="False"
    if [ "${freetype_preinstalled}" == "False" ] && [ "${matplotlib_install}" == "True" ]; then
        freetype_install="True"
    fi
fi
# ncurses (needed by Python, if Python is needed by CO𝘕CEPT)
if [ -z "${ncurses_install}" ]; then
    ncurses_install="False"
    if [ "${ncurses_preinstalled}" == "False" ] && [ "${python_install}"  == "True" ] \
        && [ "${concept_install}" == "True" ]; then
        ncurses_install="True"
    fi
fi
# BLAS (needed by NumPy, SciPy)
if [ -z "${blas_install}" ]; then
    blas_install="False"
    if [ "${blas_preinstalled}" == "False" ] \
        && ([ "${numpy_install}" == "True" ] || [ "${scipy_install}" == "True" ]); then
        blas_install="True"
    fi
fi
# OpenSSL (needed by pip)
if [ -z "${openssl_install}" ]; then
    openssl_install="False"
    if [ "${openssl_preinstalled}" == "False" ] && [ "${pip_install}" == "True" ]; then
        openssl_install="True"
    fi
fi
# libffi (needed by pip)
if [ -z "${libffi_install}" ]; then
    libffi_install="False"
    if [ "${libffi_preinstalled}" == "False" ] && [ "${pip_install}" == "True" ]; then
        libffi_install="True"
    fi
fi
# Perl (needed by OpenSSL, OpenBLAS, MPICH/OpenMPI)
if [ -z "${perl_install}" ]; then
    perl_install="False"
    if [ "${perl_preinstalled}" == "False" ]      \
        && (                                      \
               [ "${openssl_install}" == "True" ] \
            || [ "${blas_install}"    == "True" ] \
            || [ "${mpi_install}"     == "True" ] \
        )                                         \
    ; then
        perl_install="True"
    fi
fi
# The install_any_software, install_any_pypackages
# and install_anything variables.
if     [ "${concept_install}"           == "True" ] \
    || [ "${blas_install}"              == "True" ] \
    || [ "${class_install}"             == "True" ] \
    || [ "${gadget_install}"            == "True" ] \
    || [ "${fftw_for_gadget_install}"   == "True" ] \
    || [ "${python_install}"            == "True" ] \
    || [ "${fftw_install}"              == "True" ] \
    || [ "${hdf5_install}"              == "True" ] \
    || [ "${mpi_install}"               == "True" ] \
    || [ "${gsl_install}"               == "True" ] \
    || [ "${zlib_install}"              == "True" ] \
    || [ "${freetype_install}"          == "True" ] \
    || [ "${ncurses_install}"           == "True" ] \
    || [ "${openssl_install}"           == "True" ] \
    || [ "${libffi_install}"            == "True" ] \
    || [ "${perl_install}"              == "True" ] \
; then
        install_any_software="True"
fi
if     [ "${blessings_install}"         == "True" ] \
    || [ "${cython_install}"            == "True" ] \
    || [ "${cythongsl_install}"         == "True" ] \
    || [ "${h5py_install}"              == "True" ] \
    || [ "${matplotlib_install}"        == "True" ] \
    || [ "${mpi4py_install}"            == "True" ] \
    || [ "${numpy_install}"             == "True" ] \
    || [ "${scipy_install}"             == "True" ] \
    || [ "${sphinx_install}"            == "True" ] \
    || [ "${sphinx_copybutton_install}" == "True" ] \
    || [ "${sphinx_rtd_theme_install}"  == "True" ] \
    || [ "${sphinx_tabs_install}"       == "True" ] \
; then
        install_any_pypackages="True"
fi
if [ "${install_any_software}" == "True" ] || [ "${install_any_pypackages}" == "True" ]; then
    install_anything="True"
fi



###########################
# Beginning of subprocess #
installpid=$$
log_file_lines_before_install=0
if [ -f "${log}" ]; then
    log_file_lines_before_install=$(wc -l "${log}" | awk '{print $1}')
fi
# The stdout and stderr of the (background) subprocess below will be
# redirected into ${log}, which is read back in and echoed to the TTY.
# The system will keep track of the current installation step and always
# display this at the bottom, which is the whole reason for not just
# tee'ing directly to ${log}.
# To also log stderr separately, we tee this into ${log}_err.
( ( (
# Set up error trapping
ctrl_c_subprocess() {
    trap : 0
    ctrl_c
    exit 0
}
abort_subprocess() {
    trap : 0
    if [ "${current_step}" != "aborting" ]; then
        error "An error occurred during ${current_step}!"
    fi
    abort
    exit 0
}
trap 'ctrl_c_subprocess' SIGINT
trap 'abort_subprocess' EXIT
set -e

# Ensure new line in log after possible previous failed attempt
echo

# Functions for controlling the current status
set_status() {
    echo "${status_prefix}${1}"
}
disable_status() {
    echo "${status_prefix}${status_disable}"
}
enable_status() {
    echo "${status_prefix}${status_enable}"
}
successfully_finish_status() {
    echo "${status_prefix}${status_finish_successfully}"
}
# These are needed to get the spacing right in the output
current_step="initialisation"
set_status "Initialising"

# Store the pid of the installation in the install log
echo "${status_prefix}${status_installpid}${installpid}"
set_status "Initialising"



#############################
# URL's to all the software #
#############################
# In this section, ${progame_url} are defined for each program.
# In order for the rest of this script to work, these URLs must point
# to archives containing a single top-level directory.

# Function for checking that a given URL actually exists
validate_url() {
    # Arguments: Program name, [exit on error ("True" or "False")]
    progname="$(echo "${1}" | tr '[:upper:]' '[:lower:]')"
    progname="${progname// /_}"
    exit_on_error="True"
    if [ -n "$2" ]; then
        exit_on_error="$2"
    fi
    if [ "${progname}" == "blas" ]; then
        current_step="validation of OpenBLAS link"
        set_status "Validating OpenBLAS link"
    elif [ "${progname}" == "mpi" ]; then
        current_step="validation of ${mpi_formatted} link"
        set_status "Validating ${mpi_formatted} link"
    else
        current_step="validation of ${1/CONCEPT/$esc_concept} link"
        set_status "Validating ${1/CONCEPT/${esc_concept}} link"
    fi
    url="$(eval "echo \"\${${progname}_url}\"")"
    filename="$(basename "${url}")"
    mkdir -p "${tmp_dir}"
    _validate_url() {
        for n in {1..3}; do
            for spider in "True" "False"; do
                for ipv in "--inet4-only" "--inet6-only" ""; do
                    for no_dns_cache in "--no-dns-cache" ""; do
                        for no_check_certificate in "" "--no-check-certificate"; do
                            wget_status="success"
                            if [ "${spider}" == "True" ]; then
                                if [[ "${url}" == "ftp://"* ]]; then
                                    # wget do not always return with a
                                    # non-zero status on failure when
                                    # using ftp.
                                    (
                                        cd "${tmp_dir}"
                                        wget                        \
                                            -t 1                    \
                                            --timeout 30            \
                                            ${no_check_certificate} \
                                            ${no_dns_cache}         \
                                            --spider                \
                                            --no-remove-listing     \
                                            ${ipv}                  \
                                            "${url}"                \
                                            > "${tmp_dir}/.wget" 2>&1 || :
                                    )
                                    grep "${filename}" "${tmp_dir}/.listing" \
                                        > /dev/null 2>&1 || wget_status="error"
                                    rm -f "${tmp_dir}/.listing" || :
                                else
                                    wget                        \
                                        -t 1                    \
                                        --timeout 30            \
                                        ${no_check_certificate} \
                                        ${no_dns_cache}         \
                                        --spider                \
                                        ${ipv}                  \
                                        "${url}"                \
                                        > "${tmp_dir}/.wget" 2>&1 || wget_status="error"
                                fi
                                if [ "${wget_status}" == "error" ]; then
                                    # Heavy scraping can result in bans,
                                    # indicated by a "429 Too Many
                                    # Requests" error. This does not
                                    # mean that we cannot download the
                                    # file, just that the spider has
                                    # been disallowed by the server.
                                    if grep "429" "${tmp_dir}/.wget" >/dev/null 2>&1; then
                                        wget_status="success"
                                    fi
                                fi
                                rm -f "${tmp_dir}/.wget" || :
                            else
                                # Some times --spider just does not
                                # succeed in correctly reporting the
                                # existence of the remote file, even
                                # though it exists. As a last resort,
                                # try downloading the file completely,
                                # without using --spider (and throw away
                                # the downloaded file).
                                wget                        \
                                    -t 1                    \
                                    --timeout 30            \
                                    ${no_check_certificate} \
                                    ${no_dns_cache}         \
                                    ${ipv}                  \
                                    -O-                     \
                                    "${url}"                \
                                    >/dev/null 2>&1 || wget_status="error"
                            fi
                            if [ "${wget_status}" == "success" ]; then
                                return
                            fi
                        done
                    done
                done
            done
            sleep 5
        done
    }
    _validate_url
    validate_url_status="${wget_status}"
    if [ "${exit_on_error}" == "True" ]; then
        if [ "${wget_status}" != "success" ]; then
            error "Error: The ${1} link is broken: ${url}"
            exit 1
        fi
    fi
}

# Function for letting versions fall back to their secondary,
# fallback values, in case of unsuccessful retrieval of primary version.
fallback() {
    # Arguments: Program name
    progname="$(echo "${1}" | tr '[:upper:]' '[:lower:]')"
    progname="${progname// /_}"
    eval "progname_version=\"\${${progname}_version}\""
    eval "progname_version_fallback=\"\${${progname}_version_fallback}\""
    if [ "${progname}" == "blas" ]; then
        realname="OpenBLAS"
    elif [ "${progname}" == "mpi" ]; then
        realname="${mpi_formatted}"
    else
        realname="${1}"
    fi
    if [ "${progname_version}" != "${progname_version_fallback}" ]; then
        echo "Falling back to ${realname} version ${progname_version_fallback}"
    fi
    progname_version="${progname_version_fallback}"
    eval "${progname}_version=\"\${progname_version}\""
    eval "${progname}_version_fallback=\"\${progname_version_fallback}\""
}

# Function which checks the download and installation progress
# of all the programs based on helper files created by previous
# invocations of this script. The function is called with the program
# name (progname) as the argument and it will set the variables
# progname_downloaded, progname_installed and progname_test_success
# to either "True" or "False".
check_progress() {
    # Arguments: Program name
    progname_display="${1/CONCEPT/${esc_concept}}"
    progname="${1// /_}"
    progname="$(echo "${progname}" | tr '[:upper:]' '[:lower:]')"
    # The program installation directory
    eval "progdir=\"\${${progname}_dir}\""
    # CO𝘕CEPT itself will not have a .installation_finished file in its
    # directory. Instead it uses the .installation_finished in the
    # GADGET directory.
    if [ "${progname}" == "concept" ]; then
        progdir="${gadget_dir}"
        # If the CO𝘕CEPT source is missing (e.g. manually deleted),
        # info about CO𝘕CEPT from ${gadget_dir}/.installation_finished
        # should not be used. Remove such info if present, and if
        # the CO𝘕CEPT source indeed is missing.
        if [ ! -d "${concept_dir}/src" ] && [ -f "${progdir}/.installation_finished" ]; then
            linenr=$(awk "\$0 ~ \"CONCEPT\" {print NR}" \
                "${progdir}/.installation_finished" | head -n 1)
            if [ -n "${linenr}" ]; then
                linenr_first=${linenr}
                while :; do
                    line="$(sed -n "${linenr_first}p" "${progdir}/.installation_finished")"
                    if [ -z "${line}" ]; then
                        ((linenr_first += 1))
                        break
                    fi
                    ((linenr_first -= 1))
                    if [ ${linenr_first} -eq 0 ]; then
                        ((linenr_first += 1))
                        break
                    fi
                done
                linenr_last=${linenr}
                while :; do
                    line="$(sed -n "${linenr_last}p" "${progdir}/.installation_finished")"
                    if [ -z "${line}" ]; then
                        ((linenr_last -= 1))
                        break
                    fi
                    ((linenr_last += 1))
                done
                sed -i "${linenr_first},${linenr_last}d" "${progdir}/.installation_finished"
            fi
        fi
    fi
    # The program version
    eval "progversion=\"\${${progname}_version}\""
    # If the program has already been fully installed, a file called
    # .installation_finished will be placed in the program installation
    # directory. Note that some programs share a common installation
    # directory and therefore also a common .installation_finished file.
    eval "${progname}_installed=\"False\""
    if [ -f "${progdir}/.installation_finished" ]; then
        while read line; do
            prog_prev="$(echo "${line}" | grep  '^Program:*'     \
                                        | sed 's/^Program:\s//g' \
                                        | sed 's/^ *//')"
            if [ -n "${prog_prev}" ]; then
                prog_prev_real="${prog_prev// /_}"
                prog_prev_real="$(echo "${prog_prev_real}" | tr '[:upper:]' '[:lower:]')"
            fi
            version_prev="$(echo "${line}" | grep  '^Version:*'     \
                                           | sed 's/^Version:\s//g' \
                                           | sed 's/^ *//')"
            if [ -n "${version_prev}" ]; then
                version_prev_real="${version_prev}"
            fi
            test_results_prev="$(echo "${line}" | grep  '^Test results:*'     \
                                                | sed 's/^Test results:\s//g' \
                                                | sed 's/^ *//')"
            if [ -n "${test_results_prev}" ]; then
                test_results_prev_real="${test_results_prev}"
            fi
            if [ "${prog_prev_real}" == "${progname}" ]; then
                if [ "${version_prev_real}" == "${progversion}" ]; then
                    eval "${progname}_installed=\"True\""
                    if [ -n "${test_results_prev_real}" ]; then
                        if [ "${test_results_prev}" == "Success" ]; then
                            eval "${progname}_test_success=\"True\""
                        elif [ "${test_results_prev_real}" == "Failure" ]; then
                            eval "${progname}_test_success=\"False\""
                        fi
                    fi
                    # Installed programs should always count
                    # as downloaded.
                    eval "${progname}_downloaded=\"True\""
                    return
                fi
                # Program already installed but of incorrect version.
                # Count as uninstalled.
                break
            fi
        done <<< "$(tac "${progdir}/.installation_finished")"
    fi
    # Propagate the ${progname}_installed variable to the outer scope
    progname_installed_varname="${progname}_installed"
    eval "progname_installed_value=\${${progname_installed_varname}}"
    echo "${status_prefix}${status_setvar}\
${progname_installed_varname}=\"${progname_installed_value}\""
    # If the program is not yet installed fully, remove its directory,
    # cleaning up after any previous failed installation attempts.
    if [ "${progname}" == "gadget" ]; then
        # FFTW for GADGET is placed inside the GADGET directory
        if [ -d "${gadget_dir}/fftw" ]; then
            mv "${gadget_dir}/fftw" "${gadget_dir}/.fftw"
        fi
        if [ -d "${gadget_dir}" ] && [ -n "$(ls "${gadget_dir}")" ]; then
            printf "Cleaning up ${progname_display} directory ...\n"
            rm -rf "${gadget_dir}/"* || :
        fi
        if [ -d "${gadget_dir}/.fftw" ]; then
            mv "${gadget_dir}/.fftw" "${gadget_dir}/fftw"
        fi
        if [ -d "${gadget_dir}" ] && [ -z "$(ls -A "${gadget_dir}")" ]; then
            rm -rf "${gadget_dir}" || :
        fi
    elif [ "${progname}" == "python" ]; then
        # Files from ncurses, OpenSSL and libffi are placed all around
        # in ${python_dir}, so we cannot just delete this directory.
        :
    elif [ "${progname}" == "ncurses" ]; then
        if [ -d "${python_dir}/include/ncurses" ]; then
            printf "Cleaning up ${progname_display} directory ...\n"
            rm -rf "${python_dir}/include/ncurses" || :
        fi
    elif [ "${progname}" == "openssl" ]; then
        if [ -d "${python_dir}/include/openssl" ]; then
            printf "Cleaning up ${progname_display} directory ...\n"
            rm -rf "${python_dir}/include/openssl" || :
        fi
    elif [ "${progname}" == "libffi" ]; then
        for f in "${python_dir}/lib/libffi"*; do
            if [ -d "${f}" ]; then
                printf "Cleaning up ${progname_display} directory ...\n"
                rm -rf "${python_dir}/lib/libffi"* || :
                break
            fi
        done
    elif [ "${progname}" == "concept" ]; then
        if [ -d "${concept_dir}" ]; then
            set_concept_files
            cleanup_msg_printed="False"
            for f in "${files[@]}"; do
                f="${concept_dir}/${f}"
                if [ -f "${f}" ] || [ -d "${f}" ]; then
                    if [ "${cleanup_msg_printed}" == "False" ]; then
                        printf "Cleaning up ${progname_display} directory ...\n"
                        cleanup_msg_printed="True"
                    fi
                    rm -rf "${f}" || :
                fi
            done
        fi
    else
        # The files of all other programs live isolated
        # in their very own dedicated directory.
        if [ -d "${progdir}" ]; then
            printf "Cleaning up ${progname_display} directory ...\n"
            rm -rf "${progdir}" || :
        fi
    fi
    # The URL to the installation file for this program
    eval "url=\"\${${progname}_url}\""
    # The directory for the downloaded file
    download_dir="${tmp_dir}/${progname}"
    # If the source file has already been downloaded fully, a file
    # called .download_finished will be placed in the download_dir with
    # information about this file.
    eval "${progname}_downloaded=\"False\""
    if [ -f "${download_dir}/.download_finished" ]; then
        file_prev="$(grep "^File:*" "${download_dir}/.download_finished" | sed 's/^File:\s//g' \
                                                                         | sed 's/^ *//')"
        url_prev="$( grep "^URL:*"  "${download_dir}/.download_finished" | sed 's/^URL:\s//g' \
                                                                         | sed 's/^ *//')"
        if [ -f "${download_dir}/${file_prev}" ] && [ "${url_prev}" == "${url}" ]; then
            eval "${progname}_downloaded=\"True\""
        fi
    fi
}

# CO𝘕CEPT
if [ "${concept_version_specified}" == "True" ]; then
    # If concept_version has been supplied as a path to an existing
    # directory containing the CO𝘕CEPT code, the installation will use
    # a copy of these code files rather than downloading them. To fake
    # the download, we create a .tar.gz archive with the code files
    concept_dir_supplied="$(convert_to_abs_path "${concept_version}" 2>/dev/null || :)"
    if [ -d "${concept_dir_supplied}" ]; then
        if [ -f "${concept_dir_supplied}/../concept" ]; then
            concept_dir_supplied="$(dirname "${concept_dir_supplied}")"
        fi
        if [ -f "${concept_dir_supplied}/concept" ]; then
            printf "\nCopying ${esc_concept} files from \"${concept_dir_supplied}\" ...\n"
            rm -rf "${tmp_dir}/concept"
            mkdir -p "${tmp_dir}/concept/concept-supplied"
            set_concept_files
            for f in "${files[@]}"; do
                f="${concept_dir_supplied}/${f}"
                if [ -f "${f}" ] || [ -d "${f}" ]; then
                    cp -r "${f}" "${tmp_dir}/concept/concept-supplied/"
                fi
            done
            # Replace install script with a copy of this script,
            # if possible.
            current_dir="$(pwd)"
            cd "${tmp_dir}/concept"
            if [ -f "${this_file}" ]; then
                copied_installer="True"
                cp "${this_file}" "concept-supplied/.install" 2>/dev/null \
                    || copied_installer=False
                if [ "${copied_installer}" == "True" ] \
                    && [ -f "concept-supplied/.install" ]; then
                        mv "concept-supplied/.install" "concept-supplied/install"
                fi
            fi
            # Make archive and fake the download
            tar -cf - "concept-supplied" | gzip > "concept-supplied.tar.gz"
            rm -rf "concept-supplied"
            concept_url="${concept_dir_supplied}"
            echo "The following has been fully downloaded:
File:    concept-supplied.tar.gz
URL:     ${concept_url}
Program: CONCEPT
Version: ${concept_dir_supplied}
Date:    $(date)
" > ".download_finished"
            cd "${current_dir}"
        fi
    fi
fi
if [ "${concept_install}" == "True" ]; then
    # Either download the current state of the master branch
    # or a specific release.
    if [ -z "${concept_url}" ]; then
        if [ "${concept_version}" == "master" ]; then
            concept_url="https://github.com/jmd-dk/concept/archive/${concept_version}.tar.gz"
        else
            concept_url="https://github.com/jmd-dk/concept/archive/v${concept_version}.tar.gz"
        fi
    fi
    # Check if already downloaded/installed
    check_progress "CONCEPT"
    # If not yet downloaded, validate the URL
    if [ "${concept_downloaded}" != "True" ]; then
        validate_url "CONCEPT" "False"
        if [ "${validate_url_status}" != "success" ]; then
            printf "Primary ${esc_concept} link broken: ${concept_url}\n"
            error "Error: The install script does not know of a secondary ${esc_concept} link"
            exit 1
        fi
    fi
fi

# CLASS
if [ "${class_install}" == "True" ]; then
    # Either download specific release or specific branch
    if [ -z "${class_url}" ]; then
        current_step="processing of CLASS link"
        dots="${class_version//[^.]}"
        ndots="${#dots}"
        if [ "${ndots}" == 1 ]; then
            class_url="https://github.com/lesgourg/class_public/archive/${class_version}.tar.gz"
        elif [ "${ndots}" == 2 ]; then
            class_url="https://github.com/lesgourg/class_public/archive/v${class_version}.tar.gz"
        else
            error "No CLASS URL known for version ${class_version}"
            exit 1
        fi
    fi
    # Check if already installed/downloaded
    check_progress "CLASS"
    # If not yet downloaded, validate the URL
    if [ "${class_downloaded}" != "True" ]; then
        validate_url "CLASS" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary CLASS link broken: ${class_url}"
            error "Error: The install script does not know of a secondary CLASS link"
            exit 1
        fi
    fi
fi

# FFTW
if [ "${fftw_install}" == "True" ]; then
    if [ -z "${fftw_url}" ]; then
        fftw_url="http://www.fftw.org/fftw-${fftw_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "FFTW"
    # If not yet downloaded, validate the URL
    if [ "${fftw_downloaded}" != "True" ]; then
        validate_url "FFTW" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary FFTW link broken: ${fftw_url}"
            fallback "FFTW"
            fftw_url="ftp://ftp.fftw.org/pub/fftw/fftw-${fftw_version}.tar.gz"
            echo "Using secondary FFTW link: ${fftw_url}"
            # Check if already installed and/or downloaded
            check_progress "FFTW"
            # If not yet downloaded, validate the URL
            if [ "${fftw_downloaded}" != "True" ]; then
                validate_url "FFTW"
            fi
        fi
    fi
fi

# FFTW for GADGET
if [ "${fftw_for_gadget_install}" == "True" ]; then
    if [ -z "${fftw_for_gadget_url}" ]; then
        fftw_for_gadget_url="http://www.fftw.org/fftw-${fftw_for_gadget_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "FFTW for GADGET"
    # If not yet downloaded, validate the URL
    if [ "${fftw_for_gadget_downloaded}" != "True" ]; then
        validate_url "FFTW for GADGET" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary FFTW 2 link broken: ${fftw_for_gadget_url}"
            fallback "FFTW for GADGET"
            fftw_for_gadget_url="ftp://ftp.fftw.org/pub/fftw/\
fftw-${fftw_for_gadget_version}.tar.gz"
            echo "Using secondary FFTW 2 link: ${fftw_for_gadget_url}"
            # Check if already installed and/or downloaded
            check_progress "FFTW for GADGET"
            # If not yet downloaded, validate the URL
            if [ "${fftw_for_gadget_downloaded}" != "True" ]; then
                validate_url "FFTW for GADGET"
            fi
        fi
    fi
fi

# FreeType
if [ "${freetype_install}" == "True" ]; then
    if [ -z "${freetype_url}" ]; then
        freetype_url="https://download.savannah.gnu.org/releases/freetype/\
freetype-${freetype_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "FreeType"
    # If not yet downloaded, validate the URL
    if [ "${freetype_downloaded}" != "True" ]; then
        validate_url "FreeType" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary FreeType link broken: ${freetype_url}"
            fallback "freetype"
            freetype_url="https://sourceforge.net/projects/freetype/files/freetype2/\
${freetype_version}/freetype-${freetype_version}.tar.gz"
            echo "Using secondary FreeType link: ${freetype_url}"
            # Check if already installed and/or downloaded
            check_progress "FreeType"
            # If not yet downloaded, validate the URL
            if [ "${freetype_downloaded}" != "True" ]; then
                validate_url "FreeType"
            fi
        fi
    fi
fi

# GADGET
if [ "${gadget_install}" == "True" ]; then
    if [ -z "${gadget_url}" ]; then
        gadget_url="https://www.mpa-garching.mpg.de/gadget/gadget-${gadget_version}.tar.gz"
    fi
    # Check if already installed/downloaded
    check_progress "GADGET"
    # If not yet downloaded, validate the URL
    if [ "${gadget_downloaded}" != "True" ]; then
        validate_url "GADGET" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary GADGET link broken: ${gadget_url}"
            error "Error: The install script does not know of a secondary GADGET link"
            exit 1
        fi
    fi
fi

# GSL
if [ "${gsl_install}" == "True" ]; then
    if [ -z "${gsl_url}" ]; then
        gsl_url="ftp://ftp.gnu.org/gnu/gsl/gsl-${gsl_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "GSL"
    # If not yet downloaded, validate the URL
    if [ "${gsl_downloaded}" != "True" ]; then
        validate_url "GSL" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary GSL link broken: ${gsl_url}"
            fallback "GSL"
            gsl_url="https://ftpmirror.gnu.org/gsl/gsl-${gsl_version}.tar.gz"
            echo "Using secondary gsl link: ${gsl_url}"
            # Check if already installed and/or downloaded
            check_progress "GSL"
            # If not yet downloaded, validate the URL
            if [ "${gsl_downloaded}" != "True" ]; then
                validate_url "GSL"
            fi
        fi
    fi
fi

# HDF5
if [ "${hdf5_install}" == "True" ]; then
    if [ -z "${hdf5_url}" ]; then
        hdf5_version_major="$(echo "${hdf5_version}" | grep -o '[0-9]\.[0-9]*')"
        hdf5_url="https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-${hdf5_version_major}/\
hdf5-${hdf5_version}/src/hdf5-${hdf5_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "HDF5"
    # If not yet downloaded, validate the URL
    if [ "${hdf5_downloaded}" != "True" ]; then
        validate_url "HDF5" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary HDF5 link broken: ${hdf5_url}"
            error "Error: The install script does not know of a secondary HDF5 link"
            exit 1
        fi
    fi
fi

# MPI
if [ "${mpi_install}" == "True" ]; then
    if [ "${mpi}" == "mpich" ]; then
        # MPICH
        if [ -z "${mpi_url}" ]; then
            mpi_url="https://www.mpich.org/static/downloads/${mpi_version}/mpich-${mpi_version}.tar.gz"
        fi
        # Check if already installed and/or downloaded
        check_progress "MPI"
        # If not yet downloaded, validate the URL
        if [ "${mpi_downloaded}" != "True" ]; then
            validate_url "MPI" "False"
            if [ "${validate_url_status}" != "success" ]; then
                echo "Primary MPICH link broken: ${mpi_url}"
                fallback "MPI"
                mpi_url="https://fossies.org/linux/misc/mpich-${mpi_version}.tar.gz"
                echo "Using secondary MPICH link: ${mpi_url}"
                # Check if already installed and/or downloaded
                check_progress "MPI"
                # If not yet downloaded, validate the URL
                if [ "${mpi_downloaded}" != "True" ]; then
                    validate_url "MPI"
                fi
            fi
        fi
    elif [ "${mpi}" == "openmpi" ]; then
        # OpenMPI
        if [ -z "${mpi_url}" ]; then
            mpi_version_major_dot_minor="${mpi_version%.*}"
            mpi_version_major="${mpi_version_major_dot_minor%.*}"
            mpi_url="https://www.open-mpi.org/software/ompi/v${mpi_version_major_dot_minor}/\
downloads/openmpi-${mpi_version}.tar.gz"
        fi
        # Check if already installed and/or downloaded
        check_progress "MPI"
        # If not yet downloaded, validate the URL
        if [ "${mpi_downloaded}" != "True" ]; then
            validate_url "MPI" "False"
            if [ "${validate_url_status}" != "success" ]; then
                echo "Primary OpenMPI link broken: ${mpi_url}"
                error "Error: The install script does not know of a secondary OpenMPI link"
                exit 1
            fi
        fi
    fi
fi

# ncurses
if [ "${ncurses_install}" == "True" ]; then
    if [ -z "${ncurses_url}" ]; then
        ncurses_url="https://ftp.gnu.org/gnu/ncurses/ncurses-${ncurses_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "ncurses"
    # If not yet downloaded, validate the URL
    if [ "${ncurses_downloaded}" != "True" ]; then
        validate_url "ncurses" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary ncurses link broken: ${ncurses_url}"
            fallback "ncurses"
            ncurses_url="https://ftpmirror.gnu.org/ncurses/ncurses-${ncurses_version}.tar.gz"
            echo "Using secondary ncurses link: ${ncurses_url}"
            # Check if already installed and/or downloaded
            check_progress "ncurses"
            # If not yet downloaded, validate the URL
            if [ "${ncurses_downloaded}" != "True" ]; then
                validate_url "ncurses"
            fi
        fi
    fi
fi

# BLAS
if [ "${blas_install}" == "True" ]; then
    if [ -z "${blas_url}" ]; then
        blas_url="https://github.com/xianyi/OpenBLAS/archive/v${blas_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "BLAS"
    # If not yet downloaded, validate the URL
    if [ "${blas_downloaded}" != "True" ]; then
        validate_url "BLAS" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary OpenBLAS link broken: ${blas_url}"
            fallback "blas"
            blas_url="https://sourceforge.net/projects/openblas/files/v${blas_version}/\
OpenBLAS%20${blas_version}%20version.tar.gz"
            echo "Using secondary BLAS link: ${blas_url}"
            # Check if already installed and/or downloaded
            check_progress "BLAS"
            # If not yet downloaded, validate the URL
            if [ "${blas_downloaded}" != "True" ]; then
                validate_url "BLAS"
            fi
        fi
    fi
fi

# OpenSSL
if [ "${openssl_install}" == "True" ]; then
    if [ -z "${openssl_url}" ]; then
        openssl_url="https://github.com/openssl/openssl/archive/\
openssl-${openssl_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "OpenSSL"
    # If not yet downloaded, validate the URL
    if [ "${openssl_downloaded}" != "True" ]; then
        validate_url "OpenSSL" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary OpenSSL link broken: ${openssl_url}"
            fallback "openssl"
            openssl_url="https://www.openssl.org/source/old/${openssl_version/[a-z]*/}/\
openssl-${openssl_version}.tar.gz"
            echo "Using secondary OpenSSL link: ${openssl_url}"
            # Check if already installed and/or downloaded
            check_progress "OpenSSL"
            # If not yet downloaded, validate the URL
            if [ "${openssl_downloaded}" != "True" ]; then
                validate_url "OpenSSL"
            fi
        fi
    fi
fi

# libffi
if [ "${libffi_install}" == "True" ]; then
    if [ -z "${libffi_url}" ]; then
        libffi_url="https://github.com/libffi/libffi/releases/\
download/v${libffi_version}/libffi-${libffi_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "libffi"
    # If not yet downloaded, validate the URL
    if [ "${libffi_downloaded}" != "True" ]; then
        validate_url "libffi" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary libffi link broken: ${libffi_url}"
            fallback "libffi"
            libffi_url="https://sourceware.org/ftp/libffi/libffi-${libffi_version}.tar.gz"
            echo "Using secondary libffi link: ${libffi_url}"
            # Check if already installed and/or downloaded
            check_progress "libffi"
            # If not yet downloaded, validate the URL
            if [ "${libffi_downloaded}" != "True" ]; then
                validate_url "libffi"
            fi
        fi
    fi
fi

# Perl
if [ "${perl_install}" == "True" ]; then
    if [ -z "${perl_url}" ]; then
        perl_url="https://www.cpan.org/src/5.0/perl-${perl_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "Perl"
    # If not yet downloaded, validate the URL
    if [ "${perl_downloaded}" != "True" ]; then
        validate_url "Perl" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary Perl link broken: ${perl_url}"
            error "Error: The install script does not know of a secondary Perl link"
            exit 1
        fi
    fi
fi

# Python
if [ "${python_install}" == "True" ]; then
    if [ -z "${python_url}" ]; then
        python_url="https://www.python.org/ftp/python/\
${python_version}/Python-${python_version}.tgz"
    fi
    # Check if already installed and/or downloaded
    check_progress "Python"
    # If not yet downloaded, validate the URL
    if [ "${python_downloaded}" != "True" ]; then
        validate_url "Python" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary Python link broken: ${python_url}"
            error "Error: The install script does not know of a secondary Python link"
            exit 1
        fi
    fi
fi

# zlib
if [ "${zlib_install}" == "True" ]; then
    if [ -z "${zlib_url}" ]; then
        zlib_url="https://github.com/madler/zlib/archive/v${zlib_version}.tar.gz"
    fi
    # Check if already installed and/or downloaded
    check_progress "zlib"
    # If not yet downloaded, validate the URL
    if [ "${zlib_downloaded}" != "True" ]; then
        validate_url "zlib" "False"
        if [ "${validate_url_status}" != "success" ]; then
            echo "Primary zlib link broken: ${zlib_url}"
            fallback "zlib"
            zlib_url="https://zlib.net/zlib-${zlib_version}.tar.gz"
            echo "Using secondary zlib link: ${zlib_url}"
            # Check if already installed and/or downloaded
            check_progress "zlib"
            # If not yet downloaded, validate the URL
            if [ "${zlib_downloaded}" != "True" ]; then
                validate_url "zlib"
            fi
        fi
    fi
fi

# Create a python variable, storing the path to the Python interpreter
set_python() {
    if [ -z "${python_dir}" ]; then
        return
    fi
    for python_version_major in 3 2; do
        python_tmp="${python_dir}/bin/python${python_version_major}"
        if [ -f "${python_tmp}" ]; then
            python_version_minor=$(                          \
                "${python_tmp}"                             \
                -B -c                                       \
                "import sys; print(sys.version_info.minor)" \
            )
            python="${python_tmp}.${python_version_minor}"
            if [ ! -f "${python}" ]; then
                python="${python_tmp}"
            fi
            break
        fi
    done
}
set_python
# Set "pypackage"_installed variables
blessings_installed="False"
cython_installed="False"
cythongsl_installed="False"
h5py_installed="False"
matplotlib_installed="False"
mpi4py_installed="False"
numpy_installed="False"
scipy_installed="False"
sphinx_installed="False"
sphinx_copybutton_installed="False"
sphinx_rtd_theme_installed="False"
sphinx_tabs_installed="False"
pip_installed="False"
if [ -n "${python}" ] && [ "${python_installed}" == "True" ]; then
    for pypackage in      \
        blessings         \
        cython            \
        cythongsl         \
        h5py              \
        matplotlib        \
        mpi4py            \
        numpy             \
        scipy             \
        sphinx            \
        sphinx_copybutton \
        sphinx_rtd_theme  \
        sphinx_tabs       \
        pip               \
    ; do
        pypackage_installed=$(check_pypackage_installed ${pypackage})
        eval "${pypackage}_installed=\"${pypackage_installed}\""
        # Also set "pypackage"_test_success to False if a previous test
        # led to failure. As an indicator of failed tests we simply use
        # the existence of the test log file.
        eval "test_log=\${${pypackage}_test_log}"
        if [ -f "${test_log}" ]; then
            eval "${pypackage}_test_success=\"False\""
        fi
    done
fi

# Functions for printing out nice tables (these are superior to the
# "column" command on older systems, as this does not handle
# formatted output very well).
modify_element() {
    # Arguments: Character to be replaced, character to replace with
    for ((i = 0; i < nelements; i += 1)); do
        element="${table_to_print[i]}"
        table_to_print[i]="${element//$1/$2}"
    done
}
print_table() {
    # Arguments: Array to be printed (passed as array[@]),
    #            number of columns.
    table_to_print=("${!1}")
    nelements=${#table_to_print[@]}
    nc=${2}
    # Replace spaces with tildes
    modify_element " " "~"
    # Backup of table
    table_with_esc=("${table_to_print[@]}")
    # Remove escape sequences in table
    for format in "normal" "bold" "italic" "no_italic" "green" "blue"; do
        eval "esc_format=\${esc_${format}}"
        modify_element "$(echo "${esc_format}" | sed 's,\\,\\\\,g')" ""
    done
    # Determine largest length of each column
    maxlengths=($(for i in $(eval "echo {1..${nc}}"); do echo 0; done))
    c=0
    for ((i = 0; i < nelements; i += 1)); do
        s="${table_to_print[i]/†/x}"
        length=${#s}
        [ ${length} -gt ${maxlengths[c]} ] && maxlengths[c]=${length}
        ((c += 1))
        [ ${c} == ${nc} ] && c=0
    done
    # Count number of missing right spaces for each element
    c=0
    for ((i = 0; i < nelements; i += 1)); do
        s="${table_to_print[i]/†/x}"
        length=${#s}
        nspaces[i]=$((${maxlengths[${c}]} - ${length}))
        ((c += 1))
        [ ${c} == ${nc} ] && c=0
    done
    # Reinsert spaces
    table_to_print=("${table_with_esc[@]}")
    modify_element "~" " "
    # Print the table
    c=0
    for ((i = 0; i < nelements; i += 1)); do
        printf "${table_to_print[i]}"  # Print element
        [ ${nspaces[i]} -gt 0 ] && printf ' %.0s' $(eval "echo {1..${nspaces[i]}}")  # Print spaces
        ((c += 1))
        [ ${c} == ${nc} ] ||        printf "  "  # Print extra spaces
        [ ${c} == ${nc} ] && c=0 && printf "\n"  # Print newline
    done
}

# Write out installation overview.
# This overview take the form of the following tables.
# Programs which should not be installed will not be shown.
# Programs already installed and programs to be patched by this
# install script will be noted.
#
# The following software will be installed
# Name           Version  Installation path
# CO𝘕CEPT        ...      "/..."
# OpenBLAS       ...      "/..."
# CLASS          ...      "/..."
# FFTW           ...      "/..."
# FFTW           ...      "/..."
# FreeType       ...      "/..."
# GADGET         ...      "/..."
# GSL            ...      "/..."
# HDF5           ...      "/..."
# libffi         ...      "/..."
# MPICH/OpenMPI  ...      "/..."
# ncurses        ...      "/..."
# OpenSSL        ...      "/..."
# Perl           ...      "/..."
# Python         ...      "/..."
# zlib           ...      "/..."
#
# The following Python packages will be installed
# Name               Version
# Blessings          ...
# Cython             ...
# CythonGSL          ...
# H5Py               ...
# Matplotlib         ...
# MPI4Py             ...
# NumPy              ...
# SciPy              ...
# Sphinx             ...
# Sphinx_copybutton  ...
# Sphinx_rtd_theme   ...
# Sphinx_tabs        ...
blas_patch="False"
class_patch="True"
concept_patch="False"
fftw_patch="False"
fftw_for_gadget_patch="False"
freetype_patch="False"
gadget_patch="True"
gsl_patch="False"
hdf5_patch="False"
libffi_patch="False"
if [ "${mpi}" == "mpich" ]; then
    mpi_patch="False"
elif [ "${mpi}" == "openmpi" ]; then
    mpi_patch="False"
fi
openmpi_patch="False"
ncurses_patch="False"
openssl_patch="False"
perl_patch="False"
python_patch="False"
zlib_patch="False"
blessings_patch="False"
cython_patch="False"
cythongsl_patch="False"
h5py_patch="False"
matplotlib_patch="False"
mpi4py_patch="False"
numpy_patch="False"
scipy_patch="False"
sphinx_patch="False"
sphinx_copybutton_patch="False"
sphinx_rtd_theme_patch="False"
sphinx_tabs_patch="False"
footnote_patch="${esc_blue}*${esc_normal}"
footnote_installed="${esc_green}†${esc_normal}"
insert_footnote_patch() {
    # Argument: Program/Python package name
    eval "program_installed=\"\${${1}_installed}\""
    eval "program_patch=\"\${${1}_patch}\""
    if [ "${program_installed}" == "False" ] && [ "${program_patch}" == "True" ]; then
        echo "${footnote_patch}"
    fi
}
insert_footnote_installed() {
    # Argument: Program/Python package name
    eval "program_installed=\"\${${1}_installed}\""
    if [ "${program_installed}" == "True" ]; then
        echo "${footnote_installed}"
    fi
}
if [ "${install_anything}" == "True" ]; then
    disable_status
    current_step="presentation of installation overview"
    heading "Installation overview"
fi
# Print out software installation overview
if [ "${install_any_software}" == "True" ]; then
    # Title
    table=("${esc_bold}Name${esc_normal}"    \
           "${esc_bold}Version${esc_normal}" \
           "${esc_bold}Installation path${esc_normal}")
    # CO𝘕CEPT
    if [ "${concept_install}" == "True" ]; then
        table=("${table[@]}"                                       \
            "${esc_concept}$(insert_footnote_installed 'concept')" \
            "${concept_version}$(insert_footnote_patch 'concept')" \
            "\"${concept_dir}\"")
    fi
    # OpenBLAS
    if [ "${blas_install}" == "True" ]; then
        table=("${table[@]}"                                 \
            "OpenBLAS$(insert_footnote_installed 'blas')"    \
            "${blas_version}$(insert_footnote_patch 'blas')" \
            "\"${blas_dir}\"")
    fi
    # CLASS
    if [ "${class_install}" == "True" ]; then
        table=("${table[@]}"                                   \
            "CLASS$(insert_footnote_installed 'class')"        \
            "${class_version}$(insert_footnote_patch 'class')" \
            "\"${class_dir}\"")
    fi
    # FFTW
    if [ "${fftw_install}" == "True" ]; then
        table=("${table[@]}"                                 \
            "FFTW$(insert_footnote_installed 'fftw')"        \
            "${fftw_version}$(insert_footnote_patch 'fftw')" \
            "\"${fftw_dir}\"")
    fi
    # FFTW for gadget
    if [ "${fftw_for_gadget_install}" == "True" ]; then
        table=("${table[@]}"                                                       \
            "FFTW$(insert_footnote_installed 'fftw_for_gadget')"                   \
            "${fftw_for_gadget_version}$(insert_footnote_patch 'fftw_for_gadget')" \
            "\"${fftw_for_gadget_dir}\"")
    fi
    # FreeType
    if [ "${freetype_install}" == "True" ]; then
        table=("${table[@]}"                                         \
            "FreeType$(insert_footnote_installed 'freetype')"        \
            "${freetype_version}$(insert_footnote_patch 'freetype')" \
            "\"${freetype_dir}\"")
    fi
    # GADGET
    if [ "${gadget_install}" == "True" ]; then
        table=("${table[@]}"                                     \
            "GADGET$(insert_footnote_installed 'gadget')"        \
            "${gadget_version}$(insert_footnote_patch 'gadget')" \
            "\"${gadget_dir}\"")
    fi
    # GSL
    if [ "${gsl_install}" == "True" ]; then
        table=("${table[@]}"                               \
            "GSL$(insert_footnote_installed 'gsl')"        \
            "${gsl_version}$(insert_footnote_patch 'gsl')" \
            "\"${gsl_dir}\"")
    fi
    # HDF5
    if [ "${hdf5_install}" == "True" ]; then
        table=("${table[@]}"                                 \
            "HDF5$(insert_footnote_installed 'hdf5')"        \
            "${hdf5_version}$(insert_footnote_patch 'hdf5')" \
            "\"${hdf5_dir}\"")
    fi
    # libffi
    if [ "${libffi_install}" == "True" ]; then
        table=("${table[@]}"                                     \
            "libffi$(insert_footnote_installed 'libffi')"        \
            "${libffi_version}$(insert_footnote_patch 'libffi')" \
            "\"${libffi_dir}\"")
    fi
    # MPICH/OpenMPI
    if [ "${mpi_install}" == "True" ]; then
        if [ "${mpi}" == "mpich" ]; then
            table=("${table[@]}"                               \
                "MPICH$(insert_footnote_installed 'mpi')"      \
                "${mpi_version}$(insert_footnote_patch 'mpi')" \
                "\"${mpi_dir}\"")
        elif [ "${mpi}" == "openmpi" ]; then
            table=("${table[@]}"                               \
                "OpenMPI$(insert_footnote_installed 'mpi')"    \
                "${mpi_version}$(insert_footnote_patch 'mpi')" \
                "\"${mpi_dir}\"")
        fi
    fi
    # ncurses
    if [ "${ncurses_install}" == "True" ]; then
        table=("${table[@]}"                                       \
            "ncurses$(insert_footnote_installed 'ncurses')"        \
            "${ncurses_version}$(insert_footnote_patch 'ncurses')" \
            "\"${ncurses_dir}\"")
    fi
    # OpenSSL
    if [ "${openssl_install}" == "True" ]; then
        table=("${table[@]}"                                       \
            "OpenSSL$(insert_footnote_installed 'openssl')"        \
            "${openssl_version}$(insert_footnote_patch 'openssl')" \
            "\"${openssl_dir}\"")
    fi
    # Perl
    if [ "${perl_install}" == "True" ]; then
        table=("${table[@]}"                                 \
            "Perl$(insert_footnote_installed 'perl')"        \
            "${perl_version}$(insert_footnote_patch 'perl')" \
            "\"${perl_dir}\"")
    fi
    # Python
    if [ "${python_install}" == "True" ]; then
        table=("${table[@]}"                                     \
            "Python$(insert_footnote_installed 'python')"        \
            "${python_version}$(insert_footnote_patch 'python')" \
            "\"${python_dir}\"")
    fi
    # zlib
    if [ "${zlib_install}" == "True" ]; then
        table=("${table[@]}"                                 \
            "zlib$(insert_footnote_installed 'zlib')"        \
            "${zlib_version}$(insert_footnote_patch 'zlib')" \
            "\"${zlib_dir}\"")
    fi
    echo "The following software will be installed"
    print_table table[@] 3
    N_to_be_patched=0
    for ((i = 4; i < ${#table[@]}; i += 3)); do
        if [[ "${table[i]}" == *"${footnote_patch}" ]]; then
            ((N_to_be_patched += 1))
        fi
    done
    N_installed=0
    for ((i = 3; i<${#table[@]}; i += 3)); do
        if [[ "${table[i]}" == *"${footnote_installed}" ]]; then
            ((N_installed += 1))
        fi
    done
fi

# Print out Python package installation overview
if [ "${install_any_pypackages}" == "True" ]; then
    # Title
    table=("${esc_bold}Name${esc_normal}" "${esc_bold}Version${esc_normal}" "")
    # Blessings
    if [ "${blessings_install}" == "True" ]; then
        table=("${table[@]}"                                           \
            "Blessings$(insert_footnote_installed 'blessings')"        \
            "${blessings_version}$(insert_footnote_patch 'blessings')" \
            "")
    fi
    # Cython
    if [ "${cython_install}" == "True" ]; then
        table=("${table[@]}"                                     \
            "Cython$(insert_footnote_installed 'cython')"        \
            "${cython_version}$(insert_footnote_patch 'cython')" \
            "")
    fi
    # CythonGSL
    if [ "${cythongsl_install}" == "True" ]; then
           table=("${table[@]}"                                        \
            "CythonGSL$(insert_footnote_installed 'cythongsl')"        \
            "${cythongsl_version}$(insert_footnote_patch 'cythongsl')" \
            "")
    fi
    # H5Py
    if [ "${h5py_install}" == "True" ]; then
        table=("${table[@]}"                                 \
            "H5Py$(insert_footnote_installed 'h5py')"        \
            "${h5py_version}$(insert_footnote_patch 'h5py')" \
            "")
    fi
    # Matplotlib
    if [ "${matplotlib_install}" == "True" ]; then
        table=("${table[@]}"                                             \
            "Matplotlib$(insert_footnote_installed 'matplotlib')"        \
            "${matplotlib_version}$(insert_footnote_patch 'matplotlib')" \
            "")
    fi
    # MPI4Py
    if [ "${mpi4py_install}" == "True" ]; then
        table=("${table[@]}"                                     \
            "MPI4Py$(insert_footnote_installed 'mpi4py')"        \
            "${mpi4py_version}$(insert_footnote_patch 'mpi4py')" \
            "")
    fi
    # NumPy
    if [ "${numpy_install}" == "True" ]; then
        table=("${table[@]}"                                   \
            "NumPy$(insert_footnote_installed 'numpy')"        \
            "${numpy_version}$(insert_footnote_patch 'numpy')" \
            "")
    fi
    # SciPy
    if [ "${scipy_install}" == "True" ]; then
        table=("${table[@]}"                                   \
            "SciPy$(insert_footnote_installed 'scipy')"        \
            "${scipy_version}$(insert_footnote_patch 'scipy')" \
            "")
    fi
    # Sphinx
    if [ "${sphinx_install}" == "True" ]; then
        table=("${table[@]}"                                     \
            "Sphinx$(insert_footnote_installed 'sphinx')"        \
            "${sphinx_version}$(insert_footnote_patch 'sphinx')" \
            "")
    fi
    # sphinx_copybutton
    if [ "${sphinx_copybutton_install}" == "True" ]; then
        table=("${table[@]}"                                                           \
            "Sphinx_copybutton$(insert_footnote_installed 'sphinx_copybutton')"        \
            "${sphinx_copybutton_version}$(insert_footnote_patch 'sphinx_copybutton')" \
            "")
    fi
    # sphinx_rtd_theme
    if [ "${sphinx_rtd_theme_install}" == "True" ]; then
        table=("${table[@]}"                                                         \
            "Sphinx_rtd_theme$(insert_footnote_installed 'sphinx_rtd_theme')"        \
            "${sphinx_rtd_theme_version}$(insert_footnote_patch 'sphinx_rtd_theme')" \
            "")
    fi
    # sphinx_tabs
    if [ "${sphinx_tabs_install}" == "True" ]; then
        table=("${table[@]}"                                               \
            "Sphinx_tabs$(insert_footnote_installed 'sphinx_tabs')"        \
            "${sphinx_tabs_version}$(insert_footnote_patch 'sphinx_tabs')" \
            "")
    fi
    if [ "${install_any_software}" ]; then
        echo
    fi
    echo "The following Python packages will be installed"
    print_table table[@] 3
    for ((i = 3; i < ${#table[@]}; i += 3)); do
        if [[ "${table[i]}" == *"${footnote_patch}" ]]; then
            ((N_installed += 1))
        fi
    done
    for ((i = 4; i < ${#table[@]}; i += 3)); do
        if [[ "${table[i]}" == *"${footnote_installed}" ]]; then
            ((N_to_be_patched += 1))
        fi
    done
fi
echo
if [ -n "${N_to_be_patched}" ]; then
    if [ ${N_to_be_patched} -eq 1 ]; then
        printf "${footnote_patch} This will be patched during installation\n"
    elif [ ${N_to_be_patched} -gt 1 ]; then
        printf "${footnote_patch} These will be patched during installation\n"
    fi
fi
if [ -n "${N_installed}" ]; then
    if [ ${N_installed} -eq 1 ]; then
        printf "${footnote_installed} This is already installed and will not be reinstalled\n"
    elif [ ${N_installed} -gt 1 ]; then
        printf "${footnote_installed} These are already installed and will not be reinstalled\n"
    fi
fi

# Find possible C, C++ and Fortran compilers to try out when building
# the various programs. The compiler possibilities will be gathered in
# the array "compiler_possibilities". An empty value corresponds to
# whatever compilers (if any) were set in the environment at the time of
# invocation of this script. For each compiler (e.g. "gnu") detected,
# there must be declared a corresponding function
# (e.g. "use_gnu_compilers"), the job of which is to set compiler
# environment variables such as CC, CXX and FC.
# Altering PATH-like environment variables is also allowed.
# The order in which the compilers appear in compiler_possibilities is
# the order in which they will be tried out when installing programs.
# This ordering may be set by the compiler_precedence
# environment variable.
compiler_precedence_supplied="False"
if [ -n "${compiler_precedence}" ]; then
    compiler_precedence_supplied="True"
fi
compiler_precedence="$(echo "${compiler_precedence}" | tr '[:upper:]' '[:lower:]')"
IFS=' ' read -r -a compiler_precedence_arr <<< "${compiler_precedence}"
compiler_precedence=("${compiler_precedence_arr[@]}")
compiler_precedence_default=( \
    "specified_mpi" "default" "gnu" "clang" "mpi" "intel" "cray" "portland" "generic" "unset")
for compiler in "${compiler_precedence_default[@]}"; do
    present=False
    for compiler_present in "${compiler_precedence[@]}"; do
        if [ "${compiler_present}" == "${compiler}" ]; then
            present=True
            break
        fi
    done
    if [ "${present}" == "False" ]; then
        compiler_precedence=("${compiler_precedence[@]}" "${compiler}")
    fi
done
discover_specified_mpi_compilers() {
    if [ "${mpi_preinstalled}" == "True" ]; then
        compiler_possibilities=("${compiler_possibilities[@]}" "specified_mpi")
    fi
}
discover_default_compilers() {
    compiler_possibilities=("${compiler_possibilities[@]}" "default")
}
discover_gnu_compilers() {
    for program in "gcc" "g++" "gfortran"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            compiler_possibilities=("${compiler_possibilities[@]}" "gnu")
            break
        fi
    done
}
discover_clang_compilers() {
    for program in "clang" "clang++"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            compiler_possibilities=("${compiler_possibilities[@]}" "clang")
            break
        fi
    done
}
discover_mpi_compilers() {
    for program in "mpicc" "mpiCC" "mpicxx" "mpic++" "mpifort" "mpif90"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            compiler_possibilities=("${compiler_possibilities[@]}" "mpi")
            break
        fi
    done
}
discover_intel_compilers() {
    for program in "icc" "icpc" "ifort"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            compiler_possibilities=("${compiler_possibilities[@]}" "intel")
            break
        fi
    done
}
discover_cray_compilers() {
    for program in "craycc" "crayCC" "crayftn"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            compiler_possibilities=("${compiler_possibilities[@]}" "cray")
            break
        fi
    done
}
discover_portland_compilers() {
    for program in "pgcc" "pgCC" "pgf77" "pgf90"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            compiler_possibilities=("${compiler_possibilities[@]}" "portland")
            break
        fi
    done
}
discover_generic_compilers() {
    for program in "cc" "c89" "c99" "CC" "c++" "ftn" "f77" "f90" "fortran"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            compiler_possibilities=("${compiler_possibilities[@]}" "generic")
            break
        fi
    done
}
discover_unset_compilers() {
    compiler_possibilities=("${compiler_possibilities[@]}" "unset")
}
compiler_possibilities=()
for compiler in "${compiler_precedence[@]}"; do
    eval "discover_${compiler}_compilers"
done
compiler_possibilities_specified_mpi_last=()
compiler_possibilities_specified_mpi=""
for compiler in "${compiler_possibilities[@]}"; do
    if     [ "${compiler_precedence_supplied}" == "False"         ] \
        && [ "${compiler}"                     == "specified_mpi" ] \
    ; then
        compiler_possibilities_specified_mpi="${compiler}"
    else
        compiler_possibilities_specified_mpi_last=(           \
            "${compiler_possibilities_specified_mpi_last[@]}" \
            "${compiler}"                                     \
        )
    fi
done
if [ -n "${compiler_possibilities_specified_mpi}" ]; then
    compiler_possibilities_specified_mpi_last=(           \
        "${compiler_possibilities_specified_mpi_last[@]}" \
        "${compiler_possibilities_specified_mpi}"         \
    )
fi
printf "\n${esc_bold}Compiler precedence${esc_normal}\n"
printf "${compiler_possibilities[0]}"
for ((i = 1; i < ${#compiler_possibilities[@]}; i += 1)); do
    compiler="${compiler_possibilities[$i]}"
    printf " > ${compiler}"
done
printf "\n"
if [ "${install_anything}" == "True" ]; then
    echo
    sleep ${sleep_time}
    enable_status
fi
use_default_compilers() {
    # This dummy function must exist
    :
}
use_specified_mpi_compilers() {
    local program program_path bin_path include_path lib_path
    if [ -n "${mpi_dir}" ] && [ -d "${mpi_dir}" ]; then
        compiler_path="${mpi_compilerdir}"
        bin_path="${mpi_bindir}"
        include_path="${mpi_includedir}"
        lib_path="${mpi_libdir}"
        for program in "mpicc" "mpiCC"; do
            program_path="${compiler_path}/${program}"
            if [ -f "${program_path}" ]; then
                export CC="${program_path}"
                break
            fi
            program_path="${bin_path}/${program}"
            if [ -f "${program_path}" ]; then
                export CC="${program_path}"
                break
            fi
        done
        for program in "mpicxx" "mpic++"; do
            program_path="${compiler_path}/${program}"
            if [ -f "${program_path}" ]; then
                export CXX="${program_path}"
                break
            fi
            program_path="${bin_path}/${program}"
            if [ -f "${program_path}" ]; then
                export CXX="${program_path}"
                break
            fi
        done
        for program in "mpif77"; do
            program_path="${compiler_path}/${program}"
            if [ -f "${program_path}" ]; then
                export FC="${program_path}"
                export F77="${program_path}"
                break
            fi
            program_path="${bin_path}/${program}"
            if [ -f "${program_path}" ]; then
                export FC="${program_path}"
                export F77="${program_path}"
                break
            fi
        done
        for program in "mpifort" "mpif90"; do
            program_path="${compiler_path}/${program}"
            if [ -f "${program_path}" ]; then
                export FC="${program_path}"
                export F90="${program_path}"
                export F9X="${program_path}"
                break
            fi
            program_path="${bin_path}/${program}"
            if [ -f "${program_path}" ]; then
                export FC="${program_path}"
                export F90="${program_path}"
                export F9X="${program_path}"
                break
            fi
        done
        if [ -d "${compiler_path}" ]; then
            export PATH="${compiler_path}:${PATH}"
        fi
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CFLAGS="-I${include_path} ${CFLAGS}"
            export CXXFLAGS="-I${include_path} ${CXXFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
            export FFLAGS="-I${include_path} ${FFLAGS}"
            export FCFLAGS="-I${include_path} ${FCFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
        # When mixing MPICH and Intel MPI, some symlinking is required
        # due to different library names, as described in section 11 of
        # https://www.mpich.org/static/downloads/3.1/mpich-3.1-README.txt
        mkdir -p "${mpi_symlinkdir}"
        mpi_symlink_pairs=(                      \
            "libmpi.so"      "libmpich.so.12"    \
            "libmpi_dbg.so"  "libmpich.so.12"    \
            "libmpigc4.so"   "libmpichcxx.so.12" \
            "libmpigc4.so"   "libmpichcxx.so.12" \
            "libmpigf.so"    "libfmpich.so.12"   \
            "libmpigf.so"    "libmpichf90.so.12" \
            "libmpi_dbg.so"  "libmpl.so.1"       \
            "libmpi.so"      "libmpl.so.1"       \
            "libmpi.so"      "libopa.so.1"       \
            "libmpi_dbg.so"  "libopa.so.1"       \
            "libmpich.so"    "libmpi.so.5"       \
            "libmpich.so"    "libmpi_dbg.so.5"   \
            "libmpichcxx.so" "libmpigc4.so.5"    \
            "libmpichf90.so" "libmpigf.so.5"     \
            "libmpi.so"      "libmpi.so"         \
            "libmpi.so"      "libmpi.so.5"       \
            "libmpi.so"      "libmpi.so.12"      \
            "libmpi.so.5"    "libmpi.so"         \
            "libmpi.so.5"    "libmpi.so.5"       \
            "libmpi.so.5"    "libmpi.so.12"      \
            "libmpi.so.12"   "libmpi.so"         \
            "libmpi.so.12"   "libmpi.so.5"       \
            "libmpi.so.12"   "libmpi.so.12"      \
        )
        any_mpi_symlinks="False"
        for ((mpi_symlink_index = 0; mpi_symlink_index < ${#mpi_symlink_pairs[@]}; \
            mpi_symlink_index += 2)); do
            ((mpi_symlink_name_index = mpi_symlink_index + 1))
            mpi_symlink="${lib_path}/${mpi_symlink_pairs[${mpi_symlink_index}]}"
            mpi_symlink_name="${mpi_symlinkdir}/${mpi_symlink_pairs[${mpi_symlink_name_index}]}"
            if [ -f "${mpi_symlink}" ]; then
                any_mpi_symlinks="True"
                if [ ! -f "${mpi_symlink_name}" ]; then
                    ln -s "${mpi_symlink}" "${mpi_symlink_name}" >/dev/null 2>&1 || :
                fi
            fi
        done
        # Add symlinks to IBM / Spectrum MPI libraries as well
        for f in "${lib_path}/"*; do
            if [ ! -f "${f}" ]; then
                continue
            fi
            f_base="$(basename "${f}")"
            if [[ "${f_base}" == *"_ibm."* ]] || [[ "${f_base}" == *"_ibm_"* ]]; then
                any_mpi_symlinks="True"
                mpi_symlink_name="${f_base/_ibm_/_}"
                mpi_symlink_name="${mpi_symlink_name/_ibm./.}"
                mpi_symlink_name="${mpi_symlinkdir}/${mpi_symlink_name}"
                if [ ! -f "${mpi_symlink_name}" ]; then
                    ln -s "${f}" "${mpi_symlink_name}" >/dev/null 2>&1 || :
                fi
            fi
        done
        if [ "${any_mpi_symlinks}" == "True" ]; then
            export LDFLAGS="${LDFLAGS} -L${mpi_symlinkdir}"
            export LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:${mpi_symlinkdir}"
            # Using MVAPICH2 together with Python (or Fortran) can cause
            # trouble as described in section 9.1.1 of
            # https://mvapich.cse.ohio-state.edu/static/media/mvapich/
            # mvapich2-2.3b-userguide.html#x1-1280009.1.1
            # Setting the LD_PRELOAD variable should fix this.
            if [ ! -f "${mpi_symlinkdir}/ld_preload.so" ]; then
                current_dir="$(pwd)"
                cd "${mpi_symlinkdir}"
                f_lib=""
                n_lib=""
                for f in *; do
                    if [[ "${f}" == "libmpi.so"* ]]; then
                        n="${f#*.}"
                        if [ "${n}" == "so" ]; then
                            f_lib="${f}"
                            break
                        fi
                        n="${n#*.}"
                        if [ -z "${n_lib}" ] || [[ "${n_lib}" == *"."* ]] \
                            || [ "${n}" -lt "${n_lib}" ]; then
                            f_lib="${f}"
                            n_lib="${n}"
                        fi
                    fi
                done
                cd "${current_dir}"
                if [ -n "${f_lib}" ]; then
                    ln -s "${mpi_symlinkdir}/${f_lib}" "${mpi_symlinkdir}/ld_preload.so" \
                        >/dev/null 2>&1 || :
                fi
            fi
            if [ -f "${mpi_symlinkdir}/ld_preload.so" ]; then
                export LD_PRELOAD="${LD_PRELOAD} ${mpi_symlinkdir}/ld_preload.so"
            fi
        else
            rm -rf "${mpi_symlinkdir}"
        fi
        # Test whether the MPI environment is sane.
        # If not, a warning will be printed,
        # but the installation will carry on regardless.
        current_dir="$(pwd)"
        MPI_LIBS_backup="${MPI_LIBS}"
        if [ -d "${mpi_libdir}" ]; then
            MPI_LIBS="${MPI_LIBS} -L${mpi_libdir} -Wl,-rpath=${mpi_libdir}"
        fi
        if [ -d "${mpi_symlinkdir}" ]; then
            MPI_LIBS="${MPI_LIBS} -L${mpi_symlinkdir} -Wl,-rpath=${mpi_symlinkdir}"
        fi
        if [ -d "${mpi_libdir}" ]; then
            cd "${mpi_libdir}"
            mpi_lib_found="False"
            for f in *; do
                if [[ "${f}" == libmpi.* ]]; then
                    MPI_LIBS="${MPI_LIBS} -lmpi"
                    mpi_lib_found="True"
                    break
                fi
            done
            if [ "${mpi_lib_found}" == "False" ]; then
                for f in *; do
                    if [[ "${f}" == libmpich.* ]]; then
                        MPI_LIBS="${MPI_LIBS} -lmpich"
                        mpi_lib_found="True"
                        break
                    fi
                done
            fi
            cd "${current_dir}"
        fi
        mpi_test_dir="${tmp_dir}/mpi_test"
        rm -rf "${mpi_test_dir}" || :
        mkdir -p "${mpi_test_dir}"
        cd "${mpi_test_dir}"
        echo '
#include <mpi.h>
#include <stdio.h>
int main(int argc, char *argv[]) {
  MPI_Init(&argc, &argv);
  int master_rank = 0;
  int rank, number, sum;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  if (rank == 0) {
    number = 22;
    MPI_Send(&number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
  } else if (rank == 1) {
    MPI_Recv(&number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
  } else {
    number = -1;
  }
  MPI_Reduce(&number, &sum, 1, MPI_INT, MPI_SUM, master_rank, MPI_COMM_WORLD);
  if (rank == 0) {
    printf("\nMPI test result = %d\n", sum);
  }
  MPI_Finalize();
  return 0;
}
' > "test.c"
        mpicc ${CFLAGS} -c -o "test.o" "test.c" >/dev/null 2>&1 || :
        mpicc "test.o" -o "test" ${LDFLAGS} ${MPI_LIBS} >/dev/null 2>&1 || :
        # When running locally on a cluster, it may be necessary to
        # supply an additional argument to mpiexec. This additional
        # argument is captured by mpiexec_extra_args_local.
        mpi_environment_test_success="False"
        for mpiexec_extra_args_local in "" "-pami_noib"; do
            mpi_environment_result="$(                                                        \
                "${mpi_bindir}/mpiexec" ${mpiexec_extra_args_local} -n 4 "./test" 2>/dev/null \
                | grep 'MPI test result =' | awk '{print $NF}' || : \
            )"
            if [ "${mpi_environment_result}" == "42" ]; then
                mpi_environment_test_success="True"
                break
            fi
        done
        cd "${current_dir}"
        rm -rf "${mpi_test_dir}" || :
        MPI_LIBS="${MPI_LIBS_backup}"
        if [ "${mpi_environment_test_success}" == "False" ]; then
            printf "\n\nWarning: The MPI environment does not appear sane!\n\n"
        fi
    fi
}
use_gnu_compilers() {
    local program_path bin_path include_path lib_path
    program_path="$(get_command "gcc")" || :
    if [ -n "${program_path}" ]; then
        export CC="${program_path}"
        export CXX="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CFLAGS="-I${include_path} ${CFLAGS}"
            export CXXFLAGS="-I${include_path} ${CXXFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "g++")" || :
    if [ -n "${program_path}" ]; then
        export CXX="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CXXFLAGS="-I${include_path} ${CXXFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "gfortran")" || :
    if [ -n "${program_path}" ]; then
        export FC="${program_path}"
        export F77="${program_path}"
        export F90="${program_path}"
        export F9X="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export FFLAGS="-I${include_path} ${FFLAGS}"
            export FCFLAGS="-I${include_path} ${FCFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
}
use_clang_compilers() {
    local program_path bin_path include_path lib_path
    program_path="$(get_command "clang")" || :
    if [ -n "${program_path}" ]; then
        export CC="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CFLAGS="-I${include_path} ${CFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "clang++")" || :
    if [ -n "${program_path}" ]; then
        export CXX="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CXXFLAGS="-I${include_path} ${CXXFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    # Clang does not have a Fortran compiler
}
use_mpi_compilers() {
    local program program_path bin_path include_path lib_path
    for program in "mpicc" "mpiCC"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            export CC="${program_path}"
            bin_path="$(dirname "${program_path}")"
            mpicc_show="$("${CC}" -show || :)"
            lib_paths="$(echo "${mpicc_show}" | grep -o '\-L[^ ]*' || :)"
            n_lib_paths=$(echo "${lib_paths}" | wc -l)
            if [ ${n_lib_paths} -eq 1 ]; then
                lib_path="${lib_paths:2}"
            else
                # Several lib directories exist.
                # Merge them via symlinking.
                lib_path_merged="${mpi_symlinkdir}/merged_lib"
                mkdir -p "${lib_path_merged}"
                while read lib_path; do
                    lib_path="${lib_path:2}"
                    if [ -d "${lib_path}" ]; then
                        for f in "${lib_path}/"*; do
                            f_base="$(basename "${f}")"
                            mpi_symlink_name="${lib_path_merged}/${f_base}"
                            if     [ ! -f "${mpi_symlink_name}" ] \
                                && [ ! -d "${mpi_symlink_name}" ]; then
                                ln -s "${f}" "${mpi_symlink_name}" >/dev/null 2>&1 || :
                            fi
                        done
                    fi
                done <<< "${lib_paths}"
                lib_path="${lib_path_merged}"
            fi
            if [ ! -d "${lib_path}" ]; then
                lib_path="$(dirname "${bin_path}")/lib"
            fi
            include_paths="$(echo "${mpicc_show}" | grep -o '\-I[^ ]*' || :)"
            n_include_paths=$(echo "${include_paths}" | wc -l)
            if [ ${n_include_paths} -eq 1 ]; then
                include_path="${include_paths:2}"
            else
                # Several include directories exist.
                # Merge them via symlinking.
                include_path_merged="${mpi_symlinkdir}/merged_include"
                mkdir -p "${include_path_merged}"
                while read include_path; do
                    include_path="${include_path:2}"
                    if [ -d "${include_path}" ]; then
                        for f in "${include_path}/"*; do
                            f_base="$(basename "${f}")"
                            mpi_symlink_name="${include_path_merged}/${f_base}"
                            if     [ ! -f "${mpi_symlink_name}" ] \
                                && [ ! -d "${mpi_symlink_name}" ]; then
                                ln -s "${f}" "${mpi_symlink_name}" >/dev/null 2>&1 || :
                            fi
                        done
                    fi
                done <<< "${include_paths}"
                include_path="${include_path_merged}"
            fi
            if [ ! -d "${include_path}" ]; then
                include_path="$(dirname "${bin_path}")/include"
            fi
            if [ -d "${bin_path}" ]; then
                export PATH="${bin_path}:${PATH}"
            fi
            if [ -d "${include_path}" ]; then
                export CFLAGS="-I${include_path} ${CFLAGS}"
                export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
            fi
            if [ -d "${lib_path}" ]; then
                export LDFLAGS="-L${lib_path} ${LDFLAGS}"
                export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
            fi
            break
        fi
    done
    for program in "mpicxx" "mpic++"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            export CXX="${program_path}"
            bin_path="$(dirname "${program_path}")"
            include_path="${bin_path}/../include"
            lib_path="${bin_path}/../lib"
            if [ -d "${bin_path}" ]; then
                export PATH="${bin_path}:${PATH}"
            fi
            if [ -d "${include_path}" ]; then
                export CXXFLAGS="-I${include_path} ${CXXFLAGS}"
                export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
            fi
            if [ -d "${lib_path}" ]; then
                export LDFLAGS="-L${lib_path} ${LDFLAGS}"
                export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
            fi
            break
        fi
    done
    program_path="$(get_command "mpif77")" || :
    if [ -n "${program_path}" ]; then
        export FC="${program_path}"
        export F77="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export FFLAGS="-I${include_path} ${FFLAGS}"
            export FCFLAGS="-I${include_path} ${FCFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    for program in "mpifort" "mpif90"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            export FC="${program_path}"
            export F90="${program_path}"
            export F9X="${program_path}"
            bin_path="$(dirname "${program_path}")"
            include_path="${bin_path}/../include"
            lib_path="${bin_path}/../lib"
            if [ -d "${bin_path}" ]; then
                export PATH="${bin_path}:${PATH}"
            fi
            if [ -d "${include_path}" ]; then
                export FFLAGS="-I${include_path} ${FFLAGS}"
                export FCFLAGS="-I${include_path} ${FCFLAGS}"
            fi
            if [ -d "${lib_path}" ]; then
                export LDFLAGS="-L${lib_path} ${LDFLAGS}"
                export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
            fi
            break
        fi
    done
}
use_intel_compilers() {
    local program_path bin_path include_path lib_path
    program_path="$(get_command "icc")" || :
    if [ -n "${program_path}" ]; then
        export CC="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CFLAGS="-I${include_path} ${CFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "icpc")" || :
    if [ -n "${program_path}" ]; then
        export CXX="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CXXFLAGS="-I${include_path} ${CXXFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "ifort")" || :
    if [ -n "${program_path}" ]; then
        export FC="${program_path}"
        export F77="${program_path}"
        export F90="${program_path}"
        export F9X="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export FFLAGS="-I${include_path} ${FFLAGS}"
            export FCFLAGS="-I${include_path} ${FCFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
}
use_cray_compilers() {
    local program_path bin_path include_path lib_path
    program_path="$(get_command "craycc")" || :
    if [ -n "${program_path}" ]; then
        export CC="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CFLAGS="-I${include_path} ${CFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "crayCC")" || :
    if [ -n "${program_path}" ]; then
        export CXX="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CXXFLAGS="-I${include_path} ${CXXFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "crayftn")" || :
    if [ -n "${program_path}" ]; then
        export FC="${program_path}"
        export F77="${program_path}"
        export F90="${program_path}"
        export F9X="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export FFLAGS="-I${include_path} ${FFLAGS}"
            export FCFLAGS="-I${include_path} ${FCFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
}
use_portland_compilers() {
    local program_path bin_path include_path lib_path
    program_path="$(get_command "pgcc")" || :
    if [ -n "${program_path}" ]; then
        export CC="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CFLAGS="-I${include_path} ${CFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "pgCC")" || :
    if [ -n "${program_path}" ]; then
        export CXX="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export CXXFLAGS="-I${include_path} ${CXXFLAGS}"
            export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "pgf77")" || :
    if [ -n "${program_path}" ]; then
        export FC="${program_path}"
        export F77="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export FFLAGS="-I${include_path} ${FFLAGS}"
            export FCFLAGS="-I${include_path} ${FCFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    program_path="$(get_command "pgf90")" || :
    if [ -n "${program_path}" ]; then
        export FC="${program_path}"
        export F90="${program_path}"
        export F9X="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export FFLAGS="-I${include_path} ${FFLAGS}"
            export FCFLAGS="-I${include_path} ${FCFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
}
use_generic_compilers() {
    local program program_path bin_path include_path lib_path
    for program in "cc" "c89" "c99"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            export CC="${program_path}"
            bin_path="$(dirname "${program_path}")"
            include_path="${bin_path}/../include"
            lib_path="${bin_path}/../lib"
            if [ -d "${bin_path}" ]; then
                export PATH="${bin_path}:${PATH}"
            fi
            if [ -d "${include_path}" ]; then
                export CFLAGS="-I${include_path} ${CFLAGS}"
                export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
            fi
            if [ -d "${lib_path}" ]; then
                export LDFLAGS="-L${lib_path} ${LDFLAGS}"
                export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
            fi
            break
        fi
    done
    for program in "CC" "c++"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            export CXX="${program_path}"
            bin_path="$(dirname "${program_path}")"
            include_path="${bin_path}/../include"
            lib_path="${bin_path}/../lib"
            if [ -d "${bin_path}" ]; then
                export PATH="${bin_path}:${PATH}"
            fi
            if [ -d "${include_path}" ]; then
                export CXXFLAGS="-I${include_path} ${CXXFLAGS}"
                export CPPFLAGS="-I${include_path} ${CPPFLAGS}"
            fi
            if [ -d "${lib_path}" ]; then
                export LDFLAGS="-L${lib_path} ${LDFLAGS}"
                export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
            fi
            break
        fi
    done
    program_path="$(get_command "f77")" || :
    if [ -n "${program_path}" ]; then
        export FC="${program_path}"
        export F77="${program_path}"
        bin_path="$(dirname "${program_path}")"
        include_path="${bin_path}/../include"
        lib_path="${bin_path}/../lib"
        if [ -d "${bin_path}" ]; then
            export PATH="${bin_path}:${PATH}"
        fi
        if [ -d "${include_path}" ]; then
            export FFLAGS="-I${include_path} ${FFLAGS}"
            export FCFLAGS="-I${include_path} ${FCFLAGS}"
        fi
        if [ -d "${lib_path}" ]; then
            export LDFLAGS="-L${lib_path} ${LDFLAGS}"
            export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
        fi
    fi
    for program in "ftn" "f90" "f9x" "fortran"; do
        program_path="$(get_command "${program}")" || :
        if [ -n "${program_path}" ]; then
            export FC="${program_path}"
            export F90="${program_path}"
            export F9X="${program_path}"
            bin_path="$(dirname "${program_path}")"
            include_path="${bin_path}/../include"
            lib_path="${bin_path}/../lib"
            if [ -d "${bin_path}" ]; then
                export PATH="${bin_path}:${PATH}"
            fi
            if [ -d "${include_path}" ]; then
                export FFLAGS="-I${include_path} ${FFLAGS}"
                export FCFLAGS="-I${include_path} ${FCFLAGS}"
            fi
            if [ -d "${lib_path}" ]; then
                export LDFLAGS="-L${lib_path} ${LDFLAGS}"
                export LD_LIBRARY_PATH="${lib_path}:${LD_LIBRARY_PATH}"
            fi
            break
        fi
    done
}
use_unset_compilers() {
    unset CC CXX FC F90 F9X CFLAGS CXXFLAGS CPPFLAGS FCFLAGS FFLAGS LDFLAGS
}



#################################
# Download CO𝘕CEPT dependencies #
#################################
# Function for downloading compressed archives
download() {
    # Arguments: Program name, [print heading], [URL]
    progname_formatted="$1"
    progname="${progname_formatted// /_}"
    progname="$(echo "${progname}" | tr '[:upper:]' '[:lower:]')"
    print_heading="$2"
    url="$3"
    if [ -z "${print_heading}" ]; then
        print_heading="True"
    fi
    # Do not download if already fully downloaded
    eval "prog_downloaded=\"\${${progname}_downloaded}\""
    if [ "${prog_downloaded}" == "True" ]; then
        return
    fi
    eval "progversion=\"\${${progname}_version}\""
    if [ "${print_heading}" != "False" ]; then
        if [ "${progname}" == "blas" ]; then
            current_step="the downloading of OpenBLAS ${progversion}"
            heading "Downloading OpenBLAS ${progversion}"
        elif [ "${progname}" == "fftw_for_gadget" ]; then
            # When downloading FFTW for GADGET, the version number should
            # be printed together with FFTW, not GADGET.
            current_step="the downloading of FFTW ${progversion} for GADGET"
            heading "Downloading FFTW ${progversion} for GADGET"
        elif [ "${progname}" == "mpi" ]; then
            current_step="the downloading of ${mpi_formatted} ${progversion}"
            heading "Downloading ${mpi_formatted} ${progversion}"
        else
            current_step="the downloading of ${1/CONCEPT/$esc_concept} ${progversion}"
            heading "Downloading ${1/CONCEPT/$esc_concept} ${progversion}"
        fi
    fi
    if [ -z "${url}" ]; then
        eval "url=\"\${${progname}_url}\""
    fi
    # Download
    mkdir -p "${tmp_dir}/${progname}"
    cd "${tmp_dir}/${progname}"
    _download() {
        for n in {1..10}; do
            for ipv in "--inet4-only" "--inet6-only" ""; do
                for no_dns_cache in "--no-dns-cache" ""; do
                    for no_check_certificate in "" "--no-check-certificate"; do
                        for progressbar in "--progress=bar:force" ""; do
                            # Redirect stderr to the TTY, in order to
                            # show the progress bar.
                            tty_connected="True"
                            (printf "" >/dev/tty) 2>/dev/null || tty_connected="False"
                            exec 3>&2
                            if [ "${tty_connected}" == "True" ]; then
                                exec 3<> /dev/tty || :
                            fi
                            # Attempt the download
                            wget_status="success"
                            wget                        \
                                ${progressbar}          \
                                -c                      \
                                -t 1                    \
                                --timeout 60            \
                                ${no_check_certificate} \
                                ${no_dns_cache}         \
                                ${ipv}                  \
                                "${url}"                \
                                2>&3                    \
                                || wget_status="error"
                            exec 3>&-
                            if [ "${wget_status}" == "success" ]; then
                                return
                            fi
                        done
                    done
                done
            done
            sleep 5
        done
    }
    _download
    if [ "${wget_status}" == "error" ]; then
        error "Error downloading \"${url}\""
        exit 1
    fi
    # Write out success notice
    echo "The following has been fully downloaded:
File:    $(ls -t -1 | head -n 1)
URL:     ${url}
Program: ${progname_formatted}
Version: ${progversion}
Date:    $(date)
" > ".download_finished"
    cd "${concept_dir}"
}

# Make the directory in which to dump all downloaded archives
mkdir -p "${tmp_dir}"
# Download the source code for all programs that should be installed
disable_status
if [ "${concept_install}" == "True" ] && [ "${concept_downloaded}" == "False" ]; then
    download "CONCEPT"
fi
if [ "${blas_install}" == "True" ] && [ "${blas_downloaded}" == "False" ]; then
    download "BLAS"
fi
if [ "${class_install}" == "True" ] && [ "${class_downloaded}" == "False" ]; then
    download "CLASS"
fi
if [ "${fftw_install}" == "True" ] && [ "${fftw_downloaded}" == "False" ]; then
    download "FFTW"
fi
if [ "${fftw_for_gadget_install}" == "True" ] \
    && [ "${fftw_for_gadget_downloaded}" == "False" ]; then
    download "FFTW for GADGET"
fi
if [ "${freetype_install}" == "True" ] && [ "${freetype_downloaded}" == "False" ]; then
    download "FreeType"
fi
if [ "${gadget_install}" == "True" ] && [ "${gadget_downloaded}" == "False" ]; then
    download "GADGET"
fi
if [ "${gsl_install}" == "True" ] && [ "${gsl_downloaded}" == "False" ]; then
    download "GSL"
fi
if [ "${hdf5_install}" == "True" ] && [ "${hdf5_downloaded}" == "False" ]; then
    download "HDF5"
fi
if [ "${mpi_install}" == "True" ] && [ "${mpi_downloaded}" == "False" ]; then
    download "MPI"
fi
if [ "${ncurses_install}" == "True" ] && [ "${ncurses_downloaded}" == "False" ]; then
    download "ncurses"
fi
if [ "${openssl_install}" == "True" ] && [ "${openssl_downloaded}" == "False" ]; then
    download "OpenSSL"
fi
if [ "${libffi_install}" == "True" ] && [ "${libffi_downloaded}" == "False" ]; then
    download "libffi"
fi
if [ "${perl_install}" == "True" ] && [ "${perl_downloaded}" == "False" ]; then
    download "Perl"
fi
if [ "${python_install}" == "True" ] && [ "${python_downloaded}" == "False" ]; then
    download "Python"
fi
if [ "${zlib_install}" == "True" ] && [ "${zlib_downloaded}" == "False" ]; then
    download "zlib"
fi
enable_status



################################
# Install CO𝘕CEPT dependencies #
################################
# Function for extracting compressed files
extract() {
    # Arguments: Program name, [is_file]
    # Here, the optional is_file argument can be set to "True" if
    # the first argument is a filename rather than a program name.
    # In that case, the working directory will not be changed.
    if [ "$2" == "True" ]; then
        archive="$1"
    else
        progname="${1// /_}"
        progname="$(echo "${progname}" | tr '[:upper:]' '[:lower:]')"
        cd "${tmp_dir}/${progname}"
        # We assume that any directories placed here is from a similar
        # previous call which went wrong. Delete any of these
        # directories before extracting.
        n_files=0
        for f in *; do
            if [ -d "${f}" ]; then
                for n in {1..720}; do
                    rm_success="True"
                    rm -rf "${f}" || rm_success="False"
                    if [ "${rm_success}" == "True" ]; then
                        break
                    fi
                    sleep 5
                done
            else
                archive="${f}"
                ((n_files += 1))
            fi
        done
        if [ -z "${archive}" ]; then
            error "Did not find any files in \"${tmp_dir}/${progname}\""
            exit 1
        elif [ ${n_files} -gt 1 ]; then
            error "Found multiple files in \"${tmp_dir}/${progname}\"."
            error "I am confused about which to extract. Exiting."
            exit 1
        fi
    fi
    # Extract
    if [ -z "${extract_tar_options}" ]; then
        extract_tar_options="-ixf"
    fi
    extract_success="True"
    case "${archive}" in
        # 7zip
        *.tar.7zip)  7z       -so  x   "${archive}" | tar ${extract_tar_options} -;;
        *.tar.7z)    7z       -so  x   "${archive}" | tar ${extract_tar_options} -;;
        *.t7zip)     7z       -so  x   "${archive}" | tar ${extract_tar_options} -;;
        *.t7z)       7z       -so  x   "${archive}" | tar ${extract_tar_options} -;;
        *.7zip)      7z            x   "${archive}"                               ;;
        *.7z)        7z            x   "${archive}"                               ;;
        # ar
        *.ar)        ar       -xv      "${archive}"                               ;;
        *.a)         ar       -xv      "${archive}"                               ;;
        # bzip2
        *.tar.bzip2) bzip2    -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tar.bz2)   bzip2    -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tbzip2)    bzip2    -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tbz2)      bzip2    -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.bzip2)     bzip2    -d       "${archive}"                               ;;
        *.bz2)       bzip2    -d       "${archive}"                               ;;
        *.tar.bzip)  bzip2    -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tar.bz)    bzip2    -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tbzip)     bzip2    -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tbz)       bzip2    -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.bzip)      bzip2    -d       "${archive}"                               ;;
        *.bz)        bzip2    -d       "${archive}"                               ;;
        # cbz
        *.cbz)       unzip             "${archive}"                               ;;
        # compress
        *.tar.Z)     compress -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tZ)        compress -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.Z)         compress -d       "${archive}"                               ;;
        # cpio
        *.cpio)      cpio     -idv     "${archive}"                               ;;
        # exe
        *.exe)       "$(readlink -f    "${archive}")"                             ;;
        # gzip
        *.tar.gzip)  gzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tar.gz)    gzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tar.z)     gzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tgzip)     gzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tgz)       gzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tz)        gzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.gzip)      gzip     -d       "${archive}"                               ;;
        *.gz)        gzip     -d       "${archive}"                               ;;
        # iso
        *.7z)        7z            x   "${archive}"                               ;;
        # jar
        *.jar)       jar      -xvf     "${archive}"                               ;;
        # lzip
        *.tar.lzip)  lzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tar.lz)    lzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tlzip)     lzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tlz)       lzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.lzip)      lzip     -d       "${archive}"                               ;;
        *.lz)        lzip     -d       "${archive}"                               ;;
        # lzma
        *.tar.lzma)  lzma     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tlzma)     lzma     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.lzma)      lzma     -d       "${archive}"                               ;;
        # lzop
        *.tar.lzop)  lzop     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tar.lzo)   lzop     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tlzop)     lzop     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tlzo)      lzop     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.lzop)      lzop     -d       "${archive}"                               ;;
        *.lzo)       lzop     -d       "${archive}"                               ;;
        # pack
        *.z)         pack          u   "${archive}" out                           ;;
        # rar
        *.rar)       unrar         x   "${archive}"                               ;;
        # rzip
        *.tar.rzip)  rzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.tar.rz)    rzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.trzip)     rzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.trz)       rzip     -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.rzip)      rzip     -d       "${archive}"                               ;;
        *.rz)        rzip     -d       "${archive}"                               ;;
        # shar
        *.shar)      unshar            "${archive}"                               ;;
        # snappy
        *.sz)        snzip    -d       "${archive}"                               ;;
        # tar
        *.tar)       cat               "${archive}" | tar ${extract_tar_options} -;;
        # xz
        *.tar.xz)    xz       -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.txz)       xz       -d     < "${archive}" | tar ${extract_tar_options} -;;
        *.xz)        xz       -d       "${archive}"                               ;;
        # zip
        *tar.zip)    unzip    -p       "${archive}" | tar ${extract_tar_options} -;;
        *tzip)       unzip    -p       "${archive}" | tar ${extract_tar_options} -;;
        *.zip)       unzip             "${archive}"                               ;;
        # unknown
        *) error "Could not understand the compression format of \"${archive}\""
           exit 1
           ;;
    esac || extract_success="False"
    if [ "$2" != "True" ]; then
        cd "${concept_dir}"
    fi
    if [ "${extract_success}" == "False" ]; then
        if [ "${extract_tar_options}" == "-ixf" ]; then
            # If the extraction failed it may be because the tar
            # implementation in use do not support -i. Try without.
            extract_tar_options="-xf"
            extract "$1" "$2"
        else
            error "Failed to extract \"${archive}\""
            return 1
        fi
    fi
}

# Function which initialises installations (extracts the pre-
# downloaded archive and change to the extracted directory).
init_install() {
    # Arguments: Program name, ["Attempting to install" text]
    local progname_formatted="$1"
    local progname="$(echo "${progname_formatted// /_}" | tr '[:upper:]' '[:lower:]')"
    local attempting_to_install_text="$2"
    eval "progversion=\"\${${progname}_version}\""
    if [ "${progname}" != "${progname_last_init_install}" ]; then
        if [ "${progname}" == "fftw_for_gadget" ]; then
            # When installing FFTW for GADGET, the version number should
            # be printed together with FFTW, not GADGET.
            current_step="the installation of FFTW ${progversion} for GADGET"
            heading "Installing FFTW ${progversion} for GADGET"
            set_status "Installing FFTW ${progversion} for GADGET"
        else
            if [ "${progname}" == "blas" ]; then
                progname_formatted="OpenBLAS"
            elif [ "${progname}" == "mpi" ]; then
                progname_formatted="${mpi_formatted}"
            else
                progname_formatted=${progname_formatted/CONCEPT/${esc_concept}}
            fi
            current_step="the installation of ${progname_formatted} ${progversion}"
            heading "Installing ${progname_formatted} ${progversion}"
            set_status "Installing ${progname_formatted} ${progversion}"
        fi
    fi
    progname_formatted_fancy="${progname_formatted}"
    # Extract the downloaded archive
    extract "${progname}"
    # Change to the directory which contain the archive
    # and the extracted folder.
    cd "${tmp_dir}/${progname}"
    # The current directory should contain only a single directory.
    # Change to this directory.
    for f in *; do
        if [ -d "${f}" ]; then
            cd "${f}"
            break
        fi
    done
    # Print out the "Attempting to install" text
    if [ -n "${attempting_to_install_text}" ]; then
        printf "\nAttempting to install ${progname_formatted_fancy} \
with ${attempting_to_install_text}\n\n"
    fi
    # Save a copy of the program name
    progname_last_init_install="${progname}"
}

# Function for detecting when the current process appears to hang.
# When an apparent hang is detected, a soothing message is displayed.
# This should be used when installing Python packages, as pip/setuptools
# sometimes has this bad hanging behaviour, especially for particular
# packages, such as h5py. This function should not be called in a
# situation where you do not believe that the hang is only apparent.
soothe() {
    # Argument: PID of background process on which to wait,
    # [hang time in seconds after which PID is killed],
    # [total time in seconds after which the PID is killed].
    soothe_pid=$1
    kill_time=$2
    kill_time_total=$3
    if [ -z "${kill_time}" ]; then
        # If any process appears to hang for longer than the time below,
        # we will kill it.
        kill_time=7200  # 2 hours
    fi
    if [ -z "${kill_time_total}" ]; then
        kill_time_total=0
    fi
    # A long wait is detected by repeatedly
    # checking the size of the log file generated
    # by this installation script.
    soothe_update_time=60
    if [ ${kill_time} -lt ${soothe_update_time} ]; then
        error "soothe() called with kill_time=${kill_time} < \
soothe_update_time=${soothe_update_time}"
        exit 1
    fi
    (
    log_size_last=-1;                                                                           \
    log_size=$(du -b "${log}" | awk '{print $1}');                                              \
    time_slept=0;                                                                               \
    time_slept_total=0;                                                                         \
    while :; do                                                                                 \
        if [ ${kill_time_total} -gt 0 ] && [ ${time_slept_total} -ge ${kill_time_total} ]; then \
            echo "Process assumed to be hanging. Killing it";                                   \
            kill -9 ${soothe_pid} >/dev/null 2>&1;                                              \
            wait    ${soothe_pid} >/dev/null 2>&1;                                              \
        fi;                                                                                     \
        sleep ${soothe_update_time};                                                            \
        ((time_slept_total += ${soothe_update_time}));                                          \
        log_size_new=$(du -b "${log}" | awk '{print $1}');                                      \
        if [ ${log_size} -eq ${log_size_new} ]; then                                            \
            ((time_slept       += ${soothe_update_time}));                                      \
            if [ ${log_size} -ne ${log_size_last} ]; then                                       \
                printf "\n\nThe next step may take an unreasonable amount of time.
Please be patient ...\n";                                                                       \
                sleep 5;                                                                        \
                log_size_new=$(du -b "${log}" | awk '{print $1}');                              \
                log_size_last=${log_size_new};                                                  \
            elif [ ${time_slept} -gt ${kill_time} ]; then                                       \
                echo "Process assumed to be hanging. Killing it";                               \
                kill -9 ${soothe_pid} >/dev/null 2>&1;                                          \
                wait    ${soothe_pid} >/dev/null 2>&1;                                          \
            fi;                                                                                 \
        else                                                                                    \
            time_slept=0;                                                                       \
        fi;                                                                                     \
        log_size=${log_size_new};                                                               \
    done                                                                                        \
    ) & soothe_killer_pid=$!
    wait ${soothe_pid} >/dev/null 2>&1 || :
    kill ${soothe_killer_pid} >/dev/null 2>&1 || :  # No forceful kill (no -9)
    wait ${soothe_killer_pid} >/dev/null 2>&1 || :
}

# Function for installing programs
install() {
    # Example of call:
    #  install FFTW with_pic "" "--with-pic" ";" "PIC" "-fPIC" ""
    # Also, a function (implementing the installation) named
    # fftw_install_func must exist. An argument with the value
    # "no_init_install" may be given, in which case the call to
    # init_install() will be skipped.
    local progname_formatted="${1}"
    local progname="$(echo "${progname_formatted// /_}" | tr '[:upper:]' '[:lower:]')"
    # Skip installation of this program if it should not be installed
    eval "program_install=\"\${${progname}_install}\""
    eval "program_installed=\"\${${progname}_installed}\""
    if [ "${program_install}" == "False" ] || [ "${program_installed}" == "True" ]; then
        return
    fi
    # Read in remaining arguments, defining the array ${varnames}
    # and arrays ${array_0}, ${array_1}, ..., ${array_n}.
    varnames=()
    new_array="True"
    counter=0
    skip=True
    no_init_install="False"
    for arg in "$@"; do
        if [ "${skip}" == "True" ]; then
            skip="False"
            continue
        fi
        if [ "${arg}" == "no_init_install" ]; then
            no_init_install="True"
            continue
        fi
        if [ "${new_array}" == "True" ]; then
            varnames=("${varnames[@]}" "${arg}")
            eval "array_${counter}=()"
            new_array="False"
            continue
        elif [ "${arg}" == ";" ]; then
            new_array="True"
            ((counter += 1))
            continue
        fi
        eval "array_${counter}=(\"\${array_${counter}[@]}\" \"${arg}\")"
    done
    if [ "${arg}" != ";" ]; then
        ((counter += 1))
    fi
    # Iterate over Cartesian product of arrays, attempting installation
    # for each set of variable values.
    compiler=""
    install_loop "${progname_formatted}" ${counter} 0 "${no_init_install}"
    if [ "${install_success}" == "False" ]; then
        error "Failed to install ${progname_formatted_fancy}"
        exit 1
    fi
    # Reset environment variables
    reset_environment
    # Finalize handling of test results
    if [ -n "${test_success}" ]; then
        eval "${progname}_test_success=\"${test_success}\""
    fi
    eval "program_test_log=\"\${${progname}_test_log}\""
    rm -f "${program_test_log}"
    if     [ "${do_tests}" == "True"      ] \
        && [ -n "${program_test_log}"     ] \
        && [ "${test_success}" == "False" ] \
        && [ -f "test_log"                ] \
    ; then
        mkdir -p "$(dirname "${program_test_log}")"
        cp "test_log" "${program_test_log}" || :
    fi
    if [ "${program_test_log}" != "$(pwd)/test_log" ]; then
        rm -f "test_log" || :
    fi
    # Copy over license and readme files.
    # Get the directory from the test log path.
    if [ "${slim}" == "True" ]; then
        files_to_copy=()
    else
        files_to_copy=(                                                                           \
            "acknowledgement" "acknowledgements" "acknowledgment" "acknowledgments" "announce"    \
            "announcement" "announcements" "author" "authors" "backers" "changelist"              \
            "changelog" "changes" "contributing" "contributors" "copying" "copyright" "ftl" "gpl" \
            "gplv2" "gplv3" "license" "licence" "new" "news" "readme" "thank" "thanks"            \
            "trademark" "trademarks" "version"                                                    \
        )
    fi
    if [ -n "${program_test_log}" ]; then
        program_dir="$(dirname "${program_test_log}")"
    else
        eval "program_dir=\"\${${progname}_dir}\""
    fi
    mkdir -p "${program_dir}" || :
    for copy_dir in "." "doc" "docs"; do
        if [ "${copy_dir}" != "." ]; then
            if [ -d "${copy_dir}" ]; then
                cd "${copy_dir}"
            else
                continue
            fi
        fi
        for f in *; do
            if [ -d "${f}" ] || [ -f "${program_dir}/$(basename "${f}")" ]; then
                continue
            fi
            f_canonical="$(echo "${f%.*}" | tr '[:upper:]' '[:lower:]')"
            for file_to_copy in "${files_to_copy[@]}"; do
                if [ "${f_canonical}" == "${file_to_copy}" ]; then
                    cp "${f}" "${program_dir}/" || :
                fi
            done
        done
        if [ "${copy_dir}" != "." ]; then
            cd ..
        fi
    done
    # Final cleanup and install notices
    cd "${concept_dir}"
    rm -rf "${tmp_dir}/${progname}" || :
    eval "program_dir=\"\${${progname}_dir}\""
    if [ -n "${program_dir}" ]; then
        mkdir -p "${program_dir}" || :
        install_notice "${progname_formatted}" "${program_dir}"
    fi
    if [ "${no_init_install}" == "True" ]; then
        echo "Successfully installed ${progname_formatted}"
    else
        echo "Successfully installed ${progname_formatted_fancy}"
    fi
}

# Helper function used by the install() function
install_loop() {
    # Arguments: Formatted program name, number of variables in total,
    # variable number, [no_init_install, being either "True" or "False"].
    local progname_formatted="${1}"
    local nvars="${2}"
    local varnum="${3}"
    local no_init_install="${4}"
    local progname="$(echo "${progname_formatted// /_}" | tr '[:upper:]' '[:lower:]')"
    # If we are in the innermost recursive call,
    # call the supplied function and return.
    if [ "${varnum}" == "${nvars}" ]; then
        # Initialise installation
        reset_environment
        if [ -n "${compiler}" ]; then
            "use_${compiler}_compilers" || return
        fi
        for ((i = 0; i < ${nvars}; i += 1)); do
            varname=${varnames[$i]}
            eval "varval=\${${varname}}"
            if [ ${i} -eq 0 ]; then
                attempting_to_install_text="${varname}=${varval}"
            else
                attempting_to_install_text="${attempting_to_install_text}, ${varname}=${varval}"
            fi
        done
        if [ "${no_init_install}" == "True" ]; then
            # As init_install() should not be called, we should print
            # out the "Attempting to install" text here.
            if [ -n "${attempting_to_install_text}" ]; then
                printf "\nAttempting to install ${progname_formatted} \
with ${attempting_to_install_text}\n\n"
            fi
        else
            init_install "${progname_formatted}" "${attempting_to_install_text}"
        fi
        # Call the supplied function
        install_success="True"
        test_success=""
        "${progname}_install_func" || install_success="False"
        return
    fi
    # Carry out nested looping
    local varnum_next
    ((varnum_next = varnum + 1))
    local array
    eval "array=(\"\${array_${varnum}[@]}\")"
    for el in "${array[@]}"; do
        eval "${varnames[${varnum}]}=\"${el}\""
        install_loop "${progname_formatted}" ${nvars} ${varnum_next} "${no_init_install}"
        if [ "${install_success}" == "True" ]; then
            return
        fi
    done
}

# Function for writing out installation notices to files in the
# installation directories of the various programs.
install_notice() {
    # Arguments: Program name, program_dir
    local progname_formatted="$1"
    local progdir="$2"
    local progname="$(echo "${progname_formatted// /_}" | tr '[:upper:]' '[:lower:]')"
    eval "progversion=\"\${${progname}_version}\""
    test_results="None"
    if [ "${do_tests}" == "True" ]; then
        eval "test_success=\"\${${progname}_test_success}\""
        if [ "${test_success}" == "True" ]; then
            test_results="Success"
        elif [ "${test_success}" == "False" ]; then
            test_results="Failure"
        fi
    fi
    echo "The following has been fully installed:
Program:      ${progname_formatted}
Version:      ${progversion}
Test results: ${test_results}
Date:         $(date)
" >> "${progdir}/.installation_finished"
}

# Function for adding optimization to compiler flags
set_optimizations() {
    # Arguments: --no-lto to exclude link time optimizations
    use_lto="True"
    if [ "$1" == "--no-lto" ]; then
        use_lto="False"
    fi
    # Determine the compiler in use.
    # The gcc behaviour is chosen if some compiler
    # not specified here is really in use.
    CC_implementation="gcc"
    if [ "${compiler}" == "gnu" ]; then
        CC_implementation="gcc"
    elif [ "${compiler}" == "clang" ]; then
        CC_implementation="clang"
    elif [ "${compiler}" == "intel" ]; then
        CC_implementation="icc"
    else
        info="$("${CC}" --version 2>/dev/null | head -n 1 || :)"
        if echo "${info}" | grep -i "icc" >/dev/null; then
            CC_implementation="icc"
        elif echo "${info}" | grep -i "intel" >/dev/null; then
            CC_implementation="icc"
        elif echo "${info}" | grep -i "gcc" >/dev/null; then
            CC_implementation="gcc"
        elif echo "${info}" | grep -i "clang" >/dev/null; then
            CC_implementation="clang"
        fi
    fi
    # General optimizations
    optimizations="-DNDEBUG -O3 -funroll-loops"
    optimizations_linker="-O3"
    # Floating point optimizations
    if [ "${CC_implementation}" == "gcc" ] || [ "${CC_implementation}" == "clang" ]; then
        optimizations="${optimizations} -ffast-math"
    elif [ "${CC_implementation}" == "icc" ]; then
        optimizations="${optimizations} -fp-model fast=2"
    fi
    # Link time optimizations
    if [ "${use_lto}" == "True" ]; then
        local current_dir="$(pwd)"
        lto_test_dir="${tmp_dir}/lto_test"
        rm -rf "${lto_test_dir}" || :
        mkdir -p "${lto_test_dir}"
        cd "${lto_test_dir}"
        echo "int main(void){ return 0; }" > main.c
        lto_warning="$(                                              \
            "${CC}" -flto -c -o main.o main.c 2>&1 | grep flto || :; \
            "${CC}" main.o -o main -flto 2>&1      | grep flto || :; \
            ./main 2>/dev/null || echo "lto error";                  \
        )"
        cd "${current_dir}"
        rm -rf "${lto_test_dir}" || :
        if [ -z "${lto_warning}" ]; then
            optimizations="${optimizations} -flto"
            optimizations_linker="${optimizations_linker} -flto"
        fi
    fi
    # Remove unwanted flags from CFLAGS and CXXFLAGS
    unwanted_flags=(                          \
        -g -g0 -g1 -g2 -g3                    \
        -O -O0 -O1 -O2 -O3 -O4 -Og -Os -Ofast \
    )
    CFLAGS_ori="${CFLAGS}"
    CFLAGS=""
    for flag in ${CFLAGS_ori}; do
        wanted="True"
        for unwanted_flag in ${unwanted_flags[@]}; do
            if [ "${flag}" == "${unwanted_flag}" ]; then
                wanted="False"
                break
            fi
        done
        if [ "${wanted}" == "True" ]; then
            CFLAGS="${CFLAGS} ${flag}"
        fi
    done
    CXXFLAGS_ori="${CXXFLAGS}"
    CXXFLAGS=""
    for flag in ${CXXFLAGS_ori}; do
        wanted="True"
        for unwanted_flag in ${unwanted_flags[@]}; do
            if [ "${flag}" == "${unwanted_flag}" ]; then
                wanted="False"
                break
            fi
        done
        if [ "${wanted}" == "True" ]; then
            CXXFLAGS="${CXXFLAGS} ${flag}"
        fi
    done
    # Remove the same unwanted flags from LDFLAGS
    LDFLAGS_ori="${LDFLAGS}"
    LDFLAGS=""
    for flag in ${LDFLAGS_ori}; do
        wanted="True"
        for unwanted_flag in ${unwanted_flags[@]}; do
            if [ "${flag}" == "${unwanted_flag}" ] || [ "${flag}" == "-Wl,${unwanted_flag}" ]; then
                wanted="False"
                break
            fi
        done
        if [ "${wanted}" == "True" ]; then
            LDFLAGS="${LDFLAGS} ${flag}"
        fi
    done
    # Add optimization flags to CFLAGS, CXXFLAGS and LDFLAGS
    CFLAGS="${CFLAGS} ${optimizations}"
    CXXFLAGS="${CXXFLAGS} ${optimizations}"
    optimizations_linker_prefixed=""
    for optimization in ${optimizations_linker}; do
        optimizations_linker_prefixed="${optimizations_linker_prefixed} -Wl,${optimization}"
    done
    LDFLAGS="${LDFLAGS} ${optimizations} ${optimizations_linker_prefixed}"
    # Export mutated environment variables
    export CFLAGS="${CFLAGS}"
    export CXXFLAGS="${CXXFLAGS}"
    export LDFLAGS="${LDFLAGS}"
}



# zlib
zlib_install_func() {
    ./configure --shared --prefix="${zlib_dir}" 2>&1 || return 1
    if [ "${do_tests}" == "True" ]; then
        make ${make_jobs} test 2>&1 | tee "test_log"
        [ ${PIPESTATUS[0]} -eq 0 ] || test_success="False"
    fi
    make ${make_jobs} install 2>&1 || return 1
    if [ "${slim}" == "True" ]; then
        rm -rf "${zlib_dir}/share" || :
    fi
}
install "zlib" compiler "${compiler_possibilities[@]}"

# GSL
gsl_install_func() {
    ./configure --prefix="${gsl_dir}" 2>&1 || return 1
    make ${make_jobs} 2>&1 || return 1
    if [ "${do_tests}" == "True" ]; then
        make ${make_jobs} check 2>&1 | tee "test_log"
        [ ${PIPESTATUS[0]} -eq 0 ] || test_success="False"
    fi
    make ${make_jobs} install 2>&1 || return 1
    if [ "${slim}" == "True" ]; then
        rm -rf "${gsl_dir}/share" || :
    fi
}
install "GSL" compiler "${compiler_possibilities[@]}"

# Perl
perl_install_func() {
    if [ "${dump_libimf}" == "False" ] && [ "${libimf_dumped}" == "False" ]; then
        # libimf was not found, so dump_libimf == True is equivalent
        # to dump_libimf == False.
        return 1
    fi
    if [ "${without_then_with_cc}" == "True" ] && [ -z "${CC}" ]; then
        # Cannot run with -Dcc if CC is not set
        return 1
    fi
    # When an Intel C compiler is used, some libraries like libimf may
    # not be found by the perl executable. We can fix this by dropping
    # symlinks to all Intel libraries into the build directory.
    # For whatever reason, updating LD_LIBRARY_PATH has no effect.
    if [ "${dump_libimf}" == "True" ]; then
        while IFS=':' read -ra library_paths; do
            for library_path in "${library_paths[@]}"; do
                is_intel_lib_dir="False"
                for f in "${library_path}"/*; do
                    f_base="$(basename "${f}")"
                    if     [[ "${f_base}" == libimf*.a    ]] \
                        || [[ "${f_base}" == libimf*.so   ]] \
                        || [[ "${f_base}" == libimd*.so.* ]]; then
                        is_intel_lib_dir="True"
                        break
                    fi
                done
                if [ "${is_intel_lib_dir}" == "False" ]; then
                    continue
                fi
                libimf_dumped="True"
                for f in "${library_path}/"*; do
                    f_base="$(basename "${f}")"
                    if (   [[ "${f_base}" == *.a    ]] \
                        || [[ "${f_base}" == *.so   ]] \
                        || [[ "${f_base}" == *.so.* ]] \
                       ) && [ ! -f "./${f_base}" ]; then
                        ln -s "${f}" ./ >/dev/null 2>&1 || :
                    fi
                done
            done
        done <<< "${LD_LIBRARY_PATH}"
    fi
    perl_config_options="-de -Dprefix=${perl_dir}"
    if     [ "${without_then_with_cc}" == "False" ] \
        && [ "${compiler}" != "default"           ] \
        && [ -n "${CC}"                           ] \
    ; then
        perl_config_options="${perl_config_options} -Dcc=${CC}"
    fi
    # Sometimes the installation will complain that the Perl libraries
    # should have been compiled statically. Thus, we try with and
    # without the -fPIC C flag.
    if [ -n "${perl_cflags}" ]; then
        perl_config_options="${perl_config_options} -Accflags=${perl_cflags}"
    fi
    ./Configure ${perl_config_options} 2>&1 || return 1
    # Sometimes make fails to build due to #include of poll.h from a
    # wrong location. A fix for this is implemented below.
    if [ "${perl_poll_fix}" == "True" ]; then
        sed -i 's/<poll\.h>/<sys\/poll\.h>/' 'dist/IO/poll.h' || return 1
    fi
    # For some reason, first trying without -Dcc
    # and then with -Dcc sometimes help.
    if [ "${without_then_with_cc}" == "True" ]; then
        make ${make_jobs} 2>&1 || :
        make clean || :
        perl_config_options="${perl_config_options} -Dcc=${CC}"
        ./Configure ${perl_config_options} 2>&1 || return 1
    fi
    make ${make_jobs} 2>&1 || return 1
    if [ "${do_tests}" == "True" ]; then
        # On some systems, the Perl test hangs indefinitely.
        # To counteract this, kill the process if it still
        # runs after ${perl_test_max_time} seconds.
        perl_test_max_time=3600
        exit_code_filename="${tmp_dir}/.exit_code_perl"
        mkdir -p "$(dirname "${exit_code_filename}")"
        rm -f "${exit_code_filename}" || :
        (make ${make_jobs} test 2>&1 | tee "test_log"; \
            echo "${PIPESTATUS[0]}" > "${exit_code_filename}") & perl_test_pid=$!
        soothe ${perl_test_pid} ${perl_test_max_time}
        sleep 1
        kill -9 ${perl_test_pid} >/dev/null 2>&1 || :
        wait    ${perl_test_pid} >/dev/null 2>&1 || :
        exit_code="$(cat "${exit_code_filename}" 2>/dev/null || :)"
        rm -f "${exit_code_filename}" || :
        if [ "${exit_code}" != "0" ]; then
            test_success="False"
        fi
        # The text "Failed" will be present in the test log
        # file if any of the tests failed.
        if grep 'Failed' "test_log" >/dev/null 2>&1; then
            test_success="False"
        fi
    fi
    make ${make_jobs} install 2>&1 || return 1
    if [ "${slim}" == "True" ]; then
        rm -rf "${perl_dir}/man" || :
    fi
}
libimf_dumped="False"
install "Perl"                                  \
    compiler "${compiler_possibilities[@]}" ";" \
    without_then_with_cc "False" "True"     ";" \
    dump_libimf "True" "False"              ";" \
    perl_poll_fix "False" "True"            ";" \
    perl_cflags "" "-fPIC"                  ";" \

# MPI
mpi_install_func() {
    mpi_configure_options="${mpi_configure_options_supplied}"
    if [ -z "${mpi_configure_options}"] || [[ "${mpi_configure_options}" == "+="* ]]; then
        mpi_configure_options="${mpi_configure_options/+=/}"
        if [ "${mpi}" == "mpich" ]; then
            mpi_configure_options="--disable-cxx --disable-fortran \
${mpi_configure_options}"
        elif [ "${mpi}" == "openmpi" ]; then
            mpi_configure_options="--enable-mpi-cxx=none --enable-mpi-fortran=none \
${mpi_configure_options}"
        fi
        mpi_configure_options="${mpi_configure_options} ${mpi_configure_options_extra}"
        mpi_configure_options_trimmed=""
        mpi_device_set="False"
        for mpi_configure_option in ${mpi_configure_options}; do
            include_mpi_configure_option="True"
            if [[ "${mpi_configure_option}" == "--with-device"* ]]; then
                include_mpi_configure_option="False"
                if [ "${mpi_device_set}" == "False" ]; then
                    include_mpi_configure_option="True"
                fi
                mpi_device_set="True"
            fi
            if [ "${include_mpi_configure_option}" == "True" ]; then
                mpi_configure_options_trimmed="${mpi_configure_options_trimmed} \
${mpi_configure_option}"
            fi
        done
        mpi_configure_options="${mpi_configure_options_trimmed}"
    fi
    # The below works for both MPICH and OpenMPI
    if [ -d "${perl_dir}" ]; then
        export PATH="${perl_dir}/bin:${PATH}"
    fi
    ./configure ${mpi_configure_options} --prefix="${mpi_dir}" 2>&1 || return 1
    make_jobs_mpi=""
    if [ "${make_jobs}" == "-j" ]; then
        # Building in parallel takes up a lot of resources
        make_jobs_mpi="-j 2"
    fi
    make ${make_jobs_mpi} 2>&1 || return 1
    if [ "${do_tests}" == "True" ]; then
        make check 2>&1 | tee "test_log"
        [ ${PIPESTATUS[0]} -eq 0 ] || test_success="False"
    fi
    make ${make_jobs_mpi} install 2>&1 || return 1
    if [ "${slim}" == "True" ]; then
        if [ -d "${mpi_dir}/share" ]; then
            rm -rf "${mpi_dir}/share/man" || :
            rm -rf "${mpi_dir}/share/doc" || :
            if [ -z "$(ls -A "${mpi_dir}/share")" ]; then
                rm -rf "${mpi_dir}/share" || :
            fi
        fi
    fi
}
mpi_configure_options_supplied="${mpi_configure_options}"
if [ "${mpi}" == "mpich" ]; then
    mpi_configure_options_extras="\
--with-device=ch4 --with-device=ch3 \
--with-device=ch4:ofi --with-device=ch4:ucx \
--with-device=ch3:sock"
elif [ "${mpi}" == "openmpi" ]; then
    mpi_configure_options_extras=""
fi
install "MPI"                                                          \
    compiler "${compiler_possibilities_specified_mpi_last[@]}"     ";" \
    mpi_configure_options_extra "" ${mpi_configure_options_extras} ";" \

# HDF5
hdf5_install_func() {
    # Set environment variables and configure options used
    # when building against MPI and zlib.
    enable_parallel=""
    if [ -n "${mpi_dir}" ] && [ -d "${mpi_dir}" ]; then
        export LIBS="-lmpi ${LIBS}"
        enable_parallel="--enable-parallel"
    fi
    with_zlib=""
    if [ -n "${zlib_dir}" ] && [ -d "${zlib_dir}" ]; then
        export LDFLAGS="-L${zlib_dir}/lib ${LDFLAGS}"
        export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"
        export CFLAGS="-I${zlib_dir}/include ${CFLAGS}"
        with_zlib=--with-zlib="${zlib_dir}/include","${zlib_dir}/lib"
    fi
    # As part of the installation the program H5detect is built and run,
    # which amongst other things tests the signal handling capabilities
    # of the system. On some systems, some deliberately raised signals
    # are not caught as intended, leading to a crash. As verification of
    # signal handling is not crucial, we can simply skip this.
    if [ "${ignore_signal_handling_verification}" == "True" ]; then
        sed -i 's/if *( *verify_signal_handler.*!= *0/if(0 != 0/' "src/H5detect.c" || return 1
    fi
    # On some systems an explicit architecture must be set
    # for the compilation to succeed.
    if [ -n "${hdf5_arch}" ]; then
        export CFLAGS="${CFLAGS} -march=${hdf5_arch}"
    fi
    # A bug in HDF5 makes the code crash on certain file systems.
    # A workaround is to set an environment variable as below.
    export HDF5_USE_FILE_LOCKING=FALSE
    ./configure                          \
        --enable-build-mode=${buildmode} \
        --enable-shared                  \
        ${enable_parallel}               \
        ${with_zlib}                     \
        --prefix="${hdf5_dir}"           \
        2>&1 || return 1
    # Newer versions of gcc (e.g. 8.1.0) do not allow attributes to
    # be specified after the declarator in function definitions.
    # At least in some versions of HDF5 (e.g. 1.10.2), this rule is
    # broken by src/H5detect.c.
    if [ "${fix_attributes_declarator_order}" == "True" ]; then
        mv "src/H5detect.c" "src/H5detect.c_cp"
        if [ -z "${IFS+x}" ]; then
            IFS_ori="__unset__"
        else
            IFS_ori="${IFS}"
        fi
        IFS=''
        while read -r line; do
            if [ "${line}" == "static void" ] || [ "${line}" == "int" ] ; then
                printf "${line} " >> "src/H5detect.c"
            else
                echo "${line}" >> "src/H5detect.c"
            fi
        done <<< "$(cat "src/H5detect.c_cp")"
        if [ "${IFS_ori}" == "__unset__" ]; then
            unset IFS
        else
            IFS="${IFS_ori}"
        fi
        rm -f "src/H5detect.c_cp" || :
        sed -i 's/^static void \(.*\) HDF_NO_UBSAN/static void HDF_NO_UBSAN \1/' "src/H5detect.c"
        sed -i 's/^int \(.*\) HDF_NO_UBSAN/int HDF_NO_UBSAN \1/' "src/H5detect.c"
    fi
    make 2>&1 || return 1  # Building in parallel takes up a lot of resources
    # On some systems, the HDF5 test (make check) hangs indefinitely.
    # To counteract this, kill the process if it still
    # runs after ${hdf5_test_max_time} seconds.
    if [ "${do_tests}" == "True" ]; then
        hdf5_test_max_time=3600
        exit_code_filename="${tmp_dir}/.exit_code_hdf5"
        mkdir -p "$(dirname "${exit_code_filename}")"
        # Perform serial + parallel tests if build against MPI
        # or normal tests otherwise.
        if [ -n "${mpi_dir}" ] && [ -d "${mpi_dir}" ]; then
            # Serial tests
            rm -f "${exit_code_filename}" || :
            (make ${make_jobs} check-s 2>&1 | tee "test_log"; \
                echo "${PIPESTATUS[0]}" > "${exit_code_filename}") & hdf5_test_pid=$!
            soothe ${hdf5_test_pid} ${hdf5_test_max_time}
            sleep 1
            kill -9 ${hdf5_test_pid} >/dev/null 2>&1 || :
            wait    ${hdf5_test_pid} >/dev/null 2>&1 || :
            exit_code="$(cat "${exit_code_filename}" 2>/dev/null || :)"
            rm -f "${exit_code_filename}" || :
            if [ "${exit_code}" != "0" ]; then
                test_success="False"
            fi
            # Parallel tests
            printf "\n\n\nParallel tests below\n\n\n\n" >> "test_log"
            rm -f "${exit_code_filename}" || :
            (make ${make_jobs} check-p 2>&1 | tee -a "test_log"; \
                echo "${PIPESTATUS[0]}" > "${exit_code_filename}") & hdf5_test_pid=$!
            soothe ${hdf5_test_pid} ${hdf5_test_max_time}
            sleep 1
            kill -9 ${hdf5_test_pid} >/dev/null 2>&1 || :
            wait    ${hdf5_test_pid} >/dev/null 2>&1 || :
            exit_code="$(cat "${exit_code_filename}" 2>/dev/null || :)"
            rm -f "${exit_code_filename}" || :
            if [ "${exit_code}" != "0" ]; then
                test_success="False"
            fi
        else
            rm -f "${exit_code_filename}" || :
            (make ${make_jobs} check 2>&1 | tee "test_log"; \
                echo "${PIPESTATUS[0]}" > "${exit_code_filename}") & hdf5_test_pid=$!
            soothe ${hdf5_test_pid} ${hdf5_test_max_time}
            sleep 1
            kill -9 ${hdf5_test_pid} >/dev/null 2>&1 || :
            wait    ${hdf5_test_pid} >/dev/null 2>&1 || :
            exit_code="$(cat "${exit_code_filename}" 2>/dev/null || :)"
            rm -f "${exit_code_filename}" || :
            if [ "${exit_code}" != "0" ]; then
                test_success="False"
            fi
        fi
        rm -f "${exit_code_filename}" || :
    fi
    make install 2>&1 || return 1  # Building in parallel takes up a lot of resources
    if [ "${do_tests}" == "True" ]; then
        printf "\n\n\nInstall tests below\n\n\n\n" >> "test_log"
        make ${make_jobs} check-install 2>&1 | tee -a "test_log"
        # The text "*FAILED*" will be present in the test log file
        # if any of the tests failed.
        [ ${PIPESTATUS[0]} -eq 0 ] || test_success="False"
        if grep '\*FAILED\*' "test_log" >/dev/null 2>&1; then
            test_success="False"
        fi
    fi
    if [ "${slim}" == "True" ]; then
        rm -rf "${hdf5_dir}/share" || :
    fi
}
compiler_possibilities_hdf5=("${compiler_possibilities[@]}")
if [ -n "${mpi_dir}" ] && [ -d "${mpi_dir}" ]; then
    compiler_possibilities_hdf5=("specified_mpi")
fi
install "HDF5"                                             \
    compiler "${compiler_possibilities_hdf5[@]}"       ";" \
    buildmode "production" "debug"                     ";" \
    fix_attributes_declarator_order "False" "True"     ";" \
    hdf5_arch "" "x86-64"                              ";" \
    ignore_signal_handling_verification "False" "True" ";" \

# FFTW
fftw_install_func() {
    also_single_precision="False"  # Install both double and single precision?
    if [ -z "${enable_shared}" ] && [ -n "${shared}" ]; then
        return 1
    fi
    enable_mpi=""
    if [ -n "${mpi_dir}" ] && [ -d "${mpi_dir}" ]; then
        enable_mpi="--enable-mpi"
        export MPICC="${CC}"
        export MPILIBS="-lmpi ${MPILIBS}"
    fi
    if [ -d "${perl_dir}" ]; then
        export PATH="${perl_dir}/bin:${PATH}"
    fi
    export CFLAGS="-O3 ${PIC} ${CFLAGS}"
    export CXXFLAGS="-O3 ${PIC} ${CXXFLAGS}"
    export LDFLAGS="${LDFLAGS} -Wl,-O3 ${shared} ${PIC}"
    if [ "${extra_optimizations}" == "True" ]; then
        set_optimizations --no-lto
    fi
    if [ "${rm_no_gcc}" == "True" ]; then
        sed -i 's/-no-gcc//g' configure || :
    fi
    # Double-precision
    simd_instructions=""
    for ((i_simd = 0; i_simd < ${n_simd}; i_simd += 1)); do
        simd="${simd_instructions_all[${i_simd}]}"
        if [ "${simd}" == "--enable-sse" ]; then
            continue
        fi
        simd_instructions="${simd_instructions} ${simd}"
    done
    ./configure ${enable_shared} ${enable_mpi} \
        --disable-fortran ${with_pic} ${simd_instructions} \
        --prefix="${fftw_dir}" 2>&1 || return 1
    make 2>&1 || return 1  # Parallel builds fail on some systems
    if     [ "${extra_optimizations}" == "True" ] || [ -n "${simd_instructions}" ] \
        || [ "${do_tests}" == "True" ]; then
        fftw_test_max_time=3600
        exit_code_filename="${tmp_dir}/.exit_code_fftw"
        mkdir -p "$(dirname "${exit_code_filename}")"
        rm -f "${exit_code_filename}" || :
        if [ -n "${mpiexec_extra_args_local}" ]; then
            sed -i "s/^MPIRUN *=.*/MPIRUN = mpiexec ${mpiexec_extra_args_local}/" \
                "mpi/Makefile" || :
        fi
        (make check 2>&1 | tee "test_log"; echo "${PIPESTATUS[0]}" > "${exit_code_filename}" \
            ) & fftw_test_pid=$!
        soothe ${fftw_test_pid} ${fftw_test_max_time}
        sleep 1
        kill -9 ${fftw_test_pid} >/dev/null 2>&1 || :
        wait    ${fftw_test_pid} >/dev/null 2>&1 || :
        exit_code="$(cat "${exit_code_filename}" 2>/dev/null || :)"
        rm -f "${exit_code_filename}" || :
        if [ "${extra_optimizations}" == "True" ] || [ -n "${simd_instructions}" ]; then
            if [ "${exit_code}" != "0" ]; then
                rm -f "test_log" || :
                return 1
            fi
            if [ "${do_tests}" == "False" ]; then
                rm -f "test_log" || :
            fi
        elif [ "${do_tests}" == "True" ]; then
            if [ "${exit_code}" != "0" ]; then
                test_success="False"
            fi
        fi
    fi
    make install 2>&1 || return 1  # Parallel builds fail on some systems
    # Single-precision
    if [ "${also_single_precision}" == "True" ]; then
        precision_flags="--enable-float"
        make clean || :
        simd_instructions=""
        for ((i_simd = 0; i_simd < ${n_simd}; i_simd += 1)); do
            simd_instructions="${simd_instructions} ${simd_instructions_all[${i_simd}]}"
        done
        ./configure ${enable_shared} ${enable_mpi} ${precision_flags} \
            --disable-fortran ${with_pic} ${simd_instructions} \
            --prefix="${fftw_dir}" 2>&1 || return 1
        make         2>&1 || return 1  # Parallel builds fail on some systems
        make install 2>&1 || return 1  # Parallel builds fail on some systems
    fi
    if [ "${slim}" == "True" ]; then
        rm -rf "${fftw_dir}/share" || :
    fi
}
compiler_possibilities_fftw=("${compiler_possibilities[@]}")
if [ -n "${mpi_dir}" ] && [ -d "${mpi_dir}" ]; then
    compiler_possibilities_fftw=("specified_mpi")
fi
simd_instructions_all=("--enable-sse" "--enable-sse2" \
    "--enable-avx" "--enable-avx2" "--enable-avx512")
n_simd_all=""
for ((n_simd = ${#simd_instructions_all[@]}; n_simd >= 0; n_simd -= 1)); do
    n_simd_all="${n_simd_all} ${n_simd}"
done
install "FFTW"                                       \
    compiler "${compiler_possibilities_fftw[@]}" ";" \
    rm_no_gcc "False" "True"                     ";" \
    extra_optimizations "True" "False"           ";" \
    n_simd ${n_simd_all}                         ";" \
    enable_shared "--enable-shared" ""           ";" \
    shared "" "-shared"                          ";" \
    with_pic "" "--with-pic"                     ";" \
    PIC "-fPIC" ""                               ";" \

# FreeType
freetype_install_func() {
    ./configure --prefix="${freetype_dir}" \
                --with-zlib=no             \
                --with-bzip2=no            \
                --with-png=no              \
                --with-harfbuzz=no 2>&1 || return 1
    make ${make_jobs} 2>&1 || return 1
    # FreeType does not come with a test suite
    make ${make_jobs} install 2>&1 || return 1
    if [ "${slim}" == "True" ]; then
        rm -rf "${freetype_dir}/share" || :
    fi
}
install "FreeType" compiler "${compiler_possibilities[@]}"

# ncurses
ncurses_install_func() {
    # Due to a bug in (at least) ncurses 6.0, this is needed on
    # some systems. See https://trac.sagemath.org/ticket/19762
    export CPPFLAGS="-P ${CPPFLAGS}"
    ./configure --with-shared --prefix="${ncurses_dir}" 2>&1 || return 1
    make ${make_jobs}         2>&1 || return 1
    make ${make_jobs} install 2>&1 || return 1
    if [ "${do_tests}" == "True" ]; then
        export LD_LIBRARY_PATH="${ncurses_dir}/lib:${LD_LIBRARY_PATH}"
        disable_status
        (sleep ${sleep_time}; echo "q") | "test/worm" -n 7 > "/dev/tty" 2>&1 \
            || test_success="False"
        enable_status
    fi
    # Additional test run needed (if the first failed), as the one
    # above do not use tee (as it ruins the display).
    if [ "${do_tests}" == "True" ] && [ "${test_success}" == "False" ]; then
        disable_status
        (sleep ${sleep_time}; echo "q") | "test/worm" -n 7 > "test_log" 2>&1 || :
        enable_status
    fi
}
install "ncurses" compiler "${compiler_possibilities[@]}"

# OpenSSL
openssl_install_func() {
    if [ -d "${perl_dir}" ]; then
        export PATH="${perl_dir}/bin:${PATH}"
        export PERL="${perl_dir}/bin/perl"
    fi
    ./config shared --prefix="${openssl_dir}" \
        --openssldir="${openssl_dir}/openssl" 2>&1 || return 1
    make 2>&1 || return 1  # Should not be run in parallel
    if [ "${do_tests}" == "True" ]; then
        make test 2>&1 | tee "test_log"  # Should not be run in parallel
        [ ${PIPESTATUS[0]} -eq 0 ] || test_success="False"
    fi
    make install 2>&1 || return 1  # Should not be run in parallel
}
install "OpenSSL" compiler "${compiler_possibilities[@]}"

# libffi
libffi_install_func() {
    ./configure --prefix="${libffi_dir}" 2>&1 || return 1
    make ${make_jobs} 2>&1 || return 1
    if [ "${do_tests}" == "True" ]; then
        make check 2>&1 | tee "test_log"
        [ ${PIPESTATUS[0]} -eq 0 ] || test_success="False"
    fi
    make ${make_jobs} install 2>&1 || return 1
}
install "libffi" compiler "${compiler_possibilities[@]}"

# OpenBLAS
blas_install_func() {
    openblas_make_options=""
    # Compile for multiple CPU architectures
    openblas_make_options="${openblas_make_options} DYNAMIC_ARCH=1 DYNAMIC_OLDER=1"
    # Due to the threading behaviour of Python,
    # we install a non-threaded version of OpenBLAS.
    openblas_singlethread="USE_THREAD=0 USE_OPENMP=0"
    openblas_make_options="${openblas_make_options} ${openblas_singlethread}"
    # Attempt build
    openblas_make_options="${openblas_make_options} ${NO_AVX}"
    if [ "${openblas_gfortran}" == "True" ]; then
        export FC="gfortran"
        export F77="gfortran"
        export F90="gfortran"
        export F9X="gfortran"
    fi
    if ([ "${compiler}" != "default" ] && [ -n "${FC}" ]) \
        || [ "${openblas_gfortran}" == "True" ]; then
        openblas_make_options="${openblas_make_options} FC=${FC}"
    fi
    if [ "${compiler}" != "default" ] && [ -n "${CC}" ]; then
        openblas_make_options="${openblas_make_options} CC=${CC}"
    fi
    if [ -n "${openblas_BINARY}" ]; then
        openblas_make_options="${openblas_make_options} BINARY=${openblas_BINARY}"
    fi
    if [ -d "${perl_dir}" ]; then
        export PATH="${perl_dir}/bin:${PATH}"
    fi
    # Specify MAKE_NB_JOBS instead of explicit -j. By default this is
    # set to the number of hardware threads. As this takes up
    # a lot of resources we always set this to a low number,
    # regardless of ${make_jobs}.
    make MAKE_NB_JOBS=2 ${openblas_make_options}                              || return 1
    make MAKE_NB_JOBS=1 ${openblas_singlethread} PREFIX="${blas_dir}" install || return 1
    # Note that OpenBLAS runs its test suite during the build
}
NO_AVX_possibilities=(               \
    ""                               \
                       "NO_AVX512=1" \
             "NO_AVX2=1 NO_AVX512=1" \
    "NO_AVX=1 NO_AVX2=1 NO_AVX512=1" \
)
install "BLAS"                                  \
    openblas_gfortran "True" "False"        ";" \
    openblas_BINARY "" "32"                 ";" \
    compiler "${compiler_possibilities[@]}" ";" \
    NO_AVX "${NO_AVX_possibilities[@]}"     ";" \

# Python
if [ "${python_install}" == "True" ]; then
    # If the path to an already installed Python distribution is set in
    # the PYTHONPATH variable, it may conflict with the installation
    # provided by this script. Specifically, issues have been noted when
    # updating pip. Here we make sure to unset PYTHONPATH, and we do not
    # set it again, not even through the reset_environment function.
    unset PYTHONPATH
    # Similarly unset PYTHONHOME
    unset PYTHONHOME
    # As we are installing Python from scratch, we remove the user site
    # directory (~/.local/lib/python3.x/site-packages) from the searched
    # paths when importing modules in Python. In this way, other Python
    # distributions on the system cannot interfere with this one.
    export PYTHONNOUSERSITE="True"
fi
python_install_func() {
    # Determine CC implementation. Only gcc, clang and icc are
    # implemented in the Python configure script. We shall follow suit.
    if [ "${compiler}" == "gnu" ]; then
        CC_implementation="gcc"
    elif [ "${compiler}" == "clang" ]; then
        CC_implementation="clang"
    elif [ "${compiler}" == "intel" ]; then
        CC_implementation="icc"
    else
        info="$("${CC}" --version 2>/dev/null | head -n 1 || :)"
        if echo "${info}" | grep -i "gcc" >/dev/null; then
            CC_implementation="gcc"
        elif echo "${info}" | grep -i "clang" >/dev/null; then
            CC_implementation="clang"
        elif echo "${info}" | grep -i "icc" >/dev/null; then
            CC_implementation="icc"
        elif echo "${info}" | grep -i "intel" >/dev/null; then
            CC_implementation="icc"
        else
            CC_implementation="other"
        fi
    fi
    # If inteloptimizations are specified, append them to CFLAGS
    # if we are using the Intel C compiler.
    # If we are not, skip this installation attempt.
    if [ -n "${inteloptimizations}" ]; then
        if [ "${CC_implementation}" == "icc" ]; then
            export CFLAGS="${CFLAGS} ${inteloptimizations}"
        else
            return 1
        fi
    fi
    # Build with pip if both OpenSSL and zlib are installed.
    # For Python >=3.7, a stand-alone libffi is also required,
    # though we do not check explicitly for this.
    with_ensurepip_install=""
    if [ -n "${openssl_dir}" ] && [ -d "${openssl_dir}" ] \
        && [ -n "${zlib_dir}" ] && [ -d "${zlib_dir}" ]; then
        with_ensurepip_install="--with-ensurepip=install"
    fi
    # Set up environment variables and configure options
    if [ "${disable_atomic_operations}" == "True" ]; then
        sed -i '/have_stdatomic_h *= *yes/c\have_stdatomic_h=no' configure || return 1
    fi
    with_pgo=""
    if [[ "${pyoptimizations}" == *"pgo"* ]]; then
        with_pgo="--enable-optimizations"
    fi
    with_lto=""
    if [[ "${pyoptimizations}" == *"lto"* ]]; then
        with_lto="--with-lto"
    fi
    if [ -n "${ncurses_dir}" ] && [ -d "${ncurses_dir}" ]; then
        export CPPFLAGS="-I${ncurses_dir}/include -I${ncurses_dir}/include/ncurses ${CPPFLAGS}"
        export LD_LIBRARY_PATH="${ncurses_dir}/lib:${LD_LIBRARY_PATH}"
        export LDFLAGS="-L${ncurses_dir}/lib -Wl,-rpath=${ncurses_dir}/lib ${LDFLAGS}"
    fi
    with_openssl=""
    if [ -n "${openssl_dir}" ] && [ -d "${openssl_dir}" ]; then
        export CPPFLAGS="-I${openssl_dir}/include/openssl ${CPPFLAGS}"
        export LD_LIBRARY_PATH="${openssl_dir}/lib:${LD_LIBRARY_PATH}"
        export LDFLAGS="-L${openssl_dir}/lib -Wl,-rpath=${openssl_dir}/lib ${LDFLAGS}"
        with_openssl="--with-openssl=${openssl_dir}"
        # Modify Modules/Setup (Modules/Setup.dist in older Python
        # versions) in order for Python to use the custom SSL library.
        modules_setup_filename=""
        for setup_filename in "Setup" "Setup.dist"; do
            if [ -f "Modules/${setup_filename}" ]; then
                modules_setup_filename="Modules/${setup_filename}"
                break
            fi
        done
        if [ -n "${modules_setup_filename}" ]; then
            first_line="$(grep -n "SSL=" "${modules_setup_filename}")"
            first_line=${first_line%:*}
            ((last_line = first_line + 3))
            sed -i "${first_line},${last_line}s/.//" "${modules_setup_filename}"
            sed -i "${first_line}s/.*/SSL=${openssl_dir//\//\\/}/" "${modules_setup_filename}"
        fi
    fi
    if [ -n "${zlib_dir}" ] && [ -d "${zlib_dir}" ]; then
        export CPPFLAGS="-I${zlib_dir}/include ${CPPFLAGS}"
        export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"
        export LDFLAGS="-L${zlib_dir}/lib -Wl,-rpath=${zlib_dir}/lib ${LDFLAGS}"
    fi
    with_system_ffi=""
    if [ -n "${libffi_dir}" ] && [ -d "${libffi_dir}" ]; then
        with_system_ffi="--with-system-ffi"
        current_dir="$(pwd)"
        for lib_dir in "lib" "lib64"; do
            if [ ! -d "${libffi_dir}/${lib_dir}" ]; then
                continue
            fi
            cd "${libffi_dir}/${lib_dir}"
            for f in *; do
                if     [ -d "${f}" ] \
                    && [[ "${f}" == "libffi"* ]] \
                    && [ -d "${libffi_dir}/${lib_dir}/${f}/include" ]; then
                    export CPPFLAGS="-I${libffi_dir}/${lib_dir}/${f}/include ${CPPFLAGS}"
                    break
                fi
            done
            export LD_LIBRARY_PATH="${libffi_dir}/${lib_dir}:${LD_LIBRARY_PATH}"
            export LDFLAGS="-L${libffi_dir}/${lib_dir} \
-Wl,-rpath=${libffi_dir}/${lib_dir} ${LDFLAGS}"
        done
        cd "${current_dir}"
    fi
    export LDFLAGS="-L${python_dir}/lib -Wl,--rpath=${python_dir}/lib ${LDFLAGS}"
    # Configure.
    # When pgo optimizations are enabled, some of the tests which are
    # performed may hang. It appears that the configure script allows
    # each test to take up to an hour before they are forcefully killed.
    # We thus do not need to kill any such hanging process manually.
    # We do however write out a soothing message in the case of such
    # hangs, letting the user know that everything will be all right.
    pyconfigure_success="True"
    ./configure --enable-shared ${with_pgo} ${with_lto} --prefix="${python_dir}" \
        ${with_ensurepip_install}                                                \
        ${with_openssl}                                                          \
        ${with_system_ffi}                                                       \
        2>&1 || pyconfigure_success="False" & python_configure_pid=$!
    soothe ${python_configure_pid}
    if [ "${pyconfigure_success}" == "False" ]; then
        return 1
    fi
    # Make
    make ${make_jobs} 2>&1 || return 1
    # Test
    if [ "${do_tests}" == "True" ]; then
        # On some systems it has been observed that test_threading hangs
        # indefinitely, and so we kill the test process if it has not
        # completed within ${python_test_max_time} seconds.
        python_test_max_time=7200
        exit_code_filename="${tmp_dir}/.exit_code_python"
        mkdir -p "$(dirname "${exit_code_filename}")"
        rm -f "${exit_code_filename}" || :
        (                                                     \
            make ${make_jobs} test 2>&1 | tee "test_log";     \
            echo "${PIPESTATUS[0]}" > "${exit_code_filename}" \
        ) & python_test_pid=$!
        soothe ${python_test_pid} ${python_test_max_time} ${python_test_max_time}
        sleep 1
        kill -9 ${python_test_pid} >/dev/null 2>&1 || :
        wait    ${python_test_pid} >/dev/null 2>&1 || :
        exit_code="$(cat "${exit_code_filename}" 2>/dev/null || :)"
        rm -f "${exit_code_filename}" || :
        if [ "${exit_code}" != "0" ]; then
            test_success="False"
        fi
    fi
    # Make install
    make install 2>&1 || return 1  # Should be run serially
    # Cleanup if installing in slim mode.
    # Note that this also cleans up e.g. OpenSSL.
    if [ "${slim}" == "True" ]; then
        # Blessings (curses) needs share/terminfo
        mv "${python_dir}/share/terminfo" "${python_dir}/share/.terminfo" || :
        rm -rf "${python_dir}/share/"* || :
        mv "${python_dir}/share/.terminfo" "${python_dir}/share/terminfo" || :
    fi
}
install "Python"                                                    \
    compiler "${compiler_possibilities_specified_mpi_last[@]}"  ";" \
    inteloptimizations "" "-O1"              ";"                    \
    disable_atomic_operations "False" "True" ";"                    \
    pyoptimizations "pgo lto" "pgo" "lto" "" ";"                    \
# Create a python variable, storing the path to the Python interpreter
set_python



###########################
# Install Python packages #
###########################
# Set "pypackage"_installed variables
blessings_installed="False"
cython_installed="False"
cythongsl_installed="False"
h5py_installed="False"
matplotlib_installed="False"
mpi4py_installed="False"
numpy_installed="False"
scipy_installed="False"
sphinx_installed="False"
sphinx_copybutton_installed="False"
sphinx_rtd_theme_installed="False"
sphinx_tabs_installed="False"
if [ -n "${python}" ]; then
    current_step="checking of installed Python packages"
    set_status "Checking for installed Python packages"
    for pypackage in      \
        blessings         \
        cython            \
        cythongsl         \
        h5py              \
        matplotlib        \
        mpi4py            \
        numpy             \
        pip               \
        scipy             \
        sphinx            \
        sphinx_copybutton \
        sphinx_rtd_theme  \
        sphinx_tabs       \
    ; do
        pypackage_installed=$(check_pypackage_installed ${pypackage})
        eval "${pypackage}_installed=\"${pypackage_installed}\""
    done
fi

# Function for downloading Python packages, utilizing pip
pip_download() {
    # Arguments: Python package name, version, pip_download_time.
    # No second argument, blank second argument or a second argument of
    # "upgrade" means newest version. The second argument can also be a
    # version string that pip understands, e.g. ">=1.4".
    # The third argument determines how many seconds pip should get
    # to download the package before it is killed. This can be helpful
    # if pip (for whatever reason) decides to run the setup.py file of
    # the package after a successful download, and that process ends
    # up hanging. If no third argument is given, or if the third
    # argument is 0, no time limit is set.
    local command_end=""
    if [ -n "${2}" ] && [ "${2}" != "upgrade" ]; then
        if [[ "${2}" == [0-9]* ]]; then
            # Second argument is a specific version
            command_end="==${2}"
        else
            # Second argument is a version string that pip understands
            command_end="${2}"
        fi
    fi
    pip_name="$(echo "${1}" | tr '[:upper:]' '[:lower:]')"
    pip_name_nodashes="${pip_name//-/}"
    pip_name_nodashes="${pip_name_nodashes//_/}"
    tmp_pip_dir="${tmp_dir}/pip"
    mkdir -p "${tmp_pip_dir}"
    tmp_pip_dir="${tmp_pip_dir// /\\ }"  # Add backslashes before spaces
    # Maximum allowed time (in seconds) for download. After this time,
    # the download process will be killed. This is needed because the
    # process sometimes hang after an otherwise successful download.
    pip_download_time=3600
    if [ -n "${3}" ]; then
        pip_download_time=${3}
    fi
    # Download the Python package
    pip_args="download --no-cache-dir --no-binary=:all: --dest=${tmp_pip_dir} \
${pip_name}${command_end}"
    for n in {1..10}; do
        pip_status="error"
        for extra_pip_arg in                                 \
            "--no-build-isolation --no-deps --no-use-pep517" \
            "--no-build-isolation           --no-use-pep517" \
            "                     --no-deps --no-use-pep517" \
            "                               --no-use-pep517" \
            "                                              " \
            "--no-build-isolation --no-deps                " \
            "--no-build-isolation                          " \
            "                     --no-deps                " \
        ; do
            extra_pip_arg="$(echo ${extra_pip_arg} | awk '{$1=$1};1')"
            all_pip_args="${pip_args} ${extra_pip_arg}"
            printf "
Attempting to download ${1} using pip ${all_pip_args}\n\n"
            # Download Python package
            "${python}" -m pip ${all_pip_args} & pip_download_pid=$!
            # The above command may succeed in retrieving the
            # package, but then hang indefinitely.
            # Kill the process after ${pip_download_time} seconds.
            soothe ${pip_download_pid} ${pip_download_time}
            # If the archive exists in the tmp/pip dir,
            # the download completed successfully.
            if ls "${tmp_dir}/pip"                                \
                | sed 's/-//g; s/_//g'                            \
                | grep -i "${pip_name_nodashes}" > /dev/null 2>&1 \
            ; then
                pip_status="success"
            fi
            if [ "${pip_status}" == "success" ]; then
                break
            fi
        done
        if [ "${pip_status}" == "success" ]; then
            break
        fi
        sleep ${sleep_time}
    done
    if [ "${pip_status}" == "error" ]; then
        error "Error downloading ${1}"
        exit 1
    fi
}

# Function for installing and upgrading Python packages, utilizing pip
pip_install_pypackage() {
    # Arguments: Python package name, [version or "upgrade"]
    # (install specific version or update existing version to newest).
    # If second argument is not provided, the newest version
    # will be installed.
    local command_end=""
    pypackage_version=""
    if [ "${2}" == "upgrade" ]; then
        current_step="upgrade of ${1}"
        heading "Upgrading ${1}"
        set_status "Upgrading ${1}"
    else
        if [ -n "${2}" ]; then
            current_step="installation of ${1} ${2}"
            heading "Installing ${1} ${2}"
            set_status "Installing ${1} ${2}"
        else
            current_step="installation of ${1}"
            heading "Installing ${1}"
            set_status "Installing ${1}"
        fi
        if [ -n "${2}" ]; then
            pypackage_version="${2}"
            if [[ "${pypackage_version}" == *"="* ]] || [[ "${pypackage_version}" == *"<"* ]] \
                || [[ "${pypackage_version}" == *">"* ]]; then
                    command_end="${pypackage_version}"
            else
                command_end="==${pypackage_version}"
            fi
        fi
    fi
    # Download Python package source
    tmp_pip_dir="${tmp_dir}/pip"
    rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" || :
    mkdir -p "${tmp_pip_dir}" "${tmp_pip_dir}_tmp"
    export TMPDIR="${tmp_pip_dir}_tmp"
    export TEMP="${TMPDIR}"
    export TMP="${TMPDIR}"
    pypackage="$(echo "${1}" | tr '[:upper:]' '[:lower:]')"
    pypackage_nodashes="${pypackage//-/}"
    pypackage_nodashes="${pypackage_nodashes//_/}"
    pip_download "${1}" "${2}"
    rm -rf "${tmp_pip_dir}_cp" || :
    cp -r "${tmp_pip_dir}" "${tmp_pip_dir}_cp"
    # Install Python package from source
    upgrade_flag=""
    if [ "${2}" == "upgrade" ]; then
        upgrade_flag="--upgrade"
    fi
    for force_recythonization in "False" "True"; do
        if [ "${force_recythonization}" == "True" ]; then
            # Some Python packages may contain pre-cythonised files as
            # part of their source code. If this is done with a Cython
            # version that is incompatible with the Python version in
            # use, this can lead to failure. We now try deleting any
            # such pre-cythonised files, forcing re-cythonisation.
            working_cython=$(check_pypackage_installed cython)
            if [ "${working_cython}" == "False" ]; then
                continue
            fi
            rm -rf "${tmp_pip_dir}" || :
            cp -r "${tmp_pip_dir}_cp" "${tmp_pip_dir}"
            # Extract source files
            wd="$(pwd)"
            cd "${tmp_pip_dir}"
            pypackage_archive=""
            for f in *; do
                f_lower="$(echo "${f}" | tr '[:upper:]' '[:lower:]')"
                f_lower="${f_lower//-/}"
                f_lower="${f_lower//_/}"
                if [ ! -d "${f}" ] && [[ "${f_lower}" == "${pypackage_nodashes}"* ]]; then
                    pypackage_archive="${f}"
                    break
                fi
            done
            if [ -z "${pypackage_archive}" ]; then
                # Could not locate source archive
                continue
            fi
            extract "${pypackage_archive}" "True"
            for f in *; do
                f_lower="$(echo "${f}" | tr '[:upper:]' '[:lower:]')"
                f_lower="${f_lower//-/}"
                f_lower="${f_lower//_/}"
                if [ -d "${f}" ] && [[ "${f_lower}" == "${pypackage_nodashes}"* ]]; then
                    cd "${f}"
                    break
                fi
            done
            # Remove pre-cythonised files
            precythonized="$(grep -r -l '^/\* Generated by Cython' .)"
            if [ -z "${precythonized}" ]; then
                cd "${wd}"
                continue
            fi
            rm -f ${precythonized}
            # Pack source into a tar.gz file with the name
            # <package>-<version>.tar.gz, which takes the place of the
            # downloaded archive.
            cd ..
            rm -rf "${pypackage_archive}"
            if [ -n "${pypackage_version}" ]; then
                pypackage_archive="${pypackage}-${pypackage_version}.tar.gz"
            else
                pypackage_archive="${pypackage}.tar.gz"
            fi
            tar -cvf - "${f}" | gzip > "${pypackage_archive}"
            rm -rf "${f}"
            cd "${wd}"
            rm -rf "${tmp_pip_dir}_cp" || :
            cp -r "${tmp_pip_dir}" "${tmp_pip_dir}_cp"
            # The re-cythonisation should be carried out using the
            # Cython that is installed on the Python that we work with.
            # It may however be fetched from the PATH, and so we need to
            # ensure that the first Cython ('cython', 'cythonize') on
            # the PATH is the correct one.
            if [ -d "${python_dir}/bin" ]; then
                export PATH="${python_dir}/bin:${PATH}"
            fi
        fi
        for pyuser in "" "--user"; do
            # After the adoption of PEP 518 (pip 10), some packages
            # require wheels (not bare source) when building. This can
            # be disabled by supplying --no-build-isolation. We try
            # both. Some times the installation process will appear to
            # hang, but it will eventually get going. This happens often
            # for particular packages, such as h5py. When this is the
            # case, write a soothing message.
            for extra_pip_arg in                                      \
                "--no-cache-dir                                     " \
                "--no-cache-dir --no-build-isolation                " \
                "               --no-build-isolation                " \
                "--no-cache-dir                      --no-use-pep517" \
                "--no-cache-dir --no-build-isolation --no-use-pep517" \
                "               --no-build-isolation --no-use-pep517" \
                "                                    --no-use-pep517" \
                "                                                   " \
            ; do
                extra_pip_arg="$(echo ${extra_pip_arg} | awk '{$1=$1};1')"
                rm -rf "${tmp_pip_dir}" || :
                cp -r "${tmp_pip_dir}_cp" "${tmp_pip_dir}"
                if [ -z "${upgrade_flag}" ]; then
                    printf "
Attempting to install ${1} using pip with force_recythonization=${force_recythonization}, \
pyuser=${pyuser}, extra_pip_arg=${extra_pip_arg}\n\n"
                    "${python}" -m pip uninstall "${pypackage}" -y >/dev/null 2>&1 || :
                fi
                "${python}" -m pip install            \
                    ${pyuser}                         \
                    -v                                \
                    ${extra_pip_arg}                  \
                    ${upgrade_flag}                   \
                    --no-index                        \
                    --find-links="${tmp_pip_dir}"     \
                    "${pypackage}${command_end}" 2>&1 \
                    & pip_install_pid=$!
                soothe ${pip_install_pid}
                pypackage_installed=$(check_pypackage_installed ${pypackage})
                if [ "${pypackage_installed}" == "True" ]; then
                    break
                fi
            done
            if [ "${pypackage_installed}" == "True" ]; then
                break
            fi
            # If we failed to install the Python package,
            # try installing it via pip without supplying
            # the many additional arguments.
            if [ "${force_recythonization}" == "True" ]; then
                continue
            fi
            rm -rf "${tmp_pip_dir}" || :
            for extra_pip_arg in                                      \
                "--no-cache-dir                                     " \
                "--no-cache-dir --no-build-isolation                " \
                "               --no-build-isolation                " \
                "--no-cache-dir                      --no-use-pep517" \
                "--no-cache-dir --no-build-isolation --no-use-pep517" \
                "               --no-build-isolation --no-use-pep517" \
                "                                    --no-use-pep517" \
                "                                                   " \
            ; do
                extra_pip_arg="$(echo ${extra_pip_arg} | awk '{$1=$1};1')"
                printf "
Attempting to install ${1} using pip with default settings, \
force_recythonization=${force_recythonization}, pyuser=${pyuser}, \
extra_pip_arg=${extra_pip_arg}\n\n"
                if [ -z "${upgrade_flag}" ]; then
                    "${python}" -m pip uninstall "${pypackage}" -y >/dev/null 2>&1 || :
                fi
                "${python}" -m pip install ${pyuser} ${extra_pip_arg} \
                    "${pypackage}${command_end}" 2>&1 & pip_install_pid=$!
                soothe ${pip_install_pid}
                pypackage_installed=$(check_pypackage_installed ${pypackage})
                if [ "${pypackage_installed}" == "True" ]; then
                    break
                fi
            done
            if [ "${pypackage_installed}" == "True" ]; then
                break
            fi
        done
        if [ "${pypackage_installed}" == "True" ]; then
            break
        fi
    done
    reset_environment
    rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" "${tmp_pip_dir}_cp" || :
    # Return non-zero on failure
    if [ "${pypackage_installed}" != "True" ]; then
        echo "pip could not install/upgrade ${1}"
        return 1
    fi
}

# Small wrapper around pip_install_pypackage() for easy installation of
# Python package dependencies where we do not care about the version
# (the latest available version will be installed).
pip_install_pypackage_dependencies() {
    # Arguments: Name of Python package which need the dependencies,
    # [exit on error]. In addition, the 'dependencies' variable must be
    # set as an array of names of Python package dependencies,
    # possibly with added version requirements (pip style).
    exit_on_error="True"
    if [ -n "${2}" ]; then
        exit_on_error="${2}"
    fi
    if [ "${1}" != "${pip_install_pypackage_dependencies_prevdep}" ]; then
        current_step="installation of ${1} dependencies"
        heading "Installing ${1} dependencies"
        set_status "Installing ${1} dependencies"
    fi
    pip_install_pypackage_dependencies_prevdep="${1}"
    for dependency in ${dependencies[@]}; do
        dependency="$("${python}" -c "
dependency = '${dependency}'.replace(' ', '')
index = len(dependency)
for c in '=<>':
    if c in dependency:
        index = min(dependency.index(c) , index)
name = dependency[:index]
vreq = dependency[index:]
print(name, vreq)
")"
        dependency_name="$(echo "${dependency}" | awk '{print $1}')"
        dependency_vrec="$(echo "${dependency}" | awk '{print $2}')"
        dependency_installed="$(check_pypackage_installed "${dependency_name}")"
        if [ "${dependency_installed}" == "False" ]; then
            if [ "${exit_on_error}" == "False" ]; then
                pip_install_pypackage "${dependency_name}" ${dependency_vrec} || :
            else
                pip_install_pypackage "${dependency_name}" ${dependency_vrec}
            fi
        fi
    done
}

# Upgrade/install pip, setuptools and wheel.
# Do not use the pip_download or pip_install_pypackage functions
# for this, as these packages (and their dependencies) may actually be
# needed for that to work, resulting in a bootstrapping problem.
# This problem really arises from the choice of installing Python
# packages from source. Let 'pip install' upgrade pip, setuptools and
# wheel by whatever means it wants, ensuring that the dependencies of
# these bootstrapping packages are installed/upgraded as well.
if [ "${pip_install}" == "True" ] && [ "${python_install}" == "True" ]; then
    tmp_pip_dir="${tmp_dir}/pip"
    export TMPDIR="${tmp_pip_dir}_tmp"
    export TEMP="${TMPDIR}"
    export TMP="${TMPDIR}"
    for package in "pip" "setuptools" "wheel"; do
        if [ "${python_installed}" == "True" ]; then
            if [ "$(check_pypackage_installed "${package}")" == "True" ]; then
                continue
            fi
        fi
        current_step="upgrade/install of ${package}"
        heading "Upgrading/installing ${package}"
        set_status "Upgrading/installing ${package}"
        eval "package_version=\${${package}_version}"
        pip_success="True"
        for extra_pip_arg in                                      \
            "--no-cache-dir                                     " \
            "--no-cache-dir --no-build-isolation                " \
            "               --no-build-isolation                " \
            "--no-cache-dir                      --no-use-pep517" \
            "--no-cache-dir --no-build-isolation --no-use-pep517" \
            "               --no-build-isolation --no-use-pep517" \
            "                                    --no-use-pep517" \
            "                                                   " \
        ; do
            extra_pip_arg="$(echo ${extra_pip_arg} | awk '{$1=$1};1')"
            rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" || :
            mkdir -p "${tmp_pip_dir}" "${tmp_pip_dir}_tmp"
            "${python}" -m pip install \
                ${extra_pip_arg}       \
                --upgrade              \
                "${package}==${package_version}" 2>&1 || pip_success="False"
            if [ "${pip_success}" == "True" ]; then
                break
            fi
        done
        # Do not exit on failure, but write a warning
        if [ "${pip_success}" == "False" ]; then
            error "Could not upgrade ${package}"
        fi
    done
    reset_environment
    rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" || :
fi

# The code below will upgrade all packages pre-installed
# with the newly installed Python distribution,
# if upgrade_preinstalled_pypackages is True.
if [ -z "${upgrade_preinstalled_pypackages}" ]; then
    upgrade_preinstalled_pypackages="False"
fi
if [ "${python_install}" == "True" ] && [ "${python_installed}" == "False" ] \
    && [ "${upgrade_preinstalled_pypackages}" == "True" ]; then
    installed_packages_success="True"
    installed_packages="$("${python}" -m pip list --format=colu2mns 2>/dev/null)" \
        || installed_packages_success="False"
    if [ "${installed_packages_success}" == "False" ]; then
        installed_packages_success="True"
        installed_packages="$("${python}" -m pip list 2>/dev/null)" \
            || installed_packages_success="False"
    fi
    if [ "${installed_packages_success}" == "False" ]; then
        installed_packages="$("${python}" -B -c "
import pip
print('\n'.join([i.key for i in pip.get_installed_distributions()]))
")"
    fi
    installed_packages="$("${python}" -B -c "
packages = '''${installed_packages}'''.split('\n')
for i, package in enumerate(packages):
    if not package.strip().replace(' ', '').replace('-', ''):
        packages = packages[i+1:]
        break
print('\n'.join(packages))
" | awk '{print $1}')"
    while read package; do
        # No need to attempt updates of pip, setuptools and wheel,
        # as these have just been updated.
        if     [ "${package}" == "pip"        ] \
            || [ "${package}" == "setuptools" ] \
            || [ "${package}" == "wheel"      ]; then
            continue
        fi
        # Attempt to update all other installed Python packages
        for n in {1..10}; do
            pip_success="True"
            pip_install_pypackage "${package}" "upgrade" || pip_success="False"
            if [ "${pip_success}" == "True" ]; then
                break
            fi
        done
    done <<< "${installed_packages}"
fi

# Install Python packages from PyPI

# Blessings
if [ "${blessings_install}" == "True" ] && [ "${blessings_installed}" == "False" ] \
    && [ "$(check_pypackage_installed blessings)" == "False" ]; then
    # Blessings has six as a required dependency, though this is not
    # necessarily downloaded along with Blessings by pip. If not already
    # installed, we install this Python package now. Do not exit on
    # failure, as Blessings may succeed in installing six itself.
    dependencies=( \
        "six"      \
    )
    pip_install_pypackage_dependencies "Blessings" "False"
    # Install Blessings
    pip_install_pypackage "Blessings" "${blessings_version}"
fi

# Cython
if [ "${cython_install}" == "True" ] && [ "${cython_installed}" == "False" ] \
    && [ "$(check_pypackage_installed cython)" == "False" ]; then
    install_success="False"
    for compiler in "${compiler_possibilities_specified_mpi_last[@]}"; do
        "use_${compiler}_compilers" || continue
        printf "
Attempting to install Cython with compiler=${compiler}\n\n"
        pip_install_pypackage "Cython" "${cython_version}"
        if [ "$(check_pypackage_installed cython)" == "False" ]; then
            continue
        fi
        install_success="True"
        break
    done
    if [ "${install_success}" == "False" ]; then
        error "Failed to install Cython"
        exit 1
    fi
    # Implement fixes to the installed Cython code
    set_cython_dir() {
        cython_dir="$(                                                   \
            dirname "$(                                                  \
                "${python}" -B -c                                        \
                'import inspect, cython; print(inspect.getfile(cython))' \
                || :                                                     \
            )"                                                           \
        )"
        if [ "$(basename "${cython_dir}")" == "site-packages" ]; then
            for base in "Cython" "cython"; do
                for d in "${cython_dir}/${base}"*; do
                    if [ -f "${d}/${1}" ]; then
                        cython_dir="${d}"
                        return
                    fi
                done
            done
        fi
    }
    if [ ${python_version_major} -eq 3 ] && [ ${python_version_minor} -ge 9 ]; then
        # PyUnicode_GET_SIZE has been deprecated in favor of
        # PyUnicode_GET_LENGTH since Python 3.3. In Python 3.9 the use
        # of PyUnicode_GET_SIZE emits a warning. Relevant issue:
        #   https://github.com/cython/cython/issues/3924
        cython_file="Utility/ModuleSetupCode.c"
        set_cython_dir "${cython_file}"
        if [ -f "${cython_dir}/${cython_file}" ]; then
            sed -i                                                  \
                's/# *define *__Pyx_PyUnicode_IS_TRUE.*/\
#define __Pyx_PyUnicode_IS_TRUE(u) (0 != PyUnicode_GET_LENGTH(u))/' \
                "${cython_dir}/${cython_file}"                      \
                || :
        fi
    fi
    reset_environment
fi

# CythonGSL
if [ "${cythongsl_install}" == "True" ] && [ "${cythongsl_installed}" == "False" ] \
    && [ "$(check_pypackage_installed cythongsl)" == "False" ]; then
    install_success="False"
    for compiler in "${compiler_possibilities_specified_mpi_last[@]}"; do
        reset_environment
        "use_${compiler}_compilers" || continue
        printf "
Attempting to install CythonGSL with compiler=${compiler}\n\n"
        export LD_LIBRARY_PATH="${gsl_dir}/lib:${LD_LIBRARY_PATH}"
        pip_install_pypackage "CythonGSL" "${cythongsl_version}"
        if [ "$(check_pypackage_installed cythongsl)" == "False" ]; then
            continue
        fi
        install_success="True"
        break
    done
    if [ "${install_success}" == "False" ]; then
        error "Failed to install CythonGSL"
        exit 1
    fi
    # Implement fixes to the installed CythonGSL code.
    # At least in 0.2.2, some GSL_* variables are wrongly
    # (re)declared in gsl_integration.pxd, leading to warnings
    # about redeclaration when compiling CO𝘕CEPT.
    # Here we fix this by removing these declarations.
    # Note that these variables are already (properly)
    # declared in __init__.pxd.
    cythongsl_dir="$(                                                        \
        dirname "$(                                                          \
            "${python}" -B -c                                                \
            'import inspect, cython_gsl; print(inspect.getfile(cython_gsl))' \
            || :                                                             \
        )"                                                                   \
    )"
    if [ -f "${cythongsl_dir}/gsl_integration.pxd" ]; then
        for varname in     \
            "GSL_EMAXITER" \
            "GSL_EROUND"   \
            "GSL_ESING"    \
            "GSL_EDIVERGE" \
        ; do
            sed -i "/${varname}/d" "${cythongsl_dir}/gsl_integration.pxd" || :
        done
    fi
    reset_environment
fi

# NumPy (manual invocation of setup.py is needed
# as we need to link to OpenBLAS).
if [ "${numpy_install}" == "True" ] && [ "${numpy_installed}" == "False" ] \
    && [ "$(check_pypackage_installed numpy)" == "False" ]; then
    # The testing of NumPy depends on other Python packages
    # not directly used by CO𝘕CEPT.
    # If missing, we install these now.
    if [ "${do_tests}" == "True" ]; then
        dependencies=(   \
            "hypothesis" \
            "pytest"     \
        )
        pip_install_pypackage_dependencies "NumPy test" "False"
    fi
    current_step="installation of NumPy ${numpy_version}"
    heading "Installing NumPy ${numpy_version}"
    set_status "Installing NumPy ${numpy_version}"
    # Download NumPy
    tmp_pip_dir="${tmp_dir}/pip"
    rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" || :
    mkdir -p "${tmp_pip_dir}_tmp"
    export TMPDIR="${tmp_pip_dir}_tmp"
    export TEMP="${TMPDIR}"
    export TMP="${TMPDIR}"
    pip_download "NumPy" "${numpy_version}"
    cd "${tmp_pip_dir}"
    # It can happen that an archive format different from tar.gz is
    # downloaded, in which case the extraction will fail if the
    # corresponding tool is not installed. In that case, try to download
    # NumPy directly from GitHub.
    extract "numpy"* "True" || :
    numpy_extract_success="False"
    for f in *; do
        f_lower="$(echo "${f}" | tr '[:upper:]' '[:lower:]')"
        if [ -d "${f}" ] && [[ "${f_lower}" == "numpy"* ]]; then
            numpy_extract_success="True"
            numpy_build_dir="${tmp_pip_dir}/${f}"
            break
        fi
    done
    if [ "${numpy_extract_success}" == "False" ]; then
        numpy_url="https://github.com/numpy/numpy/archive/v${numpy_version}.tar.gz"
        download "NumPy"
        current_step="installation of NumPy ${numpy_version}"
        heading "Installing NumPy ${numpy_version}"
        set_status "Installing NumPy ${numpy_version}"
        cd "${tmp_dir}/numpy"
        extract * "True"
        for f in *; do
            f_lower="$(echo "${f}" | tr '[:upper:]' '[:lower:]')"
            if [ -d "${f}" ] && [[ "${f_lower}" == "numpy"* ]]; then
                numpy_build_dir="${tmp_dir}/numpy/${f}"
                break
            fi
        done
    fi
    # Create a site.cfg file containing information about OpenBLAS
    echo "[DEFAULT]
library_dirs = ${blas_dir}/lib
include_dirs = ${blas_dir}/include

[ALL]
library_dirs = ${blas_dir}/lib
include_dirs = ${blas_dir}/include

[atlas]
atlas_libs = openblas
libraries = openblas

[openblas]
libraries = openblas
library_dirs = ${blas_dir}/lib
include_dirs = ${blas_dir}/include
runtime_library_dirs = ${blas_dir}/lib
" > "${numpy_build_dir}/site.cfg"
    cp -r "${numpy_build_dir}" "${numpy_build_dir}_cp"
    # Build and install NumPy with OpenBLAS support.
    # We wish to use the gfortran Fortran compiler. We try out all the
    # compiler environments but overwriting the Fortran compiler.
    # If this fails, we retry without overwriting the Fortran compiler.
    numpy_install_func() {
        if [ "${numpy_gfortran}" == "True" ]; then
            export FC="gfortran"
            export F77="gfortran"
            export F90="gfortran"
            export F9X="gfortran"
        fi
        export CFLAGS="${CFLAGS} ${cstd}"
        export TMPDIR="${tmp_pip_dir}_tmp"
        export TEMP="${TMPDIR}"
        export TMP="${TMPDIR}"
        if [ -d "${blas_dir}" ]; then
            export BLAS="${blas_dir}/lib/libopenblas.a"
            export LAPACK="${blas_dir}/lib/libopenblas.a"
            export LD_LIBRARY_PATH="${blas_dir}/lib:${LD_LIBRARY_PATH}"
        fi
        export FCFLAGS="${extra_FCFLAGS} ${FCFLAGS}"
        export FFLAGS="${extra_FCFLAGS} ${FFLAGS}"
        export LDFLAGS="${extra_LDFLAGS} ${LDFLAGS}"
        cd "${concept_dir}"
        rm -rf "${numpy_build_dir}" || :
        "${python}" -m pip uninstall "numpy" -y >/dev/null 2>&1 || :
        cp -r "${numpy_build_dir}_cp" "${numpy_build_dir}"
        cd "${numpy_build_dir}"
        echo "True" > ".setuppy_success"
        if [ -n "${fcompiler}" ]; then
            ("${python}" setup.py build --fcompiler="${fcompiler}" \
                || echo "False" > ".setuppy_success") & setuppy_pid=$!
        else
            ("${python}" setup.py build \
                || echo "False" > ".setuppy_success") & setuppy_pid=$!
        fi
        soothe ${setuppy_pid}
        sleep 1
        setuppy_success="$(cat '.setuppy_success')"
        if [ "${setuppy_success}" != "True" ]; then
            return 1
        fi
        if [ "${setuppy_mode}" == "wheel" ]; then
            rm -rf concept_wheel || :
            ("${python}" setup.py bdist_wheel -d concept_wheel \
                && cd "${concept_dir}"                         \
                && "${python}" -m pip install                  \
                    --no-deps --ignore-installed               \
                    "${numpy_build_dir}/concept_wheel/"*.whl   \
            ) & setuppy_pid=$!
        elif [ "${setuppy_mode}" == "install" ]; then
            "${python}" setup.py install & setuppy_pid=$!
        elif [ "${setuppy_mode}" == "--user" ]; then
            "${python}" setup.py install --user & setuppy_pid=$!
        fi
        soothe ${setuppy_pid}
        if [ "$(check_pypackage_installed numpy)" == "False" ]; then
            return 1
        fi
        # Clean up
        cd "${concept_dir}"
        rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" "${tmp_dir}/numpy" || :
        reset_environment
        # Test NumPy
        if [ "${do_tests}" == "True" ]; then
            # Kill the testing and consider it failed if any given test
            # takes longer than numpy_test_max_time seconds.
            numpy_test_max_time=3600
            exit_code_filename="${tmp_dir}/.exit_code_numpy"
            mkdir -p "$(dirname "${exit_code_filename}")"
            rm -f "${exit_code_filename}" || :
            if [ -d "${blas_dir}" ]; then
                export LD_LIBRARY_PATH="${blas_dir}/lib:${LD_LIBRARY_PATH}"
            fi
            ("${python}" -B -c "import numpy; numpy.test('full', \
extra_argv=['-q', '--color=yes'])" 2>&1 | tee "test_log"; \
                echo "${PIPESTATUS[0]}" > "${exit_code_filename}") & numpy_test_pid=$!
            soothe ${numpy_test_pid} ${numpy_test_max_time}
            sleep 1
            kill -9 ${numpy_test_pid} >/dev/null 2>&1 || :
            wait    ${numpy_test_pid} >/dev/null 2>&1 || :
            exit_code="$(cat "${exit_code_filename}" 2>/dev/null || :)"
            rm -f "${exit_code_filename}" || :
            if [ "${exit_code}" != "0" ]; then
                test_success="False"
            fi
            if tail -n 1 "test_log" | grep " failed" >/dev/null 2>&1; then
                test_success="False"
            fi
        fi
    }
    install "NumPy" "no_init_install"                                  \
        setuppy_mode "wheel" "install" "--user"                    ";" \
        numpy_gfortran "True" "False"                              ";" \
        compiler "${compiler_possibilities_specified_mpi_last[@]}" ";" \
        cstd "-std=c99" ""                                         ";" \
        fcompiler "gnu95" ""                                       ";" \
        extra_FCFLAGS "" "-fPIC"                                   ";" \
        extra_LDFLAGS "" "-shared"                                 ";" \

fi

# SciPy (manual invocation of setup.py is needed
# as we need to link to OpenBLAS).
if [ "${scipy_install}" == "True" ] && [ "${scipy_installed}" == "False" ] \
    && [ "$(check_pypackage_installed scipy)" == "False" ]; then
    # As of SciPy 1.4, pybind11 is a required dependency.
    # As of SciPy 1.7, Pythran is a required dependency.
    # These are not automatically installed by pip.
    # If not already installed, we install these Python packages now.
    dependencies=( \
        "pybind11" \
        "pythran"  \
    )
    pip_install_pypackage_dependencies "SciPy"
    # The testing of SciPy depends on other Python packages
    # not directly used by CO𝘕CEPT.
    # If missing, we install these now.
    if [ "${do_tests}" == "True" ]; then
        dependencies=( \
            "pytest"   \
        )
        pip_install_pypackage_dependencies "SciPy test" "False"
    fi
    current_step="installation of SciPy ${scipy_version}"
    heading "Installing SciPy ${scipy_version}"
    set_status "Installing SciPy ${scipy_version}"
    # Download SciPy
    tmp_pip_dir="${tmp_dir}/pip"
    rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" || :
    mkdir -p "${tmp_pip_dir}_tmp"
    export TMPDIR="${tmp_pip_dir}_tmp"
    export TEMP="${TMPDIR}"
    export TMP="${TMPDIR}"
    pip_download "SciPy" "${scipy_version}"
    cd "${tmp_pip_dir}"
    extract "scipy"* "True"
    for f in *; do
        f_lower="$(echo "${f}" | tr '[:upper:]' '[:lower:]')"
        if [ -d "${f}" ] && [[ "${f_lower}" == "scipy"* ]]; then
            scipy_build_dir="${tmp_pip_dir}/${f}"
            break
        fi
    done
    # Create a site.cfg file containing information about OpenBLAS
    echo "[DEFAULT]
library_dirs = ${blas_dir}/lib
include_dirs = ${blas_dir}/include

[ALL]
library_dirs = ${blas_dir}/lib
include_dirs = ${blas_dir}/include

[atlas]
atlas_libs = openblas
libraries = openblas

[openblas]
libraries = openblas
library_dirs = ${blas_dir}/lib
include_dirs = ${blas_dir}/include
runtime_library_dirs = ${blas_dir}/lib
" > "${scipy_build_dir}/site.cfg"
    cp -r "${scipy_build_dir}" "${scipy_build_dir}_cp"
    # Build and install SciPy with OpenBLAS support.
    # We wish to use the gfortran Fortran compiler. We try out all the
    # compiler environments but overwriting the Fortran compiler.
    # If this fails, we retry without overwriting the Fortran compiler.
    scipy_install_func() {
        if [ "${scipy_gfortran}" == "True" ]; then
            export FC="gfortran"
            export F77="gfortran"
            export F90="gfortran"
            export F9X="gfortran"
        fi
        export CFLAGS="${CFLAGS} ${cstd}"
        export TMPDIR="${tmp_pip_dir}_tmp"
        export TEMP="${TMPDIR}"
        export TMP="${TMPDIR}"
        if [ -d "${blas_dir}" ]; then
            export BLAS="${blas_dir}/lib/libopenblas.a"
            export LAPACK="${blas_dir}/lib/libopenblas.a"
            export LD_LIBRARY_PATH="${blas_dir}/lib:${LD_LIBRARY_PATH}"
        fi
        export FCFLAGS="${extra_FCFLAGS} ${FCFLAGS}"
        export FFLAGS="${extra_FCFLAGS} ${FFLAGS}"
        export LDFLAGS="${extra_LDFLAGS} ${LDFLAGS}"
        cd "${concept_dir}"
        rm -rf "${scipy_build_dir}" || :
        "${python}" -m pip uninstall "scipy" -y >/dev/null 2>&1 || :
        cp -r "${scipy_build_dir}_cp" "${scipy_build_dir}"
        cd "${scipy_build_dir}"
        if [ -n "${zip_safe}" ]; then
            sed -i "s/\(^ *\)\(setup *(.*\)$/\1metadata['zip_safe'] = ${zip_safe}; \2/" \
                setup.py || return 1
        fi
        echo "True" > ".setuppy_success"
        if [ -n "${fcompiler}" ]; then
            ("${python}" setup.py build --fcompiler="${fcompiler}" \
                || echo "False" > ".setuppy_success") & setuppy_pid=$!
        else
            ("${python}" setup.py build \
                || echo "False" > ".setuppy_success") & setuppy_pid=$!
        fi
        soothe ${setuppy_pid}
        sleep 1
        setuppy_success="$(cat '.setuppy_success')"
        if [ "${setuppy_success}" != "True" ]; then
            return 1
        fi
        if [ "${setuppy_mode}" == "wheel" ]; then
            rm -rf concept_wheel || :
            ("${python}" setup.py bdist_wheel -d concept_wheel \
                && cd "${concept_dir}"                         \
                && "${python}" -m pip install                  \
                    --no-deps --ignore-installed               \
                    "${scipy_build_dir}/concept_wheel/"*.whl   \
            ) & setuppy_pid=$!
        elif [ "${setuppy_mode}" == "install" ]; then
            "${python}" setup.py install & setuppy_pid=$!
        elif [ "${setuppy_mode}" == "--user" ]; then
            "${python}" setup.py install --user & setuppy_pid=$!
        fi
        soothe ${setuppy_pid}
        if [ "$(check_pypackage_installed scipy)" == "False" ]; then
            return 1
        fi
        # Clean up
        cd "${concept_dir}"
        rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" "${tmp_dir}/scipy" || :
        reset_environment
        # Test SciPy
        if [ "${do_tests}" == "True" ]; then
            # Kill the testing and consider it failed if any given test
            # takes longer than scipy_test_max_time seconds.
            scipy_test_max_time=3600
            # We skip the test_face test as this require bz2,
            # which may not be installed.
            exit_code_filename="${tmp_dir}/.exit_code_scipy"
            mkdir -p "$(dirname "${exit_code_filename}")"
            rm -f "${exit_code_filename}" || :
            if [ -d "${blas_dir}" ]; then
                export LD_LIBRARY_PATH="${blas_dir}/lib:${LD_LIBRARY_PATH}"
            fi
            ("${python}" -B -c "import scipy; scipy.test('full', \
extra_argv=['-q', '--color=yes', '-k not test_face'])" 2>&1 | tee "test_log"; \
                echo "${PIPESTATUS[0]}" > "${exit_code_filename}") & scipy_test_pid=$!
            soothe ${scipy_test_pid} ${scipy_test_max_time}
            sleep 1
            kill -9 ${scipy_test_pid} >/dev/null 2>&1 || :
            wait    ${scipy_test_pid} >/dev/null 2>&1 || :
            exit_code="$(cat "${exit_code_filename}" 2>/dev/null || :)"
            if [ "${exit_code}" != "0" ]; then
                test_success="False"
            fi
            if tail -n 1 "test_log" | grep " failed" >/dev/null 2>&1; then
                test_success="False"
            fi
            rm -f "${exit_code_filename}" || :
        fi
        if [ "${slim}" == "True" ]; then
            removable_dependencies=( \
                "pybind11"           \
                "pythran"            \
            )
            for dependency in "${removable_dependencies[@]}"; do
                "${python}" -m pip uninstall "${dependency}" -y 2>&1 || :
            done
        fi
    }
    install "SciPy" "no_init_install"                                  \
        setuppy_mode "wheel" "install" "--user"                    ";" \
        scipy_gfortran "True" "False"                              ";" \
        compiler "${compiler_possibilities_specified_mpi_last[@]}" ";" \
        zip_safe "False" ""                                        ";" \
        cstd "-std=c99" ""                                         ";" \
        fcompiler "gnu95" ""                                       ";" \
        extra_FCFLAGS "" "-fPIC"                                   ";" \
        extra_LDFLAGS "" "-shared"                                 ";" \

fi

# Matplotlib (as Matplotlib has a hard time finding FreeType,
# some hacks are needed).
if [ "${matplotlib_install}" == "True" ] && [ "${matplotlib_installed}" == "False" ] \
    && [ "$(check_pypackage_installed matplotlib)" == "False" ]; then
    # Matplotlib depends on other Python packages not directly used by
    # CO𝘕CEPT. If missing, these will automatically be installed when
    # installing Matplotlib. However, as we install Matplotlib from
    # source, these dependencies will only be attempted install from
    # source as well, which may fail without further hacking. We thus
    # install the hard dependencies of Matplotlib now, not including
    # packages which should already have been installed by this script.
    dependencies=(        \
        "cycler"          \
        "fonttools"       \
        "python-dateutil" \
        "kiwisolver"      \
        "packaging"       \
        "pyparsing"       \
    )
    pip_install_pypackage_dependencies "Matplotlib"
    # The pillow packages is missing from the above list of Matplotlib
    # dependencies, as it may require more work to install. The pillow
    # package itself depends on zlib and libjpeg, the latter of which
    # we can explicitly disable. Furthermore, the installation may
    # complain that "ZIP does not support timestamps before 1980",
    # which can be fixed by slightly patching setuptools.
    dependencies=( \
        "pillow"   \
    )
    if [ -n "${zlib_dir}" ] && [ -d "${zlib_dir}" ]; then
        export CPPFLAGS="-I${zlib_dir}/include ${CPPFLAGS}"
        export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"
        export LDFLAGS="-L${zlib_dir}/lib -Wl,-rpath=${zlib_dir}/lib ${LDFLAGS}"
    fi
    pip_install_pypackage_dependencies "Matplotlib" "False"
    reset_environment
    pillow_installed=$(check_pypackage_installed "pillow")
    if [ "${pillow_installed}" == "False" ]; then
        # Default installation of pillow failed
        printf "\nSwitching installation strategy for pillow\n\n"
        # Download pillow
        tmp_pip_dir="${tmp_dir}/pip"
        rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" || :
        mkdir -p "${tmp_pip_dir}_tmp"
        export TMPDIR="${tmp_pip_dir}_tmp"
        export TEMP="${TMPDIR}"
        export TMP="${TMPDIR}"
        pip_download "pillow"
        cd "${tmp_pip_dir}"
        for f in *; do
            f_lower="$(echo "${f}" | tr '[:upper:]' '[:lower:]')"
            if [[ "${f_lower}" == "pillow"* ]]; then
                extract "${f}"* "True"
                break
            fi
        done
        for f in *; do
            f_lower="$(echo "${f}" | tr '[:upper:]' '[:lower:]')"
            if [ -d "${f}" ] && [[ "${f_lower}" == "pillow"* ]]; then
                pillow_build_dir="${tmp_pip_dir}/${f}"
                break
            fi
        done
        cd "${concept_dir}"
        cp -r "${pillow_build_dir}" "${pillow_build_dir}_cp"
        pillow_install_func() {
            if [ -n "${zlib_dir}" ] && [ -d "${zlib_dir}" ]; then
                export CPPFLAGS="-I${zlib_dir}/include ${CPPFLAGS}"
                export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"
                export LDFLAGS="-L${zlib_dir}/lib -Wl,-rpath=${zlib_dir}/lib ${LDFLAGS}"
            fi
            export TMPDIR="${tmp_pip_dir}_tmp"
            export TEMP="${TMPDIR}"
            export TMP="${TMPDIR}"
            cd "${concept_dir}"
            rm -rf "${pillow_build_dir}" || :
            cp -r "${pillow_build_dir}_cp" "${pillow_build_dir}"
            cd "${pillow_build_dir}"
            if [ "${zip_1980_fix}" == "True" ]; then
                bdist_egg_file="$("${python}" -B -c "
import inspect
import setuptools.command.bdist_egg as bdist_egg
print(inspect.getfile(bdist_egg))
" || :)"
                if [ ! -f "${bdist_egg_file}" ]; then
                    return 1
                fi
                cp "${bdist_egg_file}" "${bdist_egg_file}_ori" || return 1
                sed -i                                                             \
                    "s/\(^.*\. *ZipFile\)\(.*\))$/\1\2, strict_timestamps=False)/" \
                    "${bdist_egg_file}"                                            \
                || return 1
            fi
            "${python}" setup.py build_ext --disable-jpeg install ${pyuser} || :
            if [ "${zip_1980_fix}" == "True" ]; then
                cp "${bdist_egg_file}_ori" "${bdist_egg_file}" || :
                rm -f "${bdist_egg_file}_ori" || :
            fi
            if [ "$(check_pypackage_installed pillow)" == "False" ]; then
                return 1
            fi
            # Clean up
            cd "${concept_dir}"
            rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" "${tmp_dir}/pillow" || :
            reset_environment
        }
        install "pillow" "no_init_install"  \
            pyuser "" "--user"          ";" \
            zip_1980_fix "False" "True" ";" \

    fi
    # Install Matplotlib
    current_step="installation of Matplotlib ${matplotlib_version}"
    heading "Installing Matplotlib ${matplotlib_version}"
    set_status "Installing Matplotlib ${matplotlib_version}"
    install_success="False"
    for compiler in "${compiler_possibilities_specified_mpi_last[@]}"; do
        for pyuser in "" "--user"; do
            reset_environment
            "use_${compiler}_compilers" || continue
            printf "
Attempting to install Matplotlib with compiler=${compiler}, pyuser=${pyuser}\n\n"
            # Download Matplotlib
            cd "${concept_dir}"
            tmp_pip_dir="${tmp_dir}/pip"
            rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" || :
            mkdir -p "${tmp_pip_dir}_tmp"
            export TMPDIR="${tmp_pip_dir}_tmp"
            export TEMP="${TMPDIR}"
            export TMP="${TMPDIR}"
            if [ -n "${libpng_dir}" ] && [ -d "${libpng_dir}/lib" ]; then
                # For compatibility with Matplotlib < 3.3
                export LD_LIBRARY_PATH="${libpng_dir}/lib:${LD_LIBRARY_PATH}"
            fi
            if [ -n "${zlib_dir}" ] && [ -d "${zlib_dir}/lib" ]; then
                export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"
            fi
            if [ -n "${blas_dir}" ] && [ -d "${blas_dir}/lib" ]; then
                export LD_LIBRARY_PATH="${blas_dir}/lib:${LD_LIBRARY_PATH}"
            fi
            pip_download "Matplotlib" "${matplotlib_version}"
            # Install Matplotlib
            cd "${tmp_pip_dir}"
            extract "matplotlib"* "True"
            for f in *; do
                f_lower="$(echo "${f}" | tr '[:upper:]' '[:lower:]')"
                if [ -d "${f}" ] && [[ "${f_lower}" == "matplotlib"* ]]; then
                    cd "${f}"
                    break
                fi
            done
            unset MPLSETUPCFG
            for cfg in mplsetup setup; do
                cfg="${cfg}.cfg"
                if [ -f "${cfg}.template" ]; then
                    cp "${cfg}.template" "${cfg}"
                    export MPLSETUPCFG="$(pwd)/${cfg}"
                    break
                fi
            done
            if [ -z "${MPLSETUPCFG}" ]; then
                error "Could not locate *.cfg.template file"
                exit 1
            fi
            freetype_include2="$(echo "${freetype_dir}/include/freetype"* | awk '{print $NF}')"
            basedirlist="${freetype_dir},${freetype_dir}/include,\
${freetype_include2},${freetype_dir}/lib"
            CPPFLAGS_libpng=""
            LDFLAGS_libpng=""
            PATH_libpng=""
            PKG_CONFIG_PATH_libpng=""
            if [ -n "${libpng_dir}" ] && [ -d "${libpng_dir}" ]; then
                # For compatibility with Matplotlib < 3.3
                basedirlist="${basedirlist},${libpng_dir},${libpng_dir}/include,${libpng_dir}/lib"
                CPPFLAGS_libpng="-I${libpng_dir}/include"
                for d in "${libpng_dir}/include/"*; do
                    if [ -d "${d}" ]; then
                        basedirlist="${basedirlist},${d}"
                        CPPFLAGS_libpng="${CPPFLAGS_libpng} -I${d}"
                    fi
                done
                if [ -d "${libpng_dir}/lib" ]; then
                    LDFLAGS_libpng="-L${libpng_dir}/lib -Wl,-rpath=${libpng_dir}/lib"
                fi
                PATH_libpng="${libpng_dir}/bin:"
                PKG_CONFIG_PATH_libpng="${libpng_dir}/lib/pkgconfig:"
            fi
            basedirlist="${basedirlist},${zlib_dir},${zlib_dir}/include,${zlib_dir}/lib"
            sed -i "/basedirlist/c\basedirlist = ${basedirlist}" "${cfg}"
            cp -r "${freetype_include2}/"* "${freetype_dir}/include/"
            export CPPFLAGS="-I${freetype_dir}/include \
                             -I${freetype_include2}    \
                             ${CPPFLAGS_libpng}        \
                             -I${zlib_dir}/include ${CPPFLAGS}"
            export LDFLAGS="-L${freetype_dir}/lib          \
                            -Wl,-rpath=${freetype_dir}/lib \
                            ${LDFLAGS_libpng}              \
                            -L${zlib_dir}/lib              \
                            -Wl,-rpath=${zlib_dir}/lib ${LDFLAGS}"
            export PATH="${freetype_dir}/bin:${PATH_libpng}${PATH}"
            export PKG_CONFIG_PATH="${PKG_CONFIG_PATH_libpng}\
${zlib_dir}/lib/pkgconfig:${PKG_CONFIG_PATH}"
            matplotlib_build_dir="$(pwd)"
            cd "${concept_dir}"
            # As usual, various extra pip arguments may be needed
            for extra_pip_arg in                                      \
                "--no-cache-dir                                     " \
                "--no-cache-dir --no-build-isolation                " \
                "               --no-build-isolation                " \
                "--no-cache-dir                      --no-use-pep517" \
                "--no-cache-dir --no-build-isolation --no-use-pep517" \
                "               --no-build-isolation --no-use-pep517" \
                "                                    --no-use-pep517" \
                "                                                   " \
            ; do
                extra_pip_arg="$(echo ${extra_pip_arg} | awk '{$1=$1};1')"
                # Install Matplotlib
                "${python}" -m pip uninstall "matplotlib" -y >/dev/null 2>&1 || :
                printf "
Attempting to install Matplotlib using pip with extra_pip_arg=${extra_pip_arg}\n\n"
                "${python}" -m pip install        \
                    ${pyuser}                     \
                    -v                            \
                    ${extra_pip_arg}              \
                    --no-index                    \
                    --find-links="${tmp_dir}/pip" \
                    "${matplotlib_build_dir}" 2>&1 & pip_install_pid=$!
                soothe ${pip_install_pid}
                pypackage_installed=$(check_pypackage_installed matplotlib)
                if [ "${pypackage_installed}" == "True" ]; then
                    break
                fi
            done
            if [ "${pypackage_installed}" == "True" ]; then
                install_success="True"
                break
            fi
        done
        if [ "${pypackage_installed}" == "True" ]; then
            install_success="True"
            break
        fi
    done
    reset_environment
    cd "${concept_dir}"
    # Exit if installation failed
    if [ "${install_success}" == "False" ]; then
        error "Could not install Matplotlib"
        exit 1
    fi
    rm -rf "${tmp_pip_dir}" "${tmp_pip_dir}_tmp" || :
fi

# MPI4Py
if [ "${mpi4py_install}" == "True" ] && [ "${mpi4py_installed}" == "False" ] \
    && [ "$(check_pypackage_installed mpi4py)" == "False" ]; then
    install_success="False"
    for compiler in "${compiler_possibilities[@]}"; do
        reset_environment
        "use_${compiler}_compilers" || continue
        printf "
Attempting to install MPI4Py with compiler=${compiler}\n\n"
        export PATH="${mpi_bindir}:${mpi_compilerdir}:${PATH}"
        pip_install_pypackage "MPI4Py" "${mpi4py_version}" || continue
        install_success="True"
        break
    done
    if [ "${install_success}" == "False" ]; then
        error "Failed to install MPI4Py"
        exit 1
    fi
    reset_environment
fi

# H5Py
if [ "${h5py_install}" == "True" ] && [ "${h5py_installed}" == "False" ] \
    && [ "$(check_pypackage_installed h5py)" == "False" ]; then
    install_success="False"
    for compiler in "${compiler_possibilities[@]}"; do
        reset_environment
        "use_${compiler}_compilers" || continue
        printf "
Attempting to install H5Py with compiler=${compiler}\n\n"
        export LD_LIBRARY_PATH="${hdf5_dir}/lib:${LD_LIBRARY_PATH}"
        if [ -d "${blas_dir}/lib" ]; then
            export LD_LIBRARY_PATH="${blas_dir}/lib:${LD_LIBRARY_PATH}"
        fi
        export HDF5_DIR="${hdf5_dir}"
        export HDF5_MPI="ON"
        if [ -n "${mpicc}" ]; then
            export CC="${mpicc}"
        fi
        pip_install_pypackage "H5Py" "${h5py_version}" || continue
        install_success="True"
        break
    done
    if [ "${install_success}" == "False" ]; then
        error "Failed to install H5Py"
        exit 1
    fi
    reset_environment
fi

# Sphinx
sphinx_install_success="True"
if [ "${sphinx_install}" == "True" ] && [ "${sphinx_installed}" == "False" ] \
    && [ "$(check_pypackage_installed sphinx)" == "False" ]; then
    # As Sphinx is not a critical dependency (it is only used for
    # building the documentation), we continue past failure
    # to install it.
    install_success="True"
    pip_install_pypackage "Sphinx" "${sphinx_version}" || install_success="False"
    if [ "${install_success}" == "False" ]; then
        sphinx_install_success="False"
        error "Failed to install Sphinx. The installation will continue regardless."
        sphinx_install="False"  # Flag as not to be installed
    fi
fi

# Sphinx_copybutton
if     [ "${sphinx_copybutton_install}"                   == "True"  ] \
    && [ "${sphinx_copybutton_installed}"                 == "False" ] \
    && [ "${sphinx_install_success}"                      == "True"  ] \
    && [ "$(check_pypackage_installed sphinx_copybutton)" == "False" ]; then
    # As Sphinx_copybutton is not a critical dependency (it is only used
    # for building the documentation), we continue past failure
    # to install it.
    install_success="True"
    pip_install_pypackage "Sphinx_copybutton" "${sphinx_copybutton_version}" \
        || install_success="False"
    if [ "${install_success}" == "False" ]; then
        error "Failed to install Sphinx_copybutton. The installation will continue regardless."
        sphinx_copybutton_install="False"  # Flag as not to be installed
    fi
fi

# sphinx_rtd_theme
if     [ "${sphinx_rtd_theme_install}"                   == "True"  ] \
    && [ "${sphinx_rtd_theme_installed}"                 == "False" ] \
    && [ "${sphinx_install_success}"                     == "True"  ] \
    && [ "$(check_pypackage_installed sphinx_rtd_theme)" == "False" ]; then
    # As sphinx_rtd_theme is not a critical dependency (it is only used
    # for building the documentation), we continue past failure
    # to install it.
    install_success="True"
    pip_install_pypackage "Sphinx_rtd_theme" "${sphinx_rtd_theme_version}" \
        || install_success="False"
    if [ "${install_success}" == "False" ]; then
        error "Failed to install Sphinx_rtd_theme. The installation will continue regardless."
        sphinx_rtd_theme_install="False"  # Flag as not to be installed
    fi
fi

# sphinx_tabs
if     [ "${sphinx_tabs_install}"                   == "True"  ] \
    && [ "${sphinx_tabs_installed}"                 == "False" ] \
    && [ "${sphinx_install_success}"                == "True"  ] \
    && [ "$(check_pypackage_installed sphinx_tabs)" == "False" ]; then
    # As sphinx_tabs is not a critical dependency (it is only used
    # for building the documentation), we continue past failure
    # to install it.
    install_success="True"
    pip_install_pypackage "Sphinx_tabs" "${sphinx_tabs_version}" || install_success="False"
    if [ "${install_success}" == "False" ]; then
        error "Failed to install Sphinx_tabs. The installation will continue regardless."
        sphinx_tabs_install="False"  # Flag as not to be installed
    fi
fi



###################################
# Install the CO𝘕CEPT code itself #
###################################
# Paths used by CO𝘕CEPT
concept="${concept_dir}/concept"
build_dir="${concept_dir}/build"
dep_dir="${concept_dir}/dep"
doc_dir="${concept_dir}/doc"
ic_dir="${concept_dir}/ic"
job_dir="${concept_dir}/job"
output_dir="${concept_dir}/output"
param_dir="${concept_dir}/param"
reusable_dir="${concept_dir}/.reusable"
src_dir="${concept_dir}/src"
test_dir="${concept_dir}/test"
util_dir="${concept_dir}/util"
Gadget2_dir="${gadget_dir}/Gadget2"
install="${concept_dir}/install"
mpiexec="${mpi_bindir}/mpiexec"
# Move source files, create empty directories and create the .path file
if [ "${concept_install}" == "True" ] && [ "${concept_installed}" == "False" ]; then
    init_install "CONCEPT"
    # Move everything from the concept-${concept_version}
    # directory to ${concept_dir}.
    if [ -f "${concept_dir}/install" ]; then
        # An installation script already exists in the directory where
        # the downloaded installation script for the installed CO𝘕CEPT
        # version should go. This pre-existing installation script might
        # be the very file running now, and so it is not safe to
        # overwrite it. Instead, move the new installation script there
        # under a new name, reflecting its version.
        rm -f "${concept_dir}/install_${concept_version//\//_}" || :
        mv "install" "${concept_dir}/install_${concept_version//\//_}" || :
    fi
    for f in {.[!.],}*; do
        rm -rf "${concept_dir}/${f}" || :
        mv "${f}" "${concept_dir}/"
    done
    cd "${concept_dir}"
    rm -rf "${tmp_dir}/concept" || :
    # Though empty, create the sub-directory for initial conditions
    mkdir -p "${ic_dir}"
    # Add PATH-like and a few PYTHON environment variables present at
    # install time (now) to the .env file.
    current_step="setup of the .env file"
    printf "\nSetting up the .env file\n"
    set_status "Setting up the .env file"
    "${python}" -B -c "
import os
with open('${env}', 'r', encoding='utf-8') as file:
    lines = file.readlines()
# Generator for extracting environment variables
def get_envs():
    for var, val in os.environ.items():
        if (
            # PATH, LD_LIBRARY_PATH, ...
            ('path' in var.lower() and (val.startswith('/') or val.startswith(':')))
            # MPI root directories
            or (var in {'MPI_ROOT', 'I_MPI_ROOT', 'IMPI_ROOT', 'SMPI_ROOT'}
                and val.startswith('/')
            )
            # Other MPI related variables
            or any([
                var.startswith(prefix + '_')
                for prefix in ['MPI', 'OMPI', 'MV2', 'IMPI', 'I_MPI', 'SMPI', 'PAMI', 'PMIX']
            ])
            # Intel license file
            or (var in {'INTEL_LICENSE_FILE', 'INTEL_LICENCE_FILE'} and val.startswith('/'))
        ):
            yield var, val
# Add environment variables
envs_inserted = False
with open('${env}', 'w', encoding='utf-8') as file:
    for line in lines:
        if not envs_inserted and r'pathenv_name_value_pairs_installtime=()' in line:
            if '${python_install}' == 'True':
                print('unset PYTHONPATH', file=file)
                print('unset PYTHONHOME', file=file)
                print('export PYTHONNOUSERSITE=\"True\"', file=file)
            print('pathenv_name_value_pairs_installtime=( \\\\', file=file)
            for var, val in get_envs():
                print(f'    {var} \"{val}\" \\\\', file=file)
            print(')', file=file)
            envs_inserted = True
        else:
            print(line, end='', file=file)
"
    # If MPI was installed as part of this installation process, it is
    # not set up to function with e.g. Slurm, and so we set the
    # MPI executor to mpiexec explicitly. This should work even when
    # running on multiple nodes, though the network performance will
    # most likely be bad. We further add some arguments to mpiexec
    # depending on the MPI distribution and version.
    if [ "${mpi_preinstalled}" == "False" ]; then
        use_specified_mpi_compilers
        mpiexec_args=""
        if [ "${mpi}" == "mpich" ]; then
            # Though MPICH should not use process binding by default,
            # it still supports a -bind-to none or --bind-to none
            # option. Here we check if this is so, and apply it.
            mpiexec_output="$("${mpiexec}" -bind-to none -n 1 echo "success" 2>&1 || :)"
            if [ "${mpiexec_output}" == "success" ]; then
                mpiexec_args="${mpiexec_args} -bind-to none"
            else
                mpiexec_output="$("${mpiexec}" --bind-to none -n 1 echo "success" 2>&1 || :)"
                if [ "${mpiexec_output}" == "success" ]; then
                    mpiexec_args="${mpiexec_args} --bind-to none"
                fi
            fi
        elif [ "${mpi}" == "openmpi" ]; then
            # Disable automatic process binding/affinity, allowing
            # OpenMP threads to be assigned to cores in a one-to-one
            # fashion. This is off by default prior to OpenMPI version
            # 1.7. All of 1.7 -- 4.0 supports the --bind-to none option
            # to mpiexec. Here we add this option if it is understood.
            mpiexec_output="$("${mpiexec}" --bind-to none -n 1 echo "success" 2>&1 || :)"
            if [ "${mpiexec_output}" == "success" ]; then
                mpiexec_args="${mpiexec_args} --bind-to none"
            fi
        fi
        sed -i "s/mpi_executor=\"\"/mpi_executor=\"mpiexec${mpiexec_args}\"/" "${env}" || :
        reset_environment
    fi
    # If the make_jobs variable is set by the user,
    # store this in the .env file.
    if [ -n "${make_jobs}" ] && [ "${make_jobs_set_by_user}" == "True" ]; then
        sed -i "s/make_jobs=\"\"/make_jobs=\"${make_jobs}\"/" "${env}" || :
    fi
    # Create the .path file,
    # storing important paths used by CO𝘕CEPT.
    current_step="creation of the .path file"
    printf "\nWriting paths to the .path file\n"
    set_status "Writing paths to the .path file"
    echo "# This file contains absolute paths to directories and files
# used by the CO𝘕CEPT code. You may manually edit these paths.


#######################
# CO𝘕CEPT directories #
#######################
# Top-level directory of the CO𝘕CEPT installation
concept_dir='${concept_dir}'
# Default build directory
build_dir='${build_dir}'
# Directory containing installed dependency programs
dep_dir='${dep_dir}'
# Directory containing documentation
doc_dir='${doc_dir}'
# Directory intended for initial conditions
ic_dir='${ic_dir}'
# Directory containing information for each job
job_dir='${job_dir}'
# Directory intended for output
output_dir='${output_dir}'
# Directory intended for parameter files
param_dir='${param_dir}'
# Directory containing reusable dumps
reusable_dir='${reusable_dir}'
# Directory containing source code
src_dir='${src_dir}'
# Directory containing tests
test_dir='${test_dir}'
# Directory used for temporary files
tmp_dir='${tmp_dir}'
# Directory containing utilities
util_dir='${util_dir}'


##########################
# Dependency directories #
##########################
# Directory of BLAS
blas_dir='${blas_dir}'
# Directory of CLASS
class_dir='${class_dir}'
# Directory of FFTW
fftw_dir='${fftw_dir}'
# Directory of FFTW2, used by GADGET
fftw_for_gadget_dir='${fftw_for_gadget_dir}'
# Directory of GADGET2
gadget_dir='${gadget_dir}'
# Directory containing the GADGET2 source code
Gadget2_dir='${Gadget2_dir}'
# Directory of GSL
gsl_dir='${gsl_dir}'
# Directory of HDF5
hdf5_dir='${hdf5_dir}'
# Directories of MPI
mpi_dir='${mpi_dir}'
mpi_compilerdir='${mpi_compilerdir}'
mpi_bindir='${mpi_bindir}'
mpi_libdir='${mpi_libdir}'
mpi_includedir='${mpi_includedir}'
mpi_symlinkdir='${mpi_symlinkdir}'
# Directory of Python
python_dir='${python_dir}'
# Directory of zlib
zlib_dir='${zlib_dir}'


#########
# Files #
#########
# The executable script of the CO𝘕CEPT code
concept='${concept}'
# The file containing environment variables
env='${env}'
# The install script
install='${install}'
# The MPI C compiler
mpicc='${mpicc}'
# The MPI executable
mpiexec='${mpiexec}'
# The file containing paths (this file)
path='${path}'
# The Python interpreter
python='${python}'
" > "${path}"
    # CO𝘕CEPT will be tested later
fi
# The concept_print function, used later for extracting values
# from the CO𝘕CEPT code.
concept_works="False"
if [ -f "${concept}" ]; then
    # Test whether CO𝘕CEPT is able to run
    concept_print() {
        local expression="$1"
        local current_dir="$(pwd)"
        if [ -n "${concept_dir}" ] && [ -d "${concept_dir}" ]; then
            cd "${concept_dir}"
        fi
        "${concept}" -m "
from commons import *
sys.stdout.flush()
sleep(0.1)
print(correct_float(${expression}))
" --pure-python --local 2>/dev/null | tail -n 1
        cd "${current_dir}"
    }
    result="$(concept_print "π")"
    if [[ "${result}" == "3.14"* ]]; then
        concept_works="True"
    else
        # CO𝘕CEPT was not able to run.
        # Print out error but do not exit.
        error "${esc_concept} was not able to run, or it produced incorrect results"
    fi
fi



###########################
# Install and patch CLASS #
###########################
if [ "${class_install}" == "True" ] && [ "${class_installed}" == "False" ]; then
    init_install "CLASS"
    # Move the content of the current directory (the files of CLASS,
    # except .gitignore) to the CLASS installation directory.
    mkdir -p "${class_dir}"
    mv ./* "${class_dir}/"
    cd "${class_dir}"
    # Below we will do a lot of patching on the CLASS source code.
    # To aid us, we define the following function.
    patch_class() {
        filename="$1"
        local linenr="$2"
        action="$3"
        belonging="$4"
        new_lines="$5"
        wrap_in_comments="$6"
        # Determine file type ("c" or "python")
        extension="${filename##*.}"
        filetype=""
        if     [ "${extension}" == "c"   ] \
            || [ "${extension}" == "h"   ] \
            || [ "${extension}" == "cpp" ]; then
            filetype="c"
        elif   [ "${extension}" == "py"  ] \
            || [ "${extension}" == "pyx" ] \
            || [ "${extension}" == "pxd" ]; then
            filetype="python"
        fi
        # Add comments around inserted lines
        if [ "${wrap_in_comments}" != "False" ]; then
            if [ "${filetype}" == "c" ]; then
                new_lines=(""                      \
                    "/************************/"   \
                    "/* For use with CONCEPT */"   \
                    "/************************/"   \
                    "${new_lines[@]}"              \
                    "/**************************/" \
                    "/* ^For use with CONCEPT^ */" \
                    "/**************************/" \
                    ""                             \
                )
            elif [ "${filetype}" == "python" ]; then
                new_lines=(""                    \
                    "########################"   \
                    "# For use with CONCEPT #"   \
                    "########################"   \
                    "${new_lines[@]}"            \
                    "##########################" \
                    "# ^For use with CONCEPT^ #" \
                    "##########################" \
                    ""                           \
                )
            fi
        fi
        # Find indentation at linenr
        indentation=""
        if [ "${belonging}" == "below" ]; then
            n_lines=$(wc -l "${filename}" | awk '{print $1}')
            ((n_lines_down = n_lines - linenr + 1))
            content="$(tail -n ${n_lines_down} "${filename}")"
        elif [ "${belonging}" == "above" ]; then
            ((n_lines_down = linenr - 1))
            content="$(head -n ${n_lines_down} "${filename}" | tac)"
        fi
        local IFS=''
        while read -r line; do
            if [ -n "${line// }" ]; then
                line_unindented="$(echo "${line}" | awk '{gsub(/^ +/,"")} {print $0}')"
                ((indentation_size = ${#line} - ${#line_unindented})) || :
                if [ "${filetype}" == "c" ] && [ "${line_unindented:0:1}" == "}" ]; then
                    ((indentation_size += 2))
                fi
                indentation="$(printf "%${indentation_size}s")"
                break
            fi
        done <<< "${content}"
        # Construct string of indented lines from the new_lines array
        new_line_nr=0
        for new_line in "${new_lines[@]}"; do
            if [ -n "${new_line}" ]; then
                indentation_use="${indentation}"
            else
                indentation_use=""
            fi
            if [ ${new_line_nr} -eq 0 ]; then
                new_lines_str="${indentation_use}${new_line}"
                if [[ "${new_lines_str}" == " "* ]] || [[ "${new_lines_str}" == "\\n"* ]]; then
                    new_lines_str="\\${new_lines_str}"
                fi
            else
                if [ -n "${new_lines_str}" ]; then
                    new_lines_str="${new_lines_str}\\n${indentation_use}${new_line}"
                else
                    new_lines_str="\\\\n${indentation_use}${new_line}"
                fi
            fi
            ((new_line_nr += 1))
        done
        # Insert the new lines in the file
        if [ "${action}" == "insert" ]; then
            sed -i "${linenr}i${new_lines_str}" "${filename}"
        elif [ "${action}" == "replace" ]; then
            sed -i "${linenr}d" "${filename}"
            sed -i "${linenr}i${new_lines_str}" "${filename}"
        fi
    }
    # Change the values of some preprocessing directives
    # in header files, allowing larger inputs and outputs.
    # Careful though, as values too large will not fit on the stack.
    redefine_class() {
        filename="$1"
        name="$2"
        value="$3"
        sed -i "s/^\(\s*#define\s\+${name}\s\+\)\(\S*\)\(.*\)$/\1${value}\3/" "${filename}"
    }
    redefine_class "${class_dir}/include/common.h"        _MAXTITLESTRINGLENGTH_   100000  # 10⁵
    redefine_class "${class_dir}/include/parser.h"        _LINE_LENGTH_MAX_         10000  # 10⁴
    redefine_class "${class_dir}/include/parser.h"        _ARGUMENT_LENGTH_MAX_     10000  # 10⁴
    redefine_class "${class_dir}/include/perturbations.h" _MAX_NUMBER_OF_K_FILES_  100000  # 10⁵
    # As only the (relatively) late-time evolution is needed from CLASS,
    # we hard-code the perturbations output to only be printed here.
    a_min="3e-4"
    pattern=' +a *= *pvecback'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    ((linenr += 1))
    new_lines=(                                  \
        "/* Only return output at late times */" \
        "double a_min = ${a_min};"               \
        "if (a < a_min)"                         \
        "  return _SUCCESS_;"                    \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    # When using the Runge-Kutta evolver, the derivatives are only
    # computed at the beginning of each time step, which is not
    # necessarily precise enough. Here we remove the derivative
    # computation in tools/evolver_rkck.c entirely and place it
    # in the perturb_print_variables function of
    # source/perturbations.c instead. This also ensures that
    # e.g. the ppw struct has been updated correctly
    # when it is time to print the perturbation results.
    pattern='( *x1 *== *x_ini *)'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/tools/evolver_rkck.c" | head -n 1)
    new_lines=(                                          \
        "/* derivs will be called in print_variables */" \
        "if (0 == 1) {  /* (x1 == x_ini) { */"           \
    )
    patch_class "${class_dir}/tools/evolver_rkck.c" ${linenr} "replace" "below" "${new_lines[@]}"
    pattern='double *\\* *dataptr *;'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    ((linenr += 1))
    new_lines=(                                                                  \
        "/**"                                                                    \
        " * Compute perturbation derivatives. This also ensures that the"        \
        " * ppw (and other) structs are up-to-date. This is important"           \
        " * when using the Runge-Kutta evolver, as this is otherwise"            \
        " * not taken care off correctly."                                       \
        " */"                                                                    \
        "class_call("                                                            \
        "  perturb_derivs(tau, y, dy, parameters_and_workspace, error_message)," \
        "  error_message,"                                                       \
        "  error_message);"                                                      \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    # Include ncdm Psi0[q] in perturbation output
    include_ncdm_Psi0="False"
    if [ "${include_ncdm_Psi0}" == "True" ]; then
        pattern=' *char +tmp *\\[ *40 *\\] *;'
        linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
            "${class_dir}/source/perturbations.c" | head -n 1)
        new_lines=(           \
            "char tmp[1024];" \
            "int index_q;"    \
        )
        patch_class "${class_dir}/source/perturbations.c" ${linenr} \
            "replace" "below" "${new_lines[@]}"
        pattern='sprintf *\\( *tmp *, *\"cs2_ncdm\\[%d\\]\" *, *n_ncdm *\\) *;'
        linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
            "${class_dir}/source/perturbations.c" | head -n 1)
        ((linenr += 2))
        new_lines=(                                                                   \
            "/* Include ncdm Psi0[q] in perturbation output */"                       \
            "for (index_q=0; index_q<pba->q_size_ncdm[n_ncdm]; index_q++) {"          \
            "  sprintf(tmp,\"Psi0[%d](%.16f)\",n_ncdm,pba->q_ncdm[n_ncdm][index_q]);" \
            "  class_store_columntitle(ppt->scalar_titles,tmp,_TRUE_);"               \
            "}"                                                                       \
        )
        patch_class "${class_dir}/source/perturbations.c" ${linenr} \
            "insert" "below" "${new_lines[@]}"
        pattern="class_store_double *\\\\( *dataptr *, \
*delta_p_over_delta_rho_ncdm *\\\\[ *n_ncdm *\\\\] *,"
        linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
            "${class_dir}/source/perturbations.c" | head -n 1)
        ((linenr += 1))
        new_lines=(                                                            \
            "/* Include ncdm Psi0[q] in perturbation output */"                \
            "if (ppw->approx[ppw->index_ap_ncdmfa] == (int)ncdmfa_on) {"       \
            "  for (index_q=0; index_q<pba->q_size_ncdm[n_ncdm]; index_q++) {" \
            "    class_store_double(dataptr, 0.0, _TRUE_, storeidx);"          \
            "  }"                                                              \
            "}"                                                                \
            "else {"                                                           \
            "  idx = ppw->pv->index_pt_psi0_ncdm1;"                            \
            "  for (index_q=0; index_q<pba->q_size_ncdm[n_ncdm]; index_q++) {" \
            "    class_store_double(dataptr, y[idx], _TRUE_, storeidx);"       \
            "    /* Jump to next momentum bin */"                              \
            "    idx += (ppw->pv->l_max_ncdm[n_ncdm]+1);"                      \
            "  }"                                                              \
            "}"                                                                \
        )
        patch_class "${class_dir}/source/perturbations.c" ${linenr} \
            "insert" "below" "${new_lines[@]}"
    fi
    # Correctly implement the fld pressure perturbation,
    # both with and without PPF.
    pattern='double *rho_plus_p_theta_fld *;'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/include/perturbations.h" | head -n 1)
    ((linenr += 1))
    new_lines=(                                                                               \
"double delta_p_fld;  /**< pressure perturbation of fluid, very non-trivial in PPF scheme */" \
    )
    patch_class "${class_dir}/include/perturbations.h" ${linenr} \
        "insert" "above" "${new_lines[@]}"
    pattern='/\\* *fluid *contribution *\\*/'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    ((linenr += 1))
    new_lines=(                                                                                  \
        "/**"                                                                                    \
        " * Count up total pressure and conformal time derivative of pressure,"                  \
        " * excluding the fld species. These are used for the PPF formalism of fld."             \
        " */"                                                                                    \
        "double p_tot = 0.;"                                                                     \
        "double p_tot_prime = 0.;"                                                               \
        "if (pba->has_fld == _TRUE_ && pba->use_ppf == _TRUE_) {"                                \
        "  /* Photons */"                                                                        \
        "  p_tot += 1./3.*ppw->pvecback[pba->index_bg_rho_g];"                                   \
        "  p_tot_prime += -3.*a_prime_over_a*(1. + 1./3.)*1./3."                                 \
        "    *ppw->pvecback[pba->index_bg_rho_g];"                                               \
        "  /* Baryons have no pressure */"                                                       \
        "  /* Ultra relativistic species */"                                                     \
        "  if (pba->has_ur == _TRUE_) {"                                                         \
        "    p_tot += 1./3.*ppw->pvecback[pba->index_bg_rho_ur];"                                \
        "    p_tot_prime += -3.*a_prime_over_a*(1. + 1./3.)*1./3."                               \
        "      *ppw->pvecback[pba->index_bg_rho_ur];"                                            \
        "  }"                                                                                    \
        "  /* Cold dark matter has no pressure */"                                               \
        "  /* Non-cold dark matter */"                                                           \
        "  if (pba->has_ncdm == _TRUE_) {"                                                       \
        "    for(n_ncdm = 0; n_ncdm < pba->N_ncdm; n_ncdm++) {"                                  \
        "      p_tot += ppw->pvecback[pba->index_bg_p_ncdm1 + n_ncdm];"                          \
        "      p_tot_prime += -a_prime_over_a*(5.*ppw->pvecback[pba->index_bg_p_ncdm1 + n_ncdm]" \
        "        - ppw->pvecback[pba->index_bg_pseudo_p_ncdm1 + n_ncdm]);"                       \
        "    }"                                                                                  \
        "  }"                                                                                    \
        "  /* Decaying cold dark matter has no pressure */"                                      \
        "  /* Decay radiation */"                                                                \
        "  if (pba->has_dr == _TRUE_) {"                                                         \
        "    p_tot += 1./3.*ppw->pvecback[pba->index_bg_rho_dr];"                                \
        "    p_tot_prime += -3.*a_prime_over_a*(1. + 1./3.)*1./3."                               \
        "      *ppw->pvecback[pba->index_bg_rho_dr]"                                             \
        "      + 1./3.*a*pba->Gamma_dcdm*ppw->pvecback[pba->index_bg_rho_dcdm];"                 \
        "  }"                                                                                    \
        "  /* Importantly, we skip the dark energy fluid */"                                     \
        "  /* Scalar field */"                                                                   \
        "  if (pba->has_scf == _TRUE_) {"                                                        \
        "    p_tot += ppw->pvecback[pba->index_bg_p_scf];"                                       \
        "    p_tot_prime += -a_prime_over_a/(a*a)*ppw->pvecback[pba->index_bg_phi_prime_scf]"    \
        "      *ppw->pvecback[pba->index_bg_phi_prime_scf]"                                      \
        "      - 2./3.*ppw->pvecback[pba->index_bg_dV_scf]"                                      \
        "        *ppw->pvecback[pba->index_bg_phi_prime_scf];"                                   \
        "  }"                                                                                    \
        "  /* Lambda has constant pressure */"                                                   \
        "}"                                                                                      \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} \
        "insert" "above" "${new_lines[@]}"
    for n in $(grep -n 'class_call *( *background_w_fld *(' "${class_dir}/source/perturbations.c" \
        | awk '{print $1}'); do
        n="${n//:}"
        if [ ${n} -gt ${linenr} ]; then
            ((linenr = n + 1))
            new_lines=(                                                 \
                "double w_prime_fld = dw_over_da_fld*a_prime_over_a*a;" \
            )
            patch_class "${class_dir}/source/perturbations.c" ${linenr} \
                "insert" "above" "${new_lines[@]}"
            break
        fi
    done
    for n in $(grep -n 'ppw *-> *rho_plus_p_theta_fld *=' "${class_dir}/source/perturbations.c" \
        | awk '{print $1}'); do
        n="${n//:}"
        if [ ${n} -gt ${linenr} ]; then
            ((linenr = n + 1))
            new_lines=(                                                                          \
                "/* Pressure perturbation of fld without PPF */"                                 \
                "double ca2_fld = w_fld - w_prime_fld/(3.*a_prime_over_a*(1. + w_fld));"         \
                "ppw->delta_p_fld = pba->cs2_fld*ppw->delta_rho_fld"                             \
                "  + (pba->cs2_fld - ca2_fld)*(3.*a_prime_over_a*ppw->rho_plus_p_theta_fld/k2);" \
            )
            patch_class "${class_dir}/source/perturbations.c" ${linenr} \
                "insert" "above" "${new_lines[@]}"
            break
        fi
    done
    pattern='s2sq *= ppw *->'
    linenr_1=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    ((linenr_1 += 1))
    pattern='ppw *-> *S_fld *='
    linenr_2=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    ((linenr_2 -= 1))
    sed -i "${linenr_1},${linenr_2}d" "${class_dir}/source/perturbations.c"
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    new_lines=(                                                                                  \
        "double alpha_prime, X, Y, Z, X_prime, Y_prime, Z_prime;"                                \
        "double rho_plus_p_theta_fld_prime, metric_euler;"                                       \
        "double rho_t, rho_t_prime, p_t, p_t_prime, rho_fld, rho_fld_prime, p_fld, p_fld_prime;" \
        "double H, H_prime;"                                                                     \
        "double theta_t,theta_t_prime, S, S_prime;"                                              \
        "if (ppt->gauge == synchronous) {"                                                       \
        "  alpha = (y[ppw->pv->index_pt_eta] + 1.5*a2/k2/s2sq*(ppw->delta_rho"                   \
        "    + 3.*a_prime_over_a/k2*ppw->rho_plus_p_theta)"                                      \
        "    - y[ppw->pv->index_pt_Gamma_fld])/a_prime_over_a;"                                  \
        "  alpha_prime = -2.*a_prime_over_a*alpha + y[ppw->pv->index_pt_eta]"                    \
        "    - 4.5*(a2/k2)*ppw->rho_plus_p_shear;"                                               \
        "  metric_euler = 0.;"                                                                   \
        "} else {"                                                                               \
        "  alpha = 0.;"                                                                          \
        "  alpha_prime = 0.;"                                                                    \
        "  metric_euler = k2*y[ppw->pv->index_pt_phi] - 4.5*a2*ppw->rho_plus_p_shear;"           \
        "}"                                                                                      \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} \
        "insert" "above" "${new_lines[@]}"
    pattern='ppw->delta_rho_fld *='
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | tail -n 1)
    ((linenr += 1))
    new_lines=(                                                                                 \
        "rho_t = rho_plus_p_tot - p_tot;"                                                       \
        "p_t = p_tot;"                                                                          \
        "rho_t_prime = -3.*a_prime_over_a*(rho_t + p_t);"                                       \
        "p_t_prime = p_tot_prime;"                                                              \
        "rho_fld = ppw->pvecback[pba->index_bg_rho_fld];"                                       \
        "p_fld = w_fld*rho_fld;"                                                                \
        "rho_fld_prime = -3.*a_prime_over_a*(rho_fld + p_fld);"                                 \
        "p_fld_prime = w_prime_fld*rho_fld - 3.*a_prime_over_a*(1. + w_fld)*p_fld;"             \
        ""                                                                                      \
        "H = ppw->pvecback[pba->index_bg_H];"                                                   \
        "H_prime = ppw->pvecback[pba->index_bg_H_prime];"                                       \
        "X = c_gamma_k_H_square;"                                                               \
        "X_prime = -2.*X*(a_prime_over_a + H_prime/H);"                                         \
        "Y = 4.5*a2/k2/s2sq*(rho_t + p_t);"                                                     \
        "Y_prime = Y*(2.*a_prime_over_a + (rho_t_prime + p_t_prime)/(rho_t + p_t));"            \
        "Z = 2./3.*k2*H/a;"                                                                     \
        "Z_prime = Z*(H_prime/H - a_prime_over_a);"                                             \
        ""                                                                                      \
        "theta_t = ppw->rho_plus_p_theta/rho_plus_p_tot;"                                       \
        "theta_t_prime = -a_prime_over_a*theta_t + (-p_t_prime*theta_t + k2*ppw->delta_p"       \
        "  - k2*ppw->rho_plus_p_shear)/rho_plus_p_tot+metric_euler;"                            \
        ""                                                                                      \
        "S = ppw->S_fld;"                                                                       \
        "S_prime = -Z_prime/Z*S + 1./Z*(rho_fld_prime + p_fld_prime)*(theta_t + k2*alpha)"      \
        "  + 1./Z*(rho_fld + p_fld)*(theta_t_prime + k2*alpha_prime);"                          \
        "rho_plus_p_theta_fld_prime = Z_prime*(S - 1./(1. + Y)*(S/(1. + 1./X)"                  \
        "  + y[ppw->pv->index_pt_Gamma_fld]*X))"                                                \
        "  + Z*(S_prime + Y_prime/(1. + Y*Y + 2.*Y)*(S/(1. + 1./X)"                             \
        "    + y[ppw->pv->index_pt_Gamma_fld]*X)"                                               \
        "    - 1./(1. + Y)*(S_prime/(1. + 1./X) + S*X_prime/(1. + X*X + 2.*X)"                  \
        "      + ppw->Gamma_prime_fld*X + y[ppw->pv->index_pt_Gamma_fld]*X_prime))"             \
        "  - k2*alpha_prime*(rho_fld + p_fld) - k2*alpha*(rho_fld_prime + p_fld_prime);"        \
        ""                                                                                      \
        "ppw->delta_p_fld = (rho_plus_p_theta_fld_prime"                                        \
        "  + 4.*a_prime_over_a*ppw->rho_plus_p_theta_fld - (rho_fld + p_fld)*metric_euler)/k2;" \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} \
        "insert" "above" "${new_lines[@]}"
    pattern='ppw *-> *delta_p *\\+= *pba *-> *cs2_fld *\\* *ppw *-> *delta_rho_fld *;'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    new_lines=(                             \
        "ppw->delta_p += ppw->delta_p_fld;" \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} \
        "replace" "above" "${new_lines[@]}"
    # For the PPF scheme, include a maximum value for (c_Γ*k*a/H)² above
    # which Γ = Γ' = 0, for the sake of numerical stability. In CAMB
    # such a maximum value is present as well and is set to 30. I have
    # found that a value of 10³ or even 10⁴ ensures stability as well,
    # while perturbing the fld δ_fld, θ_fld and δp_fld solutions
    # significantly less. Instead of a discontinuities cutoff as
    # in CAMB, we implement a smooth transition to zero, as defects in
    # δ_fld, θ_fld and δp_fld have been observed otherwise.
    pattern='c_gamma_k_H_square *='
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    sed -i "${linenr}d" "${class_dir}/source/perturbations.c"
    pattern='s2sq *= ppw *->'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    ((linenr += 1))
    new_lines=(                                                                                   \
        "/**"                                                                                     \
        " * The computation of Gamma_fld and Gamma_prime_fld becomes unstable"                    \
        " * at large c_Gamma*k/H. To stabilise the system we set these to zero"                   \
        " * at some large c_Gamma*k/(aH)."                                                        \
        " * As to not introduce discontinuities, we have a smooth transition"                     \
        " * phase between the untouched values and completely nullified values."                  \
        " * This transition is given the shape of an error function in"                           \
        " * log(c_Gamma*k/(aH)) space. The parameters c_gamma_k_H_square_max_{0|1}"               \
        " * specify the borders of the transition."                                               \
        " * Here we nullify/shrink Gamma_fld only."                                               \
        " */"                                                                                     \
        "double Gamma_fld, Gamma_weight, Gamma_weight_steepness;"                                 \
        "double c_gamma_k_H_square_max_0, c_gamma_k_H_square_max_1;"                              \
        "c_gamma_k_H_square_max_0 = 1e+3;"                                                        \
        "c_gamma_k_H_square_max_1 = 1e+4;"                                                        \
        "c_gamma_k_H_square = pow(pba->c_gamma_over_c_fld*k/a_prime_over_a, 2)*pba->cs2_fld;"     \
        "if (c_gamma_k_H_square > c_gamma_k_H_square_max_1){"                                     \
        "    Gamma_fld = 0.;"                                                                     \
        "} else {"                                                                                \
        "  Gamma_fld = y[ppw->pv->index_pt_Gamma_fld];"                                           \
        "  if (c_gamma_k_H_square > c_gamma_k_H_square_max_0){"                                   \
        "    Gamma_weight_steepness = 5.; /* 5 results in double precision perfect transition */" \
        "    Gamma_weight = 0.5*(erf(Gamma_weight_steepness*("                                    \
        "      0.5*(log(c_gamma_k_H_square_max_0) + log(c_gamma_k_H_square_max_1))"               \
        "      - log(c_gamma_k_H_square)"                                                         \
        "    )) + 1.);"                                                                           \
        "    Gamma_fld *= Gamma_weight;"                                                          \
        "  }"                                                                                     \
        "}"                                                                                       \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} \
        "insert" "above" "${new_lines[@]}"
    pattern='double *alpha_prime *, *X *, *Y *, *Z'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    replacements_todo=7
    replacements=0
    for n in $(grep -n 'y *\[ *ppw *-> *pv *-> *index_pt_Gamma_fld *\]' \
        "${class_dir}/source/perturbations.c" | awk '{print $1}'); do
        n="${n//:}"
        if [ ${n} -ge ${linenr} ]; then
            sed -i "${n}s/y *\[ *ppw *-> *pv *-> *index_pt_Gamma_fld *\]/Gamma_fld/" \
                "${class_dir}/source/perturbations.c"
            ((replacements += 1))
            if [ ${replacements} -eq ${replacements_todo} ]; then
                break
            fi
        fi
    done
    pattern='ppw->Gamma_prime_fld *='
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    new_lines=(                                                                         \
        "/* Nullify/shrink Gamma_prime_fld as done for Gamma_fld above */"              \
        "if (c_gamma_k_H_square > c_gamma_k_H_square_max_1){"                           \
        "    ppw->Gamma_prime_fld = 0.;"                                                \
        "} else {"                                                                      \
        "  ppw->Gamma_prime_fld = a_prime_over_a*(ppw->S_fld/(1. + c_gamma_k_H_square)" \
        "    - (1. + c_gamma_k_H_square)*Gamma_fld);"                                   \
        "  if (c_gamma_k_H_square > c_gamma_k_H_square_max_0){"                         \
        "      ppw->Gamma_prime_fld *= Gamma_weight;"                                   \
        "  }"                                                                           \
        "}"                                                                             \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} \
        "replace" "above" "${new_lines[@]}"
    # Include fld in perturbation output
    new_class_perturbation_linenr() {
        if [ "${1}" == "perturb_prepare_output" ]; then
            pattern='ppt *-> *number_of_scalar_titles *='
            linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
                "${class_dir}/source/perturbations.c" | head -n 1)
            ((linenr -= 1))
        elif [ "${1}" == "perturb_print_variables" ]; then
            pattern="class_store_double *\\\\( *dataptr *, *theta_scf *, *pba *-> *has_scf *, \
*storeidx *\\\\)*;"
            linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
                "${class_dir}/source/perturbations.c" | head -n 1)
            n_lines_total=$(wc -l "${class_dir}/source/perturbations.c" | awk '{print $1}')
            ((n_lines_down = n_lines_total - linenr))
            local IFS=''
            while read -r line; do
                ((linenr += 1))
                if [[ "${line}" == "  }" ]]; then
                    break
                fi
            done <<< "$(tail -n ${n_lines_down} "${class_dir}/source/perturbations.c")"
        fi
        echo ${linenr}
    }
    linenr=$(new_class_perturbation_linenr "perturb_prepare_output")
    new_lines=(                                                                       \
        "/* Include fld in perturbation output */"                                    \
        "class_store_columntitle(ppt->scalar_titles, \"delta_fld\", pba->has_fld);"   \
        "class_store_columntitle(ppt->scalar_titles, \"theta_fld\", pba->has_fld);"   \
        "/**"                                                                         \
        " * We choose to store cs2_fld = delta_p_fld/delta_rho_fld rather than"       \
        " * simply delta_p_fld itself, as is done for massive neutrinos."             \
        " */"                                                                         \
        "class_store_columntitle(ppt->scalar_titles, \"cs2_fld\", pba->has_fld);"     \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    linenr=$(new_class_perturbation_linenr "perturb_print_variables")
    new_lines=(                                                                             \
        "/* Include fld in perturbation output */"                                          \
        "double w_fld, dw_over_da_fld, integral_fld, theta_fld;"                            \
        "if (pba->has_fld) {"                                                               \
        "  class_call(background_w_fld(pba, a, &w_fld, &dw_over_da_fld, &integral_fld),"    \
        "    pba->error_message, ppt->error_message);"                                      \
        "  class_store_double(dataptr, ppw->delta_rho_fld/pvecback[pba->index_bg_rho_fld]," \
        "    pba->has_fld, storeidx);"                                                      \
        "  /* For w_fld = -1 (Lambda), we have theta = 0 */"                                \
        "  if (w_fld == -1.) {"                                                             \
        "    theta_fld = 0.;"                                                               \
        "  }"                                                                               \
        "  else {"                                                                          \
        "    theta_fld = ppw->rho_plus_p_theta_fld/"                                        \
        "      ((1. + w_fld)*pvecback[pba->index_bg_rho_fld]);"                             \
        "  }"                                                                               \
        "  class_store_double(dataptr, theta_fld, pba->has_fld, storeidx);"                 \
        "  /**"                                                                             \
        "   * We choose to store cs2_fld = delta_p_fld/delta_rho_fld rather than"           \
        "   * simply delta_p_fld itself, as is done for massive neutrinos."                 \
        "   *"                                                                              \
        "   */"                                                                             \
        "  class_store_double(dataptr,"                                                     \
        "    ppw->delta_p_fld/ppw->delta_rho_fld, pba->has_fld, storeidx);"                 \
        "}"                                                                                 \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    # Include dcdm in the growth factor D(a)
    pattern='rho_M * \\+='
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/background.c" | head -n 1)
    ((linenr += 1))
    new_lines=(                                        \
        "/* Include dcdm in growth factor */"          \
        "if (pba->has_dcdm == _TRUE_)"                 \
        "  rho_M += pvecback[pba->index_bg_rho_dcdm];" \
    )
    patch_class "${class_dir}/source/background.c" ${linenr} \
        "insert" "below" "${new_lines[@]}"
    # Include theta_tot in perturbation output
    linenr=$(new_class_perturbation_linenr "perturb_prepare_output")
    new_lines=(                                                               \
        "/* Include theta_tot in perturbation output */"                      \
        "class_store_columntitle(ppt->scalar_titles, \"theta_tot\", _TRUE_);" \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    linenr=$(new_class_perturbation_linenr "perturb_print_variables")
    new_lines=(                                                                                  \
        "/* Include theta_tot in perturbation output */"                                         \
        "double rho_plus_p_tot = -2./3.*pvecback[pba->index_bg_H_prime]/a + 2./3.*pba->K/(a*a);" \
        "double theta_tot = ppw->rho_plus_p_theta/rho_plus_p_tot;"                               \
        "class_store_double(dataptr, theta_tot, _TRUE_, storeidx);"                              \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    # Include h_prime in perturbation output
    linenr=$(new_class_perturbation_linenr "perturb_prepare_output")
    new_lines=(                                                                                \
        "/* Include h_prime in perturbation output */"                                         \
        "class_store_columntitle(ppt->scalar_titles, \"h_prime\", ppt->gauge == synchronous);" \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    linenr=$(new_class_perturbation_linenr "perturb_print_variables")
    new_lines=(                                                          \
        "/* Include h_prime in perturbation output */"                   \
        "class_store_double(dataptr, pvecmetric[ppw->index_mt_h_prime]," \
        "  ppt->gauge == synchronous, storeidx);"                        \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    # Include H_T_prime in perturbation output
    linenr=$(new_class_perturbation_linenr "perturb_prepare_output")
    new_lines=(                                                               \
        "/* Include H_T_prime (in N-body gauge) in perturbation output */"    \
        "class_store_columntitle(ppt->scalar_titles, \"H_T_prime\", _TRUE_);" \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    linenr=$(new_class_perturbation_linenr "perturb_print_variables")
    new_lines=(                                                                             \
        "/**"                                                                               \
        " * Include H_T_prime (in N-body gauge) in perturbation output."                    \
        " * Here we make use of rho_plus_p_tot defined earlier."                            \
        " */"                                                                               \
        "double p_tot_prime = 0.0;"                                                         \
        "/* Photons */"                                                                     \
        " p_tot_prime += -3.*a*H*(1. + 1./3.)*1./3.*pvecback[pba->index_bg_rho_g];"         \
        "/* Baryons have no pressure */"                                                    \
        "/* Ultra relativistic species */"                                                  \
        "if (pba->has_ur == _TRUE_)"                                                        \
        "  p_tot_prime += -3.*a*H*(1. + 1./3.)*1./3.*pvecback[pba->index_bg_rho_ur];"       \
        "/* Cold dark matter has no pressure */"                                            \
        "/* Non-cold dark matter */"                                                        \
        "if (pba->has_ncdm == _TRUE_) {"                                                    \
        "  for(n_ncdm=0; n_ncdm < pba->N_ncdm; n_ncdm++)"                                   \
        "    p_tot_prime += -a*H*(5.*pvecback[pba->index_bg_p_ncdm1+n_ncdm]"                \
        "    - pvecback[pba->index_bg_pseudo_p_ncdm1+n_ncdm]);"                             \
        "}"                                                                                 \
        "/* Decaying cold dark matter has no pressure */"                                   \
        "/* Decay radiation */"                                                             \
        "if (pba->has_dr == _TRUE_)"                                                        \
        "  p_tot_prime += -3.*a*H*(1. + 1./3.)*1./3.*pvecback[pba->index_bg_rho_dr]"        \
        "    + 1./3.*a*pba->Gamma_dcdm*pvecback[pba->index_bg_rho_dcdm];"                   \
        "/* Dark energy fluid */"                                                           \
        "if (pba->has_fld == _TRUE_) {"                                                     \
        "  p_tot_prime += a*H*pvecback[pba->index_bg_rho_fld]"                              \
        "    *(a*dw_over_da_fld - 3.*w_fld*(1. + w_fld));"                                  \
        "}"                                                                                 \
        "/* Scalar field */"                                                                \
        "if (pba->has_scf == _TRUE_) {"                                                     \
        "  p_tot_prime += -H/a*pvecback[pba->index_bg_phi_prime_scf]"                       \
        "    *pvecback[pba->index_bg_phi_prime_scf]"                                        \
        "    - 2./3.*pvecback[pba->index_bg_dV_scf]*pvecback[pba->index_bg_phi_prime_scf];" \
        "}"                                                                                 \
        "/* Lambda has constant pressure */"                                                \
        "double H_T_prime = 3.*a*H/rho_plus_p_tot*("                                        \
        "  - ppw->delta_p"                                                                  \
        "  + p_tot_prime*theta_tot/(k*k)"                                                   \
        "  + ppw->rho_plus_p_shear);"                                                       \
        "class_store_double(dataptr, H_T_prime, _TRUE_, storeidx);"                         \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    # Do not convert synchronous variables to Newtonian gauge
    pattern='converting *synchronous *variables *to *newtonian *ones'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" \
        "${class_dir}/source/perturbations.c" | head -n 1)
    ((linenr += 1))
    new_lines=(                                              \
        "/* Do not convert to Newtonian gauge */"            \
        "if (0 == 1) {  /* (ppt->gauge == synchronous) { */" \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "replace" "below" "${new_lines[@]}"
    # Add 'node', 'num_threads' and 'message' to the classy.Class
    # initialiser as optional arguments and store them in the
    # 'background' struct. The 'num_threads' integer will hold the
    # number of MPI processes on the local node, which signals the
    # number of OpenMP threads to use. All three variables will be used
    # to make CLASS print out status updates during perturbation
    # computations.
    linenr_1="$(grep -n 'struct background' "${class_dir}/include/background.h" | head -n 1)"
    linenr_1="${linenr_1%%:*}"
    i=0
    while :; do
        ((i += 1))
        linenr_2="$(grep -n '};' "${class_dir}/include/background.h" | head -n ${i} | tail -n 1)"
        linenr_2="${linenr_2%%:*}"
        if [ ${linenr_2} -gt ${linenr_1} ]; then
            break
        fi
    done
    new_lines=(                                                \
        "/**"                                                  \
        " * Used to set number of OpenMP threads and to print" \
        " * status updates during perturbation computations."  \
        " */"                                                  \
        "int node, num_threads;"                               \
        "char* message;"                                       \
    )
    patch_class "${class_dir}/include/background.h" ${linenr_2} "insert" "below" "${new_lines[@]}"
    linenr="$(grep -n "__cinit__" "${class_dir}/python/classy.pyx")"
    linenr="${linenr%%:*}"
    sed -i "${linenr}s/.*/    def __cinit__(self, \
        default=False, node=0, num_threads=-1, message=''): \
        # Changed for use with CONCEPT/" "${class_dir}/python/classy.pyx"
    ((linenr += 1))
    new_lines=(                                                            \
        "self.ba.node = <int>node"                                         \
        "self.ba.num_threads = <int>num_threads"                           \
        "self.ba.message = <char*>malloc((len(message) + 1)*sizeof(char))" \
        "strcpy(self.ba.message, message.encode())"                        \
    )
    patch_class "${class_dir}/python/classy.pyx" ${linenr} "insert" "below" "${new_lines[@]}"
    linenr_1="$(grep -n 'cdef struct background:' "${class_dir}/python/cclassy.pxd")"
    linenr_1="${linenr_1%%:*}"
    i=0
    while :; do
        ((i += 1))
        linenr_2="$(grep -n 'cdef struct' "${class_dir}/python/cclassy.pxd" \
            | head -n ${i} | tail -n 1)"
        linenr_2="${linenr_2%%:*}"
        if [ ${linenr_2} -eq ${linenr_1} ]; then
            ((i += 1))
            linenr_2="$(grep -n 'cdef struct' "${class_dir}/python/cclassy.pxd" \
                | head -n ${i} | tail -n 1)"
            linenr_2="${linenr_2%%:*}"
            while :; do
                ((linenr_2 -= 1))
                line="$(sed "${linenr_2}!d" "${class_dir}/python/cclassy.pxd")"
                if [ -n "${line}" ]; then
                    break
                fi
            done
            ((linenr_2 += 1))
            break
        fi
    done
    new_lines=(           \
        "int node"        \
        "int num_threads" \
        "char* message"   \
    )
    patch_class "${class_dir}/python/cclassy.pxd" ${linenr_2} "insert" "above" "${new_lines[@]}"
    linenr="$(grep -n "precision_file *\[ *0 *\] *= *'\\\\0' *;" \
        "${class_dir}/source/input.c")"
    linenr="${linenr%%:*}"
    ((linenr += 1))
    new_lines=(                                         \
        "pba->node = 0;"                                \
        "pba->num_threads = -1;"                        \
        "pba->message = (char*)malloc(1*sizeof(char));" \
        "pba->message[0] = '\\\\0';"                    \
    )
    patch_class "${class_dir}/source/input.c" ${linenr} "insert" "below" "${new_lines[@]}"
    linenr="$(grep -n 'for (index_k = ppt->k_size\[index_md\]-1; index_k >=0; index_k--)' \
        "${class_dir}/source/perturbations.c")"
    linenr="${linenr%%:*}"
    ((linenr += 1))
    new_lines=(                                                     \
        "if ((abort == _FALSE_) && (pba->message[0] != '\\\\0')) {" \
        "  printf("                                                 \
        "    pba->message,"                                         \
        "    pba->node,"                                            \
        "    thread,"                                               \
        "    ppt->k[index_md][index_k],"                            \
        "    ppt->k_size[index_md] - 1 - index_k,"                  \
        "    ppt->k_size[index_md] - 1"                             \
        "  );"                                                      \
        "  fflush(stdout);"                                         \
        "}"                                                         \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "below" "${new_lines[@]}"
    pattern='#pragma *omp *parallel'
    linenr=$(awk "\$0 ~ \"${pattern}\" {print NR}" "${class_dir}/source/perturbations.c" \
        | head -n 1)
    new_lines=(                                                                  \
        "if (pba->num_threads != -1) {"                                          \
        "  /**"                                                                  \
        "   * Explicitly set the number of OpenMP threads."                      \
        "   * Note that the value of OMP_NUM_THREADS is now completely ignored." \
        "   */"                                                                  \
        "  omp_set_num_threads(pba->num_threads);"                               \
        "}"                                                                      \
    )
    patch_class "${class_dir}/source/perturbations.c" ${linenr} "insert" "above" "${new_lines[@]}"
    # If CO𝘕CEPT is installed we now switch out the values of various
    # constants in the CLASS source code so that they match the values
    # used in CO𝘕CEPT.
    if [ "${concept_works}" == "True" ]; then
        printf "Patching physical constants in CLASS to match values used in ${esc_concept}\n"
        class_constants=(                                            \
            _Mpc_over_m_   "units.Mpc/units.m"                       \
            _Gyr_over_Mpc_ "light_speed*units.Gyr/units.Mpc"         \
            _c_            "light_speed*units.s/units.m"             \
            _G_            "G_Newton*units.kg*units.s**2/units.m**3" \
            _eV_           "units.eV/units.J"                        \
            _k_B_          "NotImplemented"                          \
            _h_P_          "2*π*ħ/(units.J*units.s)"                 \
        )
        for ((name_index = 0; name_index < ${#class_constants[@]}; name_index += 2)); do
            ((expr_index = name_index + 1))
            name=${class_constants[${name_index}]}
            expr="${class_constants[${expr_index}]}"
            if [ "${expr}" == "NotImplemented" ]; then
                # This CLASS constant has no equivalent in CO𝘕CEPT
                continue
            fi
            value="$(concept_print "${expr}")"
            redefine_class "${class_dir}/include/background.h" ${name} "${value}"
        done
    fi
    # Build CLASS, including the Python wrapper classy. We explicitly
    # specify Python 3 as the language level and replace -O4 with -O3
    # (which are equivalent on compilers that recognise -O4).
    # We try with and without the -ffast-math option, try different
    # compilers and various flags for correctly linking to OpenMP.
    # The classy Python wrapper is hard-coded to use gcc in setup.py to
    # test for existence of the mvec library, as well as to get the
    # compiler library directory.
    sed -i '1s/^/# cython: language_level=3\n/' "python/classy.pyx"
    sed -i 's/-O4/-O3/' "Makefile"
    cp "Makefile" "Makefile_ori"
    cp "python/setup.py" "python/setup.py_ori"
    class_install_func() {
        if [ "${hardcoded_gcc}" == "False" ] && [ -z "${CC}" ]; then
            return 1
        fi
        if [ -d "${blas_dir}" ]; then
            export LD_LIBRARY_PATH="${blas_dir}/lib:${LD_LIBRARY_PATH}"
        fi
        cp "Makefile_ori" "Makefile"
        cp "python/setup.py_ori" "python/setup.py"
        make clean || :
        if [ "${fast_math}" == "False" ]; then
            sed -i '0,/-ffast-math/s/-ffast-math/#-ffast-math/' "Makefile"
        fi
        if [ -n "${CC}" ]; then
            sed -i "s/CC * =/CC = ${CC//\//\\/}  #/" "Makefile"
        fi
        if [ -n "${OMPFLAG}" ]; then
            sed -i "s/OMPFLAG *=/OMPFLAG = ${OMPFLAG}  #/" "Makefile"
        fi
        sed -i "s/extra_link_args *=/extra_link_args=\
'${gomp_in_extra_link_args} ${OMPFLAG}'.split(),  #/" "python/setup.py"
        if [ "${hardcoded_gcc}" == "False" ]; then
            # Remove hard-coding of gcc
            linenr_1=$(awk "\$0 ~ \"gcc\" {print NR}" "python/setup.py" \
                | head -n 1)
            linenr_2=$(awk "\$0 ~ \"mvec\" {print NR}" "python/setup.py" \
                | tail -n 1)
            sed -i "${linenr_1},${linenr_2}d" "python/setup.py"
            sed -i "${linenr_1}iliblist = ['class']" "python/setup.py"
            sed -i 's/GCCPATH//g' "python/setup.py"
            # Check for the mvec library
            rm -rf "tmp_mvec" || :
            mkdir -p "tmp_mvec"
            cd "tmp_mvec"
            echo "int main(void){ return 0; }" > test.c
            mvec_warning="$("${CC}" -lmvec test.c 2>&1 | grep mvec || :)"
            cd ..
            rm -rf "tmp_mvec" || :
            if [ -z "${mvec_warning}" ]; then
                # mvec found.
                # Add the mvec and m library.
                ((linenr = linenr_1 + 1))
                sed -i "${linenr}iliblist += ['mvec', 'm']" "python/setup.py"
            fi
        fi
        PYTHON="${python}" make ${make_jobs} 2>&1 || return 1
        "${python}" -B -c "import classy; classy.Class().compute()" || return 1
        # Test CLASS
        if [ "${do_tests}" == "True" ]; then
            if [ -d "${blas_dir}" ]; then
                export LD_LIBRARY_PATH="${blas_dir}/lib:${LD_LIBRARY_PATH}"
            fi
            # We do not use the built-in test_class.py, as this requires
            # tens of gigabytes of memory and uses the Nose and
            # parameterized Python packages. Instead we perform a simple
            # test of our own, which only does a background computation.
            if ! "${python}" -B -c "
import sys
from classy import Class
cosmo = Class()
cosmo.compute()
sys.exit(int(cosmo.get_background()['proper time [Gyr]'][-1]) != 13)
"; then
                test_success="False"
            fi
            if [ "${test_success}" == "False" ]; then
                echo "CLASS did not pass a simple background computation test" > "test_log"
            fi
        fi
        # Cleanup if installing in slim mode
        if [ "${slim}" == "True" ]; then
            (cd "${class_dir}" && make clean) || :
            rm -rf "${class_dir}/doc" || :
            rm -rf "${class_dir}/output/"* || :
            rm -f "${class_dir}/Makefile_ori" "${class_dir}/python/setup.py_ori" || :
        fi
    }
    install "CLASS" "no_init_install"               \
        gomp_in_extra_link_args "" "-gomp"      ";" \
        hardcoded_gcc "False" "True"            ";" \
        compiler "${compiler_possibilities[@]}" ";" \
        OMPFLAG "-fopenmp" "-openmp" "-qopenmp" ";" \
        fast_math "True" "False"                ";" \

fi



#####################################################
# Install GADGET, used for testing the CO𝘕CEPT code #
#####################################################
# FFTW 2.x (GADGET-2 is incompatible with FFTW 3.x)
fftw_for_gadget_install_func() {
    also_single_precision="False"  # Install both double and single precision?
    if [ -z "${enable_shared}" ] && [ -n "${shared}" ]; then
        return 1
    fi
    enable_mpi=""
    if [ -n "${mpi_dir}" ] && [ -d "${mpi_dir}" ]; then
        enable_mpi="--enable-mpi"
        export MPICC="${CC}"
        export MPILIBS="-lmpi ${MPILIBS}"
    fi
    export CFLAGS="-O3 ${PIC} ${CFLAGS}"
    export CXXFLAGS="-O3 ${PIC} ${CXXFLAGS}"
    export LDFLAGS="${LDFLAGS} -Wl,-O3 ${shared} ${PIC}"
    if [ -d "${perl_dir}" ]; then
        export PATH="${perl_dir}/bin:${PATH}"
    fi
    if [ "${extra_optimizations}" == "True" ]; then
        set_optimizations --no-lto
    fi
    # Intel compilers may link against the NUMA library, which should be
    # placed in /usr/lib64. Add this directory to the LDFLAGS.
    # Both libnuma.so and libnuma.so.1 should exist. To be sure,
    # we create symlinks to these in a new directory and add this
    # directory to LDFLAGS as well.
    if [ -d "/usr/lib64" ]; then
        export LDFLAGS="${LDFLAGS} -L/usr/lib64"
    fi
    numa_symlink_dir="${fftw_for_gadget_dir}/numa_symlinks"
    rm -rf "${numa_symlink_dir}" || :
    mkdir -p "${numa_symlink_dir}" || :
    if [ -f "/usr/lib64/libnuma.so" ] && [ ! -f "/usr/lib64/libnuma.so.1" ]; then
        ln -s "/usr/lib64/libnuma.so" "${numa_symlink_dir}/libnuma.so.1" > /dev/null 2>&1 || :
    fi
    if [ -f "/usr/lib64/libnuma.so.1" ] && [ ! -f "/usr/lib64/libnuma.so" ]; then
        ln -s "/usr/lib64/libnuma.so.1" "${numa_symlink_dir}/libnuma.so" > /dev/null 2>&1 || :
    fi
    export LDFLAGS="${LDFLAGS} -L${numa_symlink_dir}"
    # Double-precision
    precision_flags=""
    if [ "${also_single_precision}" == "True" ]; then
        precision_flags="--enable-type-prefix"
    fi
    # The config.guess and config.sub file bundled with FFTW 2 may be
    # too old to be able to recognize the system.
    config_files=("config.guess" "config.sub")
    if [ "${fetch_newest_config}" == "True" ]; then
        fftw_for_gadget_builddir="$(pwd)"
        config_url="https://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=filename;hb=HEAD"
        for config_file in "${config_files[@]}"; do
            rm -f "${fftw_for_gadget_builddir}/${config_file}" || :
            if [ ! -d "${tmp_dir}/${config_file/./_}" ] \
                || [ -z "$(ls "${tmp_dir}/${config_file/./_}")" ]; then
                download "${config_file/./_}" "False" "${config_url/filename/${config_file}}"
            fi
            cp "${tmp_dir}/${config_file/./_}/"* \
                "${fftw_for_gadget_builddir}/${config_file}" || return 1
        done
        cd "${fftw_for_gadget_builddir}"
    fi
    ./configure ${enable_shared} ${enable_mpi} ${precision_flags} \
        --disable-fortran ${with_pic} --prefix="${fftw_for_gadget_dir}" 2>&1 || return 1
    make 2>&1 || return 1  # Parallel builds fail on some systems
    if [ "${extra_optimizations}" == "True" ] || [ "${do_tests}" == "True" ]; then
        fftw_for_gadget_test_max_time=3600
        exit_code_filename="${tmp_dir}/.exit_code_fftw_for_gadget"
        mkdir -p "$(dirname "${exit_code_filename}")"
        rm -f "${exit_code_filename}" || :
        (make check 2>&1 | tee "test_log"; echo "${PIPESTATUS[0]}" > "${exit_code_filename}" \
            ) & fftw_for_gadget_test_pid=$!
        soothe ${fftw_for_gadget_test_pid} ${fftw_for_gadget_test_max_time}
        sleep 1
        kill -9 ${fftw_for_gadget_test_pid} >/dev/null 2>&1 || :
        wait    ${fftw_for_gadget_test_pid} >/dev/null 2>&1 || :
        exit_code="$(cat "${exit_code_filename}" 2>/dev/null || :)"
        rm -f "${exit_code_filename}" || :
        if [ "${extra_optimizations}" == "True" ]; then
            if [ "${exit_code}" != "0" ]; then
                rm -f "test_log" || :
                return 1
            fi
            if [ "${do_tests}" == "False" ]; then
                rm -f "test_log" || :
            fi
        elif [ "${do_tests}" == "True" ]; then
            if [ "${exit_code}" != "0" ]; then
                test_success="False"
            fi
        fi
    fi
    make install 2>&1 || return 1  # Parallel builds fail on some systems
    # Single-precision
    if [ "${also_single_precision}" == "True" ]; then
        precision_flags="--enable-float --enable-type-prefix"
        make clean || :
        ./configure ${enable_shared} ${enable_mpi} ${precision_flags} \
            --disable-fortran ${with_pic} --prefix="${fftw_for_gadget_dir}" 2>&1 || return 1
        make         2>&1 || return 1  # Parallel builds fail on some systems
        make install 2>&1 || return 1  # Parallel builds fail on some systems
    fi
    # Cleanup possibly downloaded config files
    for config_file in "${config_files[@]}"; do
        rm -rf "${tmp_dir}/${config_file/./_}" || :
    done
    # Cleanup if installing in slim mode
    if [ "${slim}" == "True" ]; then
        rm -rf "${fftw_for_gadget_dir}/info" || :
    fi
}
compiler_possibilities_fftw_for_gadget=("${compiler_possibilities[@]}")
if [ -n "${mpi_dir}" ] && [ -d "${mpi_dir}" ]; then
    compiler_possibilities_fftw_for_gadget=("specified_mpi")
fi
install "FFTW for GADGET"                                       \
    fetch_newest_config "False" "True"                      ";" \
    compiler "${compiler_possibilities_fftw_for_gadget[@]}" ";" \
    extra_optimizations "True" "False"                      ";" \
    enable_shared "--enable-shared" ""                      ";" \
    shared "" "-shared"                                     ";" \
    with_pic "" "--with-pic"                                ";" \
    PIC "-fPIC" ""                                          ";" \

# GADGET
if [ "${gadget_install}" == "True" ] && [ "${gadget_installed}" == "False" ]; then
    init_install "GADGET"
    mkdir -p "${gadget_dir}"
    mv ./* "${gadget_dir}/"
    # As M_PI is not part of the C standard,
    # it should be defined within the GADGET source code.
    if [ -n "${python}" ]; then
        pi="$("${python}" -B -c "import math; print('pi =', math.pi)" \
            | grep 'pi =' | awk '{print $NF}' || :)"
        if [[ "${pi}" == "3.14"* ]]; then
            echo "
#ifndef M_PI
#define M_PI ${pi}
#endif
" >> "${Gadget2_dir}/allvars.h"
        fi
    fi
    # Increase the maximum allowed file name size
    redefine_gadget() {
        filename="$1"
        name="$2"
        value="$3"
        sed -i "s/^\(\s*#define\s\+${name}\s\+\)\(\S*\)\(.*\)$/\1${value}\3/" "${filename}"
    }
    redefine_gadget "${Gadget2_dir}/allvars.h" MAXLEN_FILENAME 1000
    # If CO𝘕CEPT is installed we now switch out the values of various
    # constants in the GADGET source code so that they match the values
    # used in CO𝘕CEPT.
    if [ "${concept_works}" == "True" ]; then
        printf "Patching units and physical constants in GADGET \
to match values used in ${esc_concept}\n"
        gadget_constants=(                                              \
            HYDROGEN_MASSFRAC "NotImplemented"                          \
            GRAVITY           "G_Newton*units.g*units.s**2/units.cm**3" \
            SOLAR_MASS        "units.m_sun/units.g"                     \
            SOLAR_LUM         "NotImplemented"                          \
            RAD_CONST         "NotImplemented"                          \
            AVOGADRO          "NotImplemented"                          \
            BOLTZMANN         "NotImplemented"                          \
            GAS_CONST         "NotImplemented"                          \
            C                 "light_speed*units.s/units.cm"            \
            PLANCK            "2*π*ħ*units.s/(units.g*units.cm**2)"     \
            CM_PER_MPC        "units.Mpc/units.cm"                      \
            PROTONMASS        "NotImplemented"                          \
            ELECTRONMASS      "NotImplemented"                          \
            THOMPSON          "NotImplemented"                          \
            ELECTRONCHARGE    "NotImplemented"                          \
            HUBBLE            "100*units.km/units.Mpc"                  \
            SEC_PER_MEGAYEAR  "units.Myr/units.s"                       \
            SEC_PER_YEAR      "units.yr/units.s"                        \
        )
        for ((name_index = 0; name_index < ${#gadget_constants[@]}; name_index += 2)); do
            ((expr_index = name_index + 1))
            name=${gadget_constants[${name_index}]}
            expr="${gadget_constants[${expr_index}]}"
            if [ "${expr}" == "NotImplemented" ]; then
                # This GADGET constant has no equivalent in CO𝘕CEPT
                continue
            fi
            value="$(concept_print "${expr}")"
            redefine_gadget "${Gadget2_dir}/allvars.h" ${name} "${value}"
        done
    fi
    # Patch GADGET so that it does not dump restart files
    # at the end of each simulation.
    n=$(grep -n "restart(0)" "${Gadget2_dir}/run.c" | tail -n 1 | awk '{print $1}')
    n="${n//:}"
    sed -i "${n}i\  /*" "${Gadget2_dir}/run.c"
    ((n += 2))
    sed -i "${n}i\  */" "${Gadget2_dir}/run.c"
    # Done patching GADGET
    cd "${concept_dir}"
    rm -rf "${tmp_dir}/gadget" || :
    # GADGET will be tested as part of the CO𝘕CEPT test suite
    install_notice "GADGET" "${gadget_dir}"
    # Cleanup if installing in slim mode
    if [ "${slim}" == "True" ]; then
        rm -rf "${gadget_dir}/Analysis" || :
        rm -rf "${gadget_dir}/Documentation" || :
        rm -rf "${gadget_dir}/ICs" || :
        rm -rf "${Gadget2_dir}/html" || :
        rm -rf "${Gadget2_dir}/parameterfiles" || :
    fi
fi



##############################
# Testing GADGET and CO𝘕CEPT #
##############################
# As the CO𝘕CEPT build process requires a lot of memory, we perform
# the build in serial unless make_jobs is set.
make_jobs_backup="${make_jobs}"
if [ "${make_jobs_set_by_user}" == "False" ]; then
    make_jobs="-j 1"
fi
export make_jobs="${make_jobs}"
if [ "${concept_install}" == "True" ] && [ "${concept_installed}" == "False" ]; then
    if [ "${do_tests}" == "True" ]; then
        # Run basic CO𝘕CEPT test to test the environment
        current_step="basic test of ${esc_concept}"
        heading "Basic test of ${esc_concept}"
        set_status "Basic test of ${esc_concept}"
        cd "${concept_dir}"
        "${concept}" -t "basic" 2>&1 | tee "${concept_test_log}"
        [ ${PIPESTATUS[0]} -eq 0 ] || concept_test_success="False"
        if  [ "${gadget_install}" == "True" ]; then
            # Run GADGET test
            # if basic CO𝘕CEPT test finished successfully.
            if [ "${concept_test_success}" == "True" ]; then
                current_step="testing GADGET"
                heading "Testing GADGET"
                set_status "Testing GADGET"
                "${concept}" -t "gadget" 2>&1 | tee "${gadget_test_log}"
                [ ${PIPESTATUS[0]} -eq 0 ] || gadget_test_success="False"
                # Clean test_log if test is successful
                if [ "${gadget_test_success}" == "True" ]; then
                    rm -f "${gadget_test_log}" || :
                fi
            fi
            # Run complete CO𝘕CEPT test suite
            # if basic CO𝘕CEPT test finished successfully.
            if [ "${concept_test_success}" == "True" ]; then
                current_step="testing ${esc_concept}"
                heading "Testing ${esc_concept}"
                set_status "Testing ${esc_concept}"
                OMP_NUM_THREADS_backup="${OMP_NUM_THREADS}"
                unset OMP_NUM_THREADS
                "${concept}" -t "all" 2>&1 | tee "${concept_test_log}"
                [ ${PIPESTATUS[0]} -eq 0 ] || concept_test_success="False"
                # Clean up after successful tests
                if [ "${concept_test_success}" == "True" ]; then
                    rm -f "${concept_test_log}" || :
                    # To clean up properly we perform a distclean,
                    # but without removing the tmp directory.
                    (:                               \
                        && cd "${concept_dir}"       \
                        && source "${concept}"       \
                        && make distclean-except-tmp \
                    ) || :
                fi
                if [ -n "${OMP_NUM_THREADS_backup}" ]; then
                    export OMP_NUM_THREADS="${OMP_NUM_THREADS_backup}"
                fi
            fi
        fi
        cd "${concept_dir}"
    fi
    # Place the installation notice in the GADGET directory in order
    # to minimize the number of files in the CO𝘕CEPT directory.
    install_notice "CONCEPT" "${gadget_dir}"
fi
export make_jobs="${make_jobs_backup}"



###################################
# Build the CO𝘕CEPT code and docs #
###################################
if [ "${concept_install}" == "True" ] && [ "${concept_installed}" == "False" ]; then
    current_step="building ${esc_concept}"
    # Do not print a heading,
    # as the CO𝘕CEPT build process does this by itself.
    echo
    set_status "Building ${esc_concept}"
    # Build the code by running it with no parameters specified.
    # As the CO𝘕CEPT build process requires a lot of memory, we perform
    # the build in serial unless make_jobs is set.
    # On failure we try again without link time optimizations.
    make_jobs_backup="${make_jobs}"
    if [ "${make_jobs_set_by_user}" == "False" ]; then
        make_jobs="-j 1"
    fi
    export make_jobs="${make_jobs}"
    cd "${concept_dir}"
    build_concept_success="True"
    logo_printed=True "${concept}" --local 2>&1 || build_concept_success="False"
    if [ "${build_concept_success}" == "False" ]; then
        error "Failed to build ${esc_concept}"
        echo "Will now try without link time optimizations"
        (source "${concept}" && make clean) || :
        build_concept_success="True"
        logo_printed=True "${concept}" --local --no-lto 2>&1 || build_concept_success="False"
    fi
    export make_jobs="${make_jobs_backup}"
    if [ "${build_concept_success}" == "False" ]; then
        error "Failed to build ${esc_concept} even with no link time optimizations"
        exit 1
    fi
    # Remove job files generated by the above run
    (source "${concept}" && make clean-job) || :
    # Remove compilation artefacts if installing in slim mode
    if [ "${slim}" == "True" ]; then
        mkdir -p "${tmp_dir}/so"
        mv "${build_dir}/"*.so "${tmp_dir}/so/"
        (source "${concept}" && make clean) || :
        mkdir -p "${build_dir}"
        mv "${tmp_dir}/so/"* "${build_dir}/"
        rm -rf "${tmp_dir}/so" || :
    fi
    # If not in slim mode, also build the documentation
    if [ "${slim}" != "True" ]; then
        echo
        (source "${concept}" && make doc 2>/dev/null) || :
    fi
    cd "${concept_dir}"
fi



#############################
# Final cleanup and notices #
#############################
# Clean up the tmp directory except for the log files
# and the temporary log_pid file.
# This may fail on clusters with the nfs file system
# ("Device or resource busy") due to still
# running background processes holding .nfs... files open.
if [ "${cleanup_tmp}" != "False" ]; then
    files_keep=("install_log" "install_log_err" "log_pid")
    for f in "${tmp_dir}/"* "${tmp_dir}/".[^.]*; do
        f_base="$(basename "${f}")"
        remove="True"
        for file_keep in "${files_keep[@]}"; do
            if [ "${f_base}" == "${file_keep}" ]; then
                remove="False"
                break
            fi
        done
        if [ "${remove}" == "True" ]; then
            rm -rf "${f}" || :
        fi
    done
fi
# Remove the Python cache generated by all the Python invocations
# during the install.
rm -rf "${concept_dir}/__pycache__" || :
# Pytest may leave a cache directory
rm -rf "${concept_dir}/.pytest_cache" || :
# Remove miscellaneous files which may be left
# by one of the installations.
rm -rf "${concept_dir}/_configtest"* || :
rm -f "${concept_dir}/gramA" "${concept_dir}/gramB" || :
# Further cleanups when installing in slim mode
slimdown_python() {
    # Arguments: Name, directory
    if get_command "find" >/dev/null; then
        find "${2}"                      \
            -type d -a \(                \
                   -name "__pycache__"   \
                -o -name ".pytest_cache" \
                -o -name "idle_test"     \
                -o -name "test"          \
                -o -name "tests"         \
            \)                           \
            -exec rm -rf '{}' +          \
            || :
        find "${2}"                \
            -type f -a \(          \
                   -name "*.ipynb" \
                -o -name "*.pyc"   \
                -o -name "*.pyo"   \
            \)                     \
            -exec rm -f '{}' +     \
            || :
    else
        echo "Could not slim down ${1} as the 'find' command was not found" >&2
    fi
}
if [ "${slim}" == "True" ]; then
    # Slim down Python and Python packages
    if [ "${python_install}" == "True" ] && [ "${python_installed}" == "False" ]; then
        slimdown_python "Python" "${python_dir}"
        rm -rf "${python_dir}/lib/python${python_version_major}.${python_version_minor}/\
config-${python_version_major}.${python_version_minor}-"*
        rm -f "${python_dir}/lib/python${python_version_major}.${python_version_minor}/\
site-packages/Pillow.libs/"lib{freetype,harfbuzz,lcms,png,web}*.so* || :
        rm -f "${python_dir}/lib/python${python_version_major}.${python_version_minor}/\
site-packages/scipy/misc/face.dat" || :
    fi
    # Slim down the Python component of CLASS
    if [ "${class_install}" == "True" ] && [ "${class_installed}" == "False" ]; then
        slimdown_python "CLASS" "${class_dir}"
    fi
    # Slim down FreeType
    if [ "${freetype_install}" == "True" ] && [ "${freetype_installed}" == "False" ]; then
        rm -f "${freetype_dir}/lib/"libfreetype*.so* || :
    fi
    # Remove all static libraries (archive files) in the dependency directory
    if get_command "find" >/dev/null; then
        rm -f $(find "${dep_dir}" -name "*.a") || :
    fi
    # We may even remove some of the dependencies entirely
    if [ "${python_install}" == "True" ] && [ "${python_installed}" == "False" ]; then
        # Python packages to remove
        removable_dependencies=( \
            "hypothesis"         \
            "pybind11"           \
            "pytest"             \
            "pythran"            \
        )
        for dependency in "${removable_dependencies[@]}"; do
            dependency_installed="$(check_pypackage_installed "${dependency}")"
            if [ "${dependency_installed}" == "True" ]; then
                "${python}" -m pip uninstall "${dependency}" -y 2>&1 || :
            fi
        done
    fi
    removable_dependencies=("perl" "zlib")
    for dependency in "${removable_dependencies[@]}"; do
        eval "dependency_install=\"\${${dependency}_install}\""
        eval "dependency_installed=\"\${${dependency}_installed}\""
        if [ "${dependency_install}" == "True" ] && [ "${dependency_installed}" == "False" ]; then
            eval "dependency_dir=\"\${${dependency}_dir}\""
            rm -rf "${dependency_dir}" || :
        fi
    done
fi
if [ "${cleanup_concept}" == "True" ] && [ "${concept_install}" == "True" ]; then
    current_dir="$(pwd)"
    cd "${concept_dir}"
    # Remove the build files of CO𝘕CEPT, leaving only the source
    (source "${concept}" && make distclean 2>/dev/null) || :
    # Further remove empty directories (e.g. jobs, output)
    for d in * .*; do
        if [ ! -d "${d}" ] || [ "${d}" == "." ] || [ "${d}" == ".." ]; then
            continue
        fi
        if [ -z "$(ls -A "${d}")" ]; then
            rm -rf "${d}" || :
        fi
    done
    cd "${current_dir}"
fi
# Copyright notice
disable_status
copyright_notice() {
    # Arguments: Program/package name, text if installed by this script
    if eval "[ \"\${${1}_install}\" == \"True\" ]"; then
        printf "${2}\n"
    fi
}
if [ "${install_anything}" == "True" ] && [ "${say_copyright}" != "False" ]; then
    current_step="copyright notice"
    heading "Copyright notice"
    if [ "${concept_install}" == "True" ]; then
        printf "${esc_concept} has been installed along with the following dependencies:\n"
    else
        printf "The following software has been installed:\n"
    fi
    copyright_notice "blas"              "OpenBLAS"
    copyright_notice "class"             "CLASS"
    copyright_notice "fftw"              "FFTW 3"
    copyright_notice "fftw_for_gadget"   "FFTW 2"
    copyright_notice "freetype"          "FreeType"
    copyright_notice "gadget"            "GADGET"
    copyright_notice "gsl"               "GSL"
    copyright_notice "hdf5"              "HDF5"
    copyright_notice "mpi"               "${mpi_formatted}"
    copyright_notice "ncurses"           "ncurses"
    copyright_notice "openssl"           "OpenSSL"
    copyright_notice "perl"              "Perl"
    copyright_notice "zlib"              "zlib"
    copyright_notice "python"            "Python"
    copyright_notice "blessings"         "$(printf ${en_quad}%.s {1..4})Blessings"
    copyright_notice "cython"            "$(printf ${en_quad}%.s {1..4})Cython"
    copyright_notice "cythongsl"         "$(printf ${en_quad}%.s {1..4})CythonGSL"
    copyright_notice "h5py"              "$(printf ${en_quad}%.s {1..4})H5Py"
    copyright_notice "matplotlib"        "$(printf ${en_quad}%.s {1..4})Matplotlib"
    copyright_notice "mpi4py"            "$(printf ${en_quad}%.s {1..4})MPI4Py"
    copyright_notice "numpy"             "$(printf ${en_quad}%.s {1..4})NumPy"
    copyright_notice "scipy"             "$(printf ${en_quad}%.s {1..4})SciPy"
    copyright_notice "sphinx"            "$(printf ${en_quad}%.s {1..4})Sphinx"
    copyright_notice "sphinx_copybutton" "$(printf ${en_quad}%.s {1..4})Sphinx_copybutton"
    copyright_notice "sphinx_rtd_theme"  "$(printf ${en_quad}%.s {1..4})Sphinx_rtd_theme"
    copyright_notice "sphinx_tabs"       "$(printf ${en_quad}%.s {1..4})Sphinx_tabs"
    printf "\nThese have been installed into separate directories in\n\"${concept_dir}\".\n"
    if [ "${concept_install}" == "True" ] && [ "${concept_installed}" == "False" ]; then
        printf "\nAny use of ${esc_concept} must conform to the license terms\n\
of the above software in addition to its own.\n"
    else
        printf "\nAny use of the above software must conform to their license terms.\n"
    fi
    if [ "${slim}" != "True" ]; then
        echo "These can be found in the separate installation directories."
    fi
fi
# Notice about test errors
current_step="erroneous tests notice"
any_test_error_notices="False"
erroneous_test_notice() {
    # Arguments: Program name, [alternative message]
    progname="${1// /_}"
    progname="$(echo "${progname}" | tr '[:upper:]' '[:lower:]')"
    test_success="True"
    eval "test_success=\"\${${progname}_test_success}\""
    if [ "${test_success}" == "False" ]; then
        if [ "${any_test_error_notices}" == "False" ]; then
            # First test error notice
            heading "Erroneous tests notice"
            any_test_error_notices="True"
        else
            # Add newline between notices
            echo
        fi
        eval "test_log_path=\"\${${progname}_test_log}\""
        printf "${esc_bold}${esc_red}Warning: ${esc_normal}"
        real_name="${1/CONCEPT/$esc_concept}"
        if [ "${real_name}" == "BLAS" ]; then
            real_name="OpenBLAS"
        elif [ "${real_name}" == "MPI" ]; then
            real_name="${mpi_formatted}"
        fi
        printf "Some tests of ${real_name} did not pass successfully.\n"
        if [ -n "${2}" ]; then
            printf "${2}\n"
            if [ "${progname}" != "concept" ] && [ "${concept_test_success}" != "False" ]; then
                printf "As ${esc_concept} do seem to function correctly, "
                printf "you may choose to disregard this.\n"
            fi
        else
            printf "As ${real_name} did seem to install correctly, "
            printf "this is usually not of any concern.\n"
        fi
        printf "The logged output of the tests can be found in\n"
        printf "\"${test_log_path}\"\n"
    fi
}
erroneous_test_notice "CLASS"
erroneous_test_notice "FFTW"
erroneous_test_notice "FFTW for GADGET"
erroneous_test_notice "FreeType"
erroneous_test_notice "GADGET"
erroneous_test_notice "GSL"
erroneous_test_notice "HDF5"
erroneous_test_notice "MPI"
erroneous_test_notice "ncurses"
erroneous_test_notice "NumPy"
erroneous_test_notice "OpenSSL"
erroneous_test_notice "Perl"
erroneous_test_notice "Python"
erroneous_test_notice "SciPy"
erroneous_test_notice "zlib"
erroneous_test_notice "CONCEPT" \
                      "${esc_italic}This should usually be taken seriously!${esc_no_italic}"
if [ "${do_tests}" == "True" ] && [ "${any_test_error_notices}" != "True" ]; then
    printf "\nEvery test of every program ran successfully.\n"
fi
if [ "${any_test_error_notices}" == "True" ] \
    && ([ "${slim}" != "True" ] || [ "${keep_install_logs}" == "True" ]) \
; then
    if [ -s "${log}" ]; then
        printf "\nThe logged output of the entire installation process can be found in\n"
        printf "\"${log}\"\n"
        if [ -s "${log}_err" ]; then
            printf "while the logged warnings and errors can be found in\n"
            printf "\"${log}_err\"\n"
        fi
    elif [ -s "${log}_err" ]; then
        printf "\nThe logged warnings and errors for the entire installation process\n"
        printf "can be found in\n"
        printf "\"${log}_err\"\n"
    fi
fi

# Subprocess complete
printf "\n\n\n"
disable_status
if [ "${any_test_error_notices}" == "False" ]; then
    successfully_finish_status
fi
# Deactivate traps before exiting subprocess
trap : 0
) >> "${log}") 3>&1 1>&2 2>&3 & echo $! > "${tmp_dir}/log_pid") \
    | tee -a "${log}" "${log}_err" > /dev/null & 3>&1 1>&2 2>&3
# Wait for the log_pid file to be created
slept=0
while [ ! -f "${tmp_dir}/log_pid" ]; do
    sleep 1
    ((slept += 1))
    if [ ${slept} -eq 30 ]; then
        break
    fi
done
log_pid=$(cat "${tmp_dir}/log_pid")
rm -f "${tmp_dir}/log_pid" || :
# End of subprocess #
#####################



################
# Display loop #
################
# Wait for the install log to be created
slept=0
while [ ! -f "${log}" ]; do
    sleep 1
    ((slept += 1))
    if [ ${slept} -eq 30 ]; then
        error "Could not create the log file \"${log}\""
        exit 1
    fi
done

# Continuously print the tail of the install log
((n_lines_to_skip = log_file_lines_before_install + 2))
rm -f "${tmp_dir}/.setvars" || :
display_loop() {
    local IFS=''
    printf "\n\n"
    tail -n +${n_lines_to_skip} -f "${log}" --pid ${log_pid} | while read -r line; do
        # Print out the lines, formatted nicely
        if [[ "${line}" == "${status_prefix}"* ]]; then
            status_backup_="${status}"
            status=${line:${status_prefix_length}}
            if [ "${status}" == "${status_disable}" ]; then
                # Disable status
                status_visible="${status_off}"
                status_backup="${status_backup_}"
                printf "${esc_up}${esc_erase}"
                printf "${esc_up}"
            elif [ "${status}" == "${status_enable}" ]; then
                # Enable status
                status_visible="${status_on}"
                status="${status_backup}"
                printf "\n${esc_bold}${esc_reverted}${status}${esc_normal}\n"
            elif    [ "${status}" == "${status_finish_successfully}" ] \
                || [[ "${status}" == "${status_installpid}"* ]] \
            ; then
                # Display loop complete or print of
                # internal install PID. Do nothing.
                :
            elif [[ "${status}" == "${status_setvar}"* ]]; then
                # A variable is to be set in the outer scope
                # from within the subprocess.
                echo "${status#*:}" >> "${tmp_dir}/.setvars"
            elif [ "${status_visible}" == "${status_on}" ]; then
                # Normal status update
                printf "${esc_up}${esc_erase}"
                printf "${esc_up}"
                printf "\n${esc_bold}${esc_reverted}${status}${esc_normal}\n"
            fi
        else
            if [ "${status_visible}" == "${status_on}" ]; then
                # Line with status enabled
                printf "${esc_up}${esc_erase}"
                printf "${esc_up}"
                printf "%s\n" "${line}"
                if [[ "${status}" == "${status_setvar}"* ]]; then
                    printf "\n\n"
                else
                    printf "\n${esc_bold}${esc_reverted}${status}${esc_normal}\n"
                fi
            else
                # Line with status disabled
                printf "%s\n" "${line}"
            fi
        fi
    done
}
display_loop
sleep 1
eval "$(cat "${tmp_dir}/.setvars" 2>/dev/null)" 2>/dev/null || :
rm -f "${tmp_dir}/.setvars" || :

# Installation complete
installation_guaranteed_successful="False"
if     [ "${do_tests}" == "True" ]                                                                \
    && [ "$(tail -n 1 "${log}" 2>/dev/null)" == "${status_prefix}${status_finish_successfully}" ] \
; then
    installation_guaranteed_successful="True"
fi
if [ ! -s "${log}" ]; then
    rm -f "${log}" || :
fi
if [ ! -s "${log}_err" ]; then
    rm -f "${log}_err" || :
fi
if [ "${slim}" == "True" ]; then
    if [ "${keep_install_logs}" != "True" ]; then
        rm -f "${log}"     || :
        rm -f "${log}_err" || :
    fi
fi
if [ -d "${tmp_dir}" ] && [ -z "$(ls -A "${tmp_dir}")" ]; then
    rm -rf "${tmp_dir}" || :
fi
if [ "${say_goodbye}" != "False" ]; then
    if [ "${concept_install}" == "True" ] && [ "${concept_installed}" == "False" ]; then
        if [ "${installation_guaranteed_successful}" == "True" ]; then
            printf "${esc_bold}${esc_green}${esc_concept} installation finished${esc_normal}\n"
        else
            printf "${esc_concept} installation finished\n"
        fi
    else
        if [ "${installation_guaranteed_successful}" == "True" ]; then
            printf "${esc_bold}${esc_green}Installation finished${esc_normal}\n"
        else
            printf "Installation finished\n"
        fi
    fi
fi
trap : 0
