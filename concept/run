#!/usr/bin/env bash

# This file is part of COùòïCEPT, the cosmological ùòï-body code in Python.
# Copyright ¬© 2015 Jeppe Mosgaard Dakin.
#
# COùòïCEPT is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# COùòïCEPT is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with COùòïCEPT. If not, see http://www.gnu.org/licenses/
#
# The auther of COùòïCEPT can be contacted at
# jeppe.mosgaard.dakin(at)post.au.dk
# The latest version of COùòïCEPT is available at
# https://github.com/jmd-dk/concept/



# This script runs the COùòïCEPT code.
# Run the script with the -h option to get help.

# If this file is being sourced, backups of 'this_file' and 'this_dir'
# is needed not to alter the values of these variables.
this_file_backup="${this_file}"
this_dir_backup="${this_dir}"

# Absolute paths to this file and its directory
this_file="$(readlink -f "${BASH_SOURCE[0]}")"
this_dir="$(dirname "${this_file}")"

# ANSI/VT100 escape sequences
esc="\x1b"
esc_normal="${esc}[0m"
esc_bold="${esc}[1m"
esc_italic="${esc}[3m"
esc_no_italic="${esc}[23m"
esc_red="${esc}[91m"

# Load paths from the .paths file
curr="${this_dir}"
while :; do
    if [ -f "${curr}/.paths" ]; then
        source "${curr}/.paths"
        break
    fi
    if [ "${curr}" == "/" ]; then
        # Print out error message and exit
        printf "${esc_bold}${esc_red}Could not find the .paths file!${esc_normal}\n" >&2
        exit 1
    fi
    curr="$(dirname "${curr}")"
done

# Function for printing colored messages
terminal_CONCEPT="CO${esc_italic}N${esc_no_italic}CEPT"
colorprint()
{
# Arguments: Message, color
"${python}" -B -c "
import sys
from blessings import Terminal
terminal = Terminal(force_styling=True)
msg='${1}'.replace('CONCEPT', '${terminal_CONCEPT}')
print(terminal.bold_${2}(msg), file=(sys.stderr if '${2}' == 'red' else sys.stdout))"
}

# Function for converting paths to absolute paths
absolute()
{
    local path="${1}"
    local path_backup="${path}"
    path="${path//[ ]/\\ }"        # Places backslashes before spaces. These are needed when expanding tilde, but they will not persist!
    eval path="${path}"            # Expand tilde
    path=$(readlink -m "${path}")  # Convert to absolute path
    if [ -z "${path}" ]; then
        colorprint "Cannot convert \"${path_backup}\" to an absolute path!" "red"
        exit 1
    fi
    echo "${path}"
} 

# If this file is being sourced, return now
if [ "${BASH_SOURCE[0]}" != "${0}" ]; then
    this_file="${this_file_backup}"
    this_dir="${this_dir_backup}"
    return
fi

# Default values of command-line arguments
local_default="False"
main_default="${concept_dir}/main.py"
nprocs_default=1
params_default="None"
pure_python_default="False"
walltime_default=72
# List of remote queues and number of CPU per node. The first queue is the default queue 
queues=(q8n q8 q4)
ppns=(8 8 4)
# Should PBS be used to submit remote jobs?
use_PBS=1

# Initial but illegal values of some command-line arguments,
# for testing whether these arguments have been supplied.
nprocs_unspecified="-1"
params_unspecified="__none__"
queue_unspecified="__none__"
test_unspecified="__none__"
util_unspecified="__none__"

# Change to the concept code directory
cd "${concept_dir}"
# On some systems, libpng finds wrong versions of the zlib shared
# library. To fix this we export the zlib library at run time.
export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"

# Use Python's argparse module to handle command-line arguments
args=($("${python}" -B -c "
import argparse, sys
# Setup command-line arguments
parser = argparse.ArgumentParser(prog='$(basename ${this_file})',
                                 description='Run the CONCEPT code')
parser.add_argument('-m', '--main',
                    help='entry point of the code',
                    default='${main_default}',
                    )
parser.add_argument('-n', '--nprocs',
                    help='number of processes',
                    type=int,
                    default=${nprocs_unspecified},
                    )
parser.add_argument('-p', '--params',
                    help='parameterfile to use',
                    default='${params_unspecified}',
                    )
parser.add_argument('-q', '--queue',
                    help='Queue for submission of the remote job. If omitted the script will try to choose the best.',
                    default='${queue_unspecified}',
                    )
parser.add_argument('-t', '--test',
                    help='run test TEST. TEST can be any subdirectory of the tests directory. Use TEST=all to run all tests',
                    default='${test_unspecified}',
                    )
parser.add_argument('-u', '--util',
                    nargs='+',
                    help='run utility UTIL. UTIL can be any executable in the utilities directory',
                    default=['${util_unspecified}'],
                    )
parser.add_argument('-w', '--walltime',
                     help='Set the PBS walltime in whole hours',
                     type=int,
                     default=${walltime_default},
                     )
parser.add_argument('--local',
                    help='Force the run to be done locally, without submitting it via PBS',
                    default=${local_default},
                    action='store_true',
                    )
parser.add_argument('--pure-python',
                    help='run in pure Python mode',
                    default=${pure_python_default},
                    action='store_true',
                    )
# Enables Python to write directly to screen (stderr)
# in case of help request
stdout_copy = sys.stdout
sys.stdout = sys.stderr
# Now do the actual argument parsing, including writing out the help message
args = parser.parse_args()
# Reset stdout
sys.stdout = stdout_copy
# Print out the arguments.
# These will be captured in the bash 'args' variable
print('graceful_exit',
      args.main,
      args.nprocs,
      args.params,
      args.queue,
      args.test,
      args.util[0],
      '\"' + '\"__space__\"'.join(args.util[1:]).replace(' ','__space__') + '\"' if len(args.util) > 1 else '\"\"',
      args.walltime,
      args.local,
      args.pure_python,
      )
" "$@"))
graceful_exit="${args[0]}"
main="${args[1]}"
nprocs="${args[2]}"
params="${args[3]}"
queue="${args[4]}"
test="${args[5]}"
util="${args[6]}"
util_args="${args[7]//__space__/ }"
walltime="${args[8]}"
local="${args[9]}"
pure_python="${args[10]}"
if [ -z "${graceful_exit}" ]; then
    # Help requested and given. Exit
    trap : 0
    exit 0
fi
if [ "${#args[@]}" -ne 11 ]; then
    colorprint "Error: Not every command-line argument was gracefully dealt with!" "red"
    exit 1
fi

# Set up error trapping
ctrl_c()
{
    trap : 0
    exit 2
}
abort()
{
    colorprint "An error occurred!" "red"
    exit 1
}
trap 'ctrl_c' SIGINT
trap 'abort' EXIT
set -e

# Convert all supplied paths to absolute paths
main="$(absolute "${main}")"
if [ "${params}" != "${params_unspecified}" ]; then
    params="$(absolute "${params}")"
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ]; then
    test="${concept_dir}/tests/$(basename "${test}")"
fi
if [ "${util}" != "${util_unspecified}" ]; then
    util="${concept_dir}/utilities/$(basename "${util}")"
fi

# Do the supplied paths exist?
if [ ! -f "${main}" ]; then
    colorprint "Error: Entry point \"${main}\" does not exist!" "red"
    exit 1
fi
if [ "${params}" != "${params_unspecified}" ] && [ ! -f "${params}" ]; then
    colorprint "Error: Parameterfile \"${params}\" does not exist!" "red"
    exit 1
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ] && [ ! -d "${test}" ]; then
    colorprint "Error: Test \"${test}\" does not exist!" "red"
    exit 1
fi
if [ "${util}" != "${util_unspecified}" ] && [ ! -f "${util}" ]; then
    colorprint "Error: Utility \"${util}\" does not exist!" "red"
    exit 1
fi

# Assigned values to unspecified parameters
running_test_or_util="False"
if [ "${util}" != "${util_unspecified}" ] || [ "${test}" != "${test_unspecified}" ]; then
    running_test_or_util="True"
fi
if [ "${nprocs}" == "${nprocs_unspecified}" ]; then
    nprocs="${nprocs_default}"
    if [ "${running_test_or_util}" == "False" ]; then
        echo "Number of processes not specified - Will use ${nprocs}"
    fi
fi
if [ "${params}" == "${params_unspecified}" ]; then
    params="${params_default}"
    if [ "${running_test_or_util}" == "False" ]; then
        echo "Parameterfile not specified - Will use default parameters"
    fi
fi

# If a test is to be run, run it and exit
if [ "${test}" != "${test_unspecified}" ]; then
    if [ "${test}" == "all" ]; then
        trap : 0
        for dir in "${concept_dir}/tests/"*/; do
            dir=${dir%*/}
            colorprint "\nRunning $(basename ${dir}) test" "yellow"
            "${dir}/run_test"
        done
        colorprint "All tests ran successfully" "green"
    else
        colorprint "Running $(basename ${test}) test" "yellow"
        trap : 0
        "${test}/run_test"
    fi
    exit 0
fi

# If a utility is to be run, run it and exit
if [ "${util}" != "${util_unspecified}" ]; then
    # Export every command-line argument. These will be fed back into
    # this script when called from the utility.
    export main="${main}"
    export nprocs="${nprocs}"
    export params="${params}"
    export queue="${queue}"
    export test="${test}"
    export util="${util}"
    export walltime="${walltime}"
    export local="${local}"
    export pure_python="${pure_python}"
    colorprint "Running the $(basename ${util}) utility" "yellow"
    trap : 0
    eval "${util}" ${util_args}
    exit 0
fi

# Relative path to the main and parameter, for clean printout
main_rel=$(${python}   -B -c "from os.path import relpath; rel = relpath('${main}',   '${concept_dir}'); print(rel if not rel.startswith('../../') else '${main}')")
params_rel=$(${python} -B -c "from os.path import relpath; rel = relpath('${params}', '${concept_dir}'); print(rel if not rel.startswith('../../') else '${params}')")

# Prompt the user for the secure shell password,
# if the live render should be uploaded to a remote host.
args=($("${python}" -B -c "
import os, pexpect, re, sys
from getpass import getpass
from time import sleep
# Import parameters from the commons module
from commons import *
# Ask for password if remote liverender is requested
scp_password = ''
scp_success = 'success'
if remote_liverender:
    # Create test file to be scp'ed
    test_filename = '${this_dir}/.scp_test'
    with open(test_filename, 'a'):
        pass
    # Spawn the interactive process
    cmd = 'scp \"{}\" \"{}\"'.format(test_filename, remote_liverender)
    scp_host = re.search('@(.*):', remote_liverender).group(1)
    scp_dist = re.search(':(.*)',  remote_liverender).group(1)
    expects = ['password.*',
               'passphrase.*',
               'continue connecting',
               pexpect.EOF,
               pexpect.TIMEOUT,
               ]
    print('\nThe latest render will continuously be scp\'ed to\n\"{}\" at {}'
           .format(scp_dist, scp_host), file=sys.stderr)
    child = pexpect.spawn(cmd, timeout=15, env={'SSH_ASKPASS': '',
                                                'DISPLAY'    : ''})
    # Interactions
    while True:
        n = child.expect(expects)
        if n < 2:
            # scp asks for password or passphrase. Prompt the user for it
            scp_password = getpass((child.before + child.after).decode('utf-8'))
            # Now supply scp with the password
            child.sendline(scp_password)
        elif n == 2:
            # scp cannot authenticate host. Connect anyway
            child.sendline('yes')
        elif n == 3:
            # 
            break
        else:
            child.kill(9)
            break
    child.close(force=True)
    os.remove(test_filename)
    # If the test scp did not go well, reset password and write error message
    if child.status:
        scp_password = ''
        scp_success = ('Warning: Could not establish connection to {}\\\n'
                       + \"Remote live renders will not be scp\\\'ed\"
                       ).format(scp_host)
# Print out the password/passphrase and whether the scp test was
# successful. These will be captured in the bash 'args' variable.
print(scp_success.replace(' ', '~'),
      scp_password,
      )
" "params='${params}'"))
scp_success="${args[0]//\~/ }"
scp_password="${args[1]}"
if [ "${scp_success}" != "success" ]; then
    colorprint "${scp_success}" "red"
    sleep 10
fi

# Compile or do cleanup from last compilation
if [ "${pure_python}" == "True" ] ; then
    # Rename compiled Cython modules *.so to *.so_
    if ls "${concept_dir}/"*.so > /dev/null 2>&1; then
        (cd "${concept_dir}" && for f in *.so; do mv "${f}" "${f%.so}.so_"; done)
    fi
else
    # Rename compiled Cython modules *.so_ back to *.so and compile with Cython
    if ls "${concept_dir}/"*.so_ > /dev/null 2>&1; then
        (cd "${concept_dir}" && for f in *.so_; do mv "${f}" "${f%.so_}.so"; done)
    fi
    (cd "${concept_dir}" && make)
fi

# Create the logs dir if it does not exist
mkdir -p "${concept_dir}/logs"

# Determine whether this script is run locally or remotely via ssh.
# Always treat tests as if they were run locally.
if [ "${local}" == "False" ] && [ "${test}" == "${test_unspecified}" ] && ([ -n "${SSH_CLIENT}" ] || [ -n "${SSH_TTY}" ]); then
    remote=1
else
    remote=0
fi

# Either stop doing further actions, submit job or run it locally
if [ "${use_PBS}" -eq 0 ] && [ "${remote}" -eq 1 ]; then
    # Run remotely but do not use PBS
    printf "The ${terminal_CONCEPT} code is ready to be submitted"
    trap : 0
elif [ "${use_PBS}" -eq 1 ] && [ "${remote}" -eq 1 ]; then
    # Run remotely.
    # If no queue is explicitly chosen, use one with enough free nodes
    if [ "${queue}" == "${queue_unspecified}" ]; then
        # The first queue in the list is the default queue
        queue="${queues[0]}"
        ppn="${ppns[0]}"
        # Change to the queue that has enogh free CPUS to begin job immediately
        node_table=$(nodes)
        for i in $(eval echo "{0..${#queues[@]}}" | sed s/'\w*$'//); do
            free_nodes=$(echo "${node_table}" | grep -o -P "(?<= ${queues[${i}]}:).*(?= free)" | awk '{print $NF}')
            free_cpus=$(echo "$((${free_nodes} * ${ppns[${i}]}))")
            if [ "${free_cpus}" -ge "${nprocs}" ] && [ "$((${nprocs} % ${ppns[${i}]}))" -eq 0 ]; then
                queue="${queues[${i}]}"
                ppn="${ppns[${i}]}"
                break
            fi
        done
    else
        # How many CPUs does the explicitly chosen queue have per node?
        for i in $(eval echo "{0..${#queues[@]}}" | sed s/'\w*$'//); do
            if [ "${queue}" == "${queues[${i}]}" ]; then
                ppn="${ppns[${i}]}"
                break
            fi
        done
    fi
    # Check that the chosen queue can be run with all the node's CPUs in use
    if [ "$((${nprocs} % ${ppn}))" != 0 ]; then
        colorprint "Error: Job submission refused:\nNo queue has the right amount of processors per node" "red"
        exit 1
    fi
    nodes="$((${nprocs} / ${ppn}))"
    # Write a jobscript file
    echo -e "#!/usr/bin/env bash
#PBS -N $(whoami):CONCEPT:$(basename ${params})
#PBS -q ${queue}
#PBS -l nodes=${nodes}:ppn=${ppn}
#PBS -l walltime=${walltime}:00:00
#PBS -o /dev/null
#PBS -e /dev/null

# Get the id of the current job
jobid=\"\${PBS_JOBID%.in1}\"

# Change to the logs directory, so that autogenerated files will be dumped there
cd \"${concept_dir}/logs\"

# Source the run script
source \"${this_file}\"

# Print start messages
if [ \"${pure_python}\" == \"True\" ]; then
    colorprint \"Running CONCEPT in pure Python mode remotely on \$(hostname -f) as job \${jobid}\" \"yellow\" > \"${concept_dir}/logs/\${jobid}\"
else
    colorprint \"Running CONCEPT remotely on \$(hostname -f) as job \${jobid}\" \"yellow\" > \"${concept_dir}/logs/\${jobid}\"
fi
echo \"Entry point:   \\\"${main_rel}\\\"\"    >> \"${concept_dir}/logs/\${jobid}\"
echo \"Parameterfile: \\\"${params_rel}\\\"\"  >> \"${concept_dir}/logs/\${jobid}\"
echo \"Logfile:       \\\"logs/\${jobid}\\\"\" >> \"${concept_dir}/logs/\${jobid}\"
echo \"Nr. of CPUs:    ${nprocs}\"             >> \"${concept_dir}/logs/\${jobid}\"

# Prepare Python options
if [ \"${pure_python}\" == \"True\" ]; then
    # Run as normal Python script
    main_as_library=\"${main}\"
    m_flag=\"\"
else
    # Run as compiled library module
    main_as_library=\"$(basename "${main%.*}.so")\"
    m_flag=\"-m\"
fi

# Run the code. Both stdout and stderr are being logged to logs/jobid,
# while the stderr alone is also logged to logs/jobid_err.
(cd \"${concept_dir}\" && \"${mpiexec}\" \"${python}\" -B \${m_flag} \"\${main_as_library}\" \"${scp_password}\" >> \"${concept_dir}/logs/\${jobid}\" 2>> >(tee -a \"${concept_dir}/logs/\${jobid}_err\"))

# Run complete. Remove error log if empty
if [ -f \"${concept_dir}/logs/\${jobid}_err\" ] && [ ! -s \"${this_dir}/logs/\${jobid}_err\" ]; then
    rm \"${concept_dir}/logs/\${jobid}_err\"
else
    colorprint \"\\\nSome warnings/errors occured during CONCEPT run!\" \"red\" >> \"${concept_dir}/logs/\${jobid}\" 2>&1
    colorprint \"Check the following error log for more information:\" \"red\" >> \"${concept_dir}/logs/\${jobid}\" 2>&1
    colorprint \"\\\"${concept_dir}/logs/\${jobid}_err\\\"\" \"red\" >> \"${concept_dir}/logs/\${jobid}\" 2>&1
fi
" > "${this_dir}/jobscript"
    # Submit the remote job from within the logs directory, so that autogenerated files will be dumped there
    jobid=$(cd "${concept_dir}/logs" && qsub "${this_dir}/jobscript")
    jobid="${jobid%.in1}"
    colorprint "\nSubmitting job" "yellow"
    echo "Job ${jobid} submitted to queue ${queue}"
    echo "You can now kill (Ctrl-C) this script without cancelling the job"
    # Deactivate trap and call the watch script
    trap : 0
    "${concept_dir}/utilities/watch" "${jobid}"
else
    # Run locally.
    # Construct a jobid that does not conflict with the content of the logs dir
    jobid=0
    while :; do
        if [ ! -f "${concept_dir}/logs/${jobid}" ]; then
            break
        fi
        ((jobid += 1))
    done
    # Print start message
    echo
    if [ "${pure_python}" == "True" ]; then
        colorprint "Running CONCEPT in pure Python mode" "yellow" | tee "${concept_dir}/logs/${jobid}"
    else
        colorprint "Running CONCEPT" "yellow" | tee "${concept_dir}/logs/${jobid}"
    fi
    echo "Entry point:   \"${main_rel}\""   | tee -a "${concept_dir}/logs/${jobid}"
    echo "Parameterfile: \"${params_rel}\"" | tee -a "${concept_dir}/logs/${jobid}"
    echo "Logfile:       \"logs/${jobid}\"" | tee -a "${concept_dir}/logs/${jobid}"
    echo "Nr. of CPUs:    ${nprocs}"        | tee -a "${concept_dir}/logs/${jobid}"
    # Prepare Python options
    if [ "${pure_python}" == "True" ] ; then
        # Run as normal Python script
        main_as_library="${main}"
        m_flag=""
    else
        # Run as compiled library module
        main_as_library="$(basename "${main%.*}.so")"
        m_flag="-m"
    fi
    # Run the code. Print stdout and stderr to the terminal while at the
    # same time logging them to logs/jobid. The stderr alone is also
    # logged to logs/jobid_err.
    "${mpiexec}" -n "${nprocs}" "${python}" -B ${m_flag} "${main_as_library}" "params='${params}'" "scp_password='${scp_password}'" 2> >(tee -a "${concept_dir}/logs/${jobid}_err") | tee -a "${concept_dir}/logs/${jobid}"
    # Get exit status of the above COùòïCEPT run
    concept_exit_status="${PIPESTATUS[0]}"
    # Run complete. Remove error log if empty
    if [ -f "${concept_dir}/logs/${jobid}_err" ] && [ ! -s "${concept_dir}/logs/${jobid}_err" ]; then
        rm "${concept_dir}/logs/${jobid}_err"
    else
        colorprint "\nSome warnings/errors occured during CONCEPT run!" "red" 2>&1 | tee -a "${concept_dir}/logs/${jobid}"
        colorprint "Check the following error log for more information:" "red" 2>&1 | tee -a "${concept_dir}/logs/${jobid}"
        colorprint "\"${concept_dir}/logs/${jobid}_err\"" "red" 2>&1 | tee -a "${concept_dir}/logs/${jobid}"
    fi
    # If the COùòïCEPT run exited erroneously, exit now
    if [ "${concept_exit_status}" != "0" ]; then
        exit 1
    fi
    # Deactivate trap before exiting
    trap : 0
fi
